{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cloth recommendation_ML2_KDY.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "JkwdpQlUClQ_",
        "CFybH6x5B0Bi",
        "JSid7uSYCHD6",
        "zrB2fMi9CN3_",
        "IvZ1SF5RFdUH",
        "6HDq2JlTFNa8",
        "51bj6rT1KcrB",
        "VGmrv14UFa5i",
        "9f_T8XF66lTu",
        "Ylnb0mrS9NB2",
        "ctAUgY48Z2yi"
      ],
      "mount_file_id": "1eTSc5ZQVx_g1iQq5Lv2GXyHswvnpg6T_",
      "authorship_tag": "ABX9TyOhYdfViC29L3MVkG9ZLdnS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kdy5213/AI-ExpertFW-Prj/blob/main/cloth_recommendation_ML2_KDY.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###머신러닝 관련 메모"
      ],
      "metadata": {
        "id": "JkwdpQlUClQ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "머신러닝 범주형 데이터 처리\n",
        "https://blog.naver.com/PostView.naver?blogId=dalgoon02121&logNo=222088976883&parentCategoryNo=&categoryNo=37&viewDate=&isShowPopularPosts=true&from=search\n",
        "\n",
        "- 문자열(범주형) 값을 내림차순 정렬 후 0부터 1씩 증가하는 값으로 변환함.\n",
        "\n",
        "- 숫자의 차이가 모델에 영향을 주지 않는 트리 계열 모델에 적용함.\n",
        "\n",
        "    (의사결정나무, 랜덤포레스트)\n",
        "결정 트리와 랜덤 포레스트는 특성 스케일 조정에 대해 걱정할 필요가 없는 몇 안되는 머신러닝 알고리즘 중 하나이다.\n",
        "대부분 머신러닝과 최적화 알고리즘은 특성의 스케일이 같을때 성능이 훨씬 좋다\n",
        "\n",
        "- 숫자의 차이가 모델에 영향을 미치는 선형 계열 모델에는 적용하지 않는 것이 좋음.\n",
        "\n",
        "    (로지스틱 회귀, SVM, 신경망 → 원핫인코딩 적용)\n",
        "\n",
        "\n",
        "Up sampling : HH2_2022_2.ipynb 참고\n",
        "sm = SMOTE(sampling_strategy = 1 ,k_neighbors = 5, random_state=1)   \n",
        "#Synthetic Minority Over Sampling Technique\n",
        "X_train_res, y_train_res = sm.fit_resample(X_train, y_train.ravel())\n",
        "Down Sampling : HH2_2022_2.ipynb 참고\n",
        "\n",
        "\n",
        "sklearn.preprocessing.LabelEncoder 활용 방법\n",
        "\n",
        "> fit() : 어떻게 변환할 것인지에 대해 학습\n",
        "\n",
        "> transform() : 문자열을 숫자로 변환\n",
        "\n",
        "> fit_transform() : 학습과 변환을 한 번에 처리\n",
        "\n",
        "> inverse_transform() : 숫자를 다시 문자열로 변환\n",
        "\n",
        "> classes_ : 인코딩한 클래스 조회\n",
        "\n",
        "\n",
        "벨 인코딩에도 뚜렷한 장점이 있는데 첫째, 컬럼의 수가 1개로 줄어서 메모리의 관점에서 매우 효율적입니다. \n",
        "둘째, 변수가 순서를 가지는 경우, 예를 들어서 수능 1등급 집단, 2등급 집단, 3등급 집단 ... \n",
        "혹은 10대, 20대, ... , 90대와 같이 순서 자체가 진짜 의미가 있는 경우에는 라벨 인코딩이 효과적일 수 있습니다. \n",
        "\n",
        "\n",
        "train_test_split(..., stratify = y, random_state = 1)\n",
        "stratify 값을 target으로 지정해주면 각각의 class 비율(ratio)을 train / validation에 유지해줍니다.(https://ysyblog.tistory.com/71)\n",
        "\n",
        "scaling 할 때는 train data scaling 한 것 기준으로 test data를 scaling\n",
        "\n",
        "\n",
        "\n",
        "np.unique(y) 함수는 iris.target에 저장된 세 개의 고유한 클래스 레이블을 반환합니다.\n",
        "\n",
        "정수 레이블을 사용하는 이유는 사소한 실수를 피할 수 있고 작은 메모리 영역을 차지하므로 계산 성능을 향상 시킵니다.\n",
        "\n",
        "클래스 레이블을 정수로 인코딩하는 것은 대부분 머신러닝 라이브러리들의 공통된 관례이기도 합니다.\n",
        "\n",
        "처음 본 데이터에서 훈련된 모델 성능을 평가하기 위해 데이터셋을 훈련 세트와 테스트 세트로 분할합니다.(ppt 참고)"
      ],
      "metadata": {
        "id": "RTYZ1iG4AcCC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6jN-yWfhSam5"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 전처리 데이터 불러오기"
      ],
      "metadata": {
        "id": "CFybH6x5B0Bi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir('/content/drive/MyDrive/Colab Notebooks/GitHub/AI-ExpertFW-Prj/dataset')"
      ],
      "metadata": {
        "id": "MbWajIyUS46s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mc_df = pd.read_excel('/content/drive/MyDrive/Colab Notebooks/GitHub/AI-ExpertFW-Prj/dataset/modcloth.xlsx')\n",
        "mc_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "VlGq3lYz-n-G",
        "outputId": "62e7408a-9c18-4118-816c-99758c2264ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   item_id  waist  size  quality cup size  hips  bra size category bust  \\\n",
              "0   123373   29.0     7      5.0        d  38.0      34.0      new   36   \n",
              "1   123373   31.0    13      3.0        b  30.0      36.0      new  NaN   \n",
              "2   123373   30.0     7      2.0        b   NaN      32.0      new  NaN   \n",
              "3   123373    NaN    21      5.0     dd/e   NaN       NaN      new  NaN   \n",
              "4   123373    NaN    18      5.0        b   NaN      36.0      new  NaN   \n",
              "\n",
              "    height         user_name         length    fit  user_id  shoe size  \\\n",
              "0  5ft 6in             Emily     just right  small   991571        NaN   \n",
              "1  5ft 2in  sydneybraden2001     just right  small   587883        NaN   \n",
              "2  5ft 7in             Ugggh  slightly long  small   395665        9.0   \n",
              "3      NaN      alexmeyer626     just right    fit   875643        NaN   \n",
              "4  5ft 2in        dberrones1  slightly long  small   944840        NaN   \n",
              "\n",
              "  shoe width review_summary review_text  \n",
              "0        NaN            NaN         NaN  \n",
              "1        NaN            NaN         NaN  \n",
              "2        NaN            NaN         NaN  \n",
              "3        NaN            NaN         NaN  \n",
              "4        NaN            NaN         NaN  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e3a36570-e4ec-40b3-ac2a-0c880e40397f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>item_id</th>\n",
              "      <th>waist</th>\n",
              "      <th>size</th>\n",
              "      <th>quality</th>\n",
              "      <th>cup size</th>\n",
              "      <th>hips</th>\n",
              "      <th>bra size</th>\n",
              "      <th>category</th>\n",
              "      <th>bust</th>\n",
              "      <th>height</th>\n",
              "      <th>user_name</th>\n",
              "      <th>length</th>\n",
              "      <th>fit</th>\n",
              "      <th>user_id</th>\n",
              "      <th>shoe size</th>\n",
              "      <th>shoe width</th>\n",
              "      <th>review_summary</th>\n",
              "      <th>review_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>123373</td>\n",
              "      <td>29.0</td>\n",
              "      <td>7</td>\n",
              "      <td>5.0</td>\n",
              "      <td>d</td>\n",
              "      <td>38.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>new</td>\n",
              "      <td>36</td>\n",
              "      <td>5ft 6in</td>\n",
              "      <td>Emily</td>\n",
              "      <td>just right</td>\n",
              "      <td>small</td>\n",
              "      <td>991571</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>123373</td>\n",
              "      <td>31.0</td>\n",
              "      <td>13</td>\n",
              "      <td>3.0</td>\n",
              "      <td>b</td>\n",
              "      <td>30.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>new</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5ft 2in</td>\n",
              "      <td>sydneybraden2001</td>\n",
              "      <td>just right</td>\n",
              "      <td>small</td>\n",
              "      <td>587883</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>123373</td>\n",
              "      <td>30.0</td>\n",
              "      <td>7</td>\n",
              "      <td>2.0</td>\n",
              "      <td>b</td>\n",
              "      <td>NaN</td>\n",
              "      <td>32.0</td>\n",
              "      <td>new</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5ft 7in</td>\n",
              "      <td>Ugggh</td>\n",
              "      <td>slightly long</td>\n",
              "      <td>small</td>\n",
              "      <td>395665</td>\n",
              "      <td>9.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>123373</td>\n",
              "      <td>NaN</td>\n",
              "      <td>21</td>\n",
              "      <td>5.0</td>\n",
              "      <td>dd/e</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>new</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>alexmeyer626</td>\n",
              "      <td>just right</td>\n",
              "      <td>fit</td>\n",
              "      <td>875643</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>123373</td>\n",
              "      <td>NaN</td>\n",
              "      <td>18</td>\n",
              "      <td>5.0</td>\n",
              "      <td>b</td>\n",
              "      <td>NaN</td>\n",
              "      <td>36.0</td>\n",
              "      <td>new</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5ft 2in</td>\n",
              "      <td>dberrones1</td>\n",
              "      <td>slightly long</td>\n",
              "      <td>small</td>\n",
              "      <td>944840</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e3a36570-e4ec-40b3-ac2a-0c880e40397f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e3a36570-e4ec-40b3-ac2a-0c880e40397f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e3a36570-e4ec-40b3-ac2a-0c880e40397f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "modcloth_preprocessing3 = pd.read_excel('modcloth_preprocessing3.xlsx')\n"
      ],
      "metadata": {
        "id": "Qljn-SRmS4_1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modcloth_preprocessing3.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5sfRSeUPLU2j",
        "outputId": "6731d6c3-aad5-4e5c-a8ee-8d0f5678c77a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 62994 entries, 0 to 62993\n",
            "Data columns (total 21 columns):\n",
            " #   Column           Non-Null Count  Dtype  \n",
            "---  ------           --------------  -----  \n",
            " 0   item_id          62994 non-null  int64  \n",
            " 1   size             62994 non-null  int64  \n",
            " 2   rating           62994 non-null  int64  \n",
            " 3   height           62994 non-null  float64\n",
            " 4   length           62994 non-null  int64  \n",
            " 5   fit              62994 non-null  int64  \n",
            " 6   user_id          62994 non-null  int64  \n",
            " 7   review_summary   58106 non-null  object \n",
            " 8   review_text      58106 non-null  object \n",
            " 9   cate_bottoms     62994 non-null  int64  \n",
            " 10  cate_dresses     62994 non-null  int64  \n",
            " 11  cate_new         62994 non-null  int64  \n",
            " 12  cate_outerwear   62994 non-null  int64  \n",
            " 13  cate_sale        62994 non-null  int64  \n",
            " 14  cate_tops        62994 non-null  int64  \n",
            " 15  cate_wedding     62994 non-null  int64  \n",
            " 16  waist            62994 non-null  float64\n",
            " 17  hips             62994 non-null  float64\n",
            " 18  bra_size         62994 non-null  float64\n",
            " 19  bust_size        62994 non-null  float64\n",
            " 20  cup_size_in_cms  62994 non-null  float64\n",
            "dtypes: float64(6), int64(13), object(2)\n",
            "memory usage: 10.1+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "modcloth_preprocessing3.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "cCWS1CEd2uFL",
        "outputId": "ba947213-e647-4238-d80d-8de3775ef654"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   item_id  size  rating  height  length  fit  user_id review_summary  \\\n",
              "0   123373     7       5  167.64       3    1   991571            NaN   \n",
              "1   123373    13       3  157.48       3    1   587883            NaN   \n",
              "2   123373     7       2  170.18       4    1   395665            NaN   \n",
              "3   123373    18       5  157.48       4    1   944840            NaN   \n",
              "4   123373    11       5  162.56       3    1   162012            NaN   \n",
              "\n",
              "  review_text  cate_bottoms  ...  cate_new  cate_outerwear  cate_sale  \\\n",
              "0         NaN             0  ...         1               0          0   \n",
              "1         NaN             0  ...         1               0          0   \n",
              "2         NaN             0  ...         1               0          0   \n",
              "3         NaN             0  ...         1               0          0   \n",
              "4         NaN             0  ...         1               0          0   \n",
              "\n",
              "   cate_tops  cate_wedding   waist       hips  bra_size  bust_size  \\\n",
              "0          0             0  29.000  38.000000      34.0  36.000000   \n",
              "1          0             0  31.000  30.000000      36.0  35.724218   \n",
              "2          0             0  30.000  34.438637      32.0  32.904880   \n",
              "3          0             0  31.325  39.688948      36.0  36.370556   \n",
              "4          0             0  27.000  41.000000      36.0  37.467970   \n",
              "\n",
              "   cup_size_in_cms  \n",
              "0             18.5  \n",
              "1             14.5  \n",
              "2             14.5  \n",
              "3             14.5  \n",
              "4             16.5  \n",
              "\n",
              "[5 rows x 21 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9a54dc16-8f26-40ca-a6cc-fbe958be00ea\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>item_id</th>\n",
              "      <th>size</th>\n",
              "      <th>rating</th>\n",
              "      <th>height</th>\n",
              "      <th>length</th>\n",
              "      <th>fit</th>\n",
              "      <th>user_id</th>\n",
              "      <th>review_summary</th>\n",
              "      <th>review_text</th>\n",
              "      <th>cate_bottoms</th>\n",
              "      <th>...</th>\n",
              "      <th>cate_new</th>\n",
              "      <th>cate_outerwear</th>\n",
              "      <th>cate_sale</th>\n",
              "      <th>cate_tops</th>\n",
              "      <th>cate_wedding</th>\n",
              "      <th>waist</th>\n",
              "      <th>hips</th>\n",
              "      <th>bra_size</th>\n",
              "      <th>bust_size</th>\n",
              "      <th>cup_size_in_cms</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>123373</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>167.64</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>991571</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>29.000</td>\n",
              "      <td>38.000000</td>\n",
              "      <td>34.0</td>\n",
              "      <td>36.000000</td>\n",
              "      <td>18.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>123373</td>\n",
              "      <td>13</td>\n",
              "      <td>3</td>\n",
              "      <td>157.48</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>587883</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>31.000</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>36.0</td>\n",
              "      <td>35.724218</td>\n",
              "      <td>14.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>123373</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>170.18</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>395665</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30.000</td>\n",
              "      <td>34.438637</td>\n",
              "      <td>32.0</td>\n",
              "      <td>32.904880</td>\n",
              "      <td>14.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>123373</td>\n",
              "      <td>18</td>\n",
              "      <td>5</td>\n",
              "      <td>157.48</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>944840</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>31.325</td>\n",
              "      <td>39.688948</td>\n",
              "      <td>36.0</td>\n",
              "      <td>36.370556</td>\n",
              "      <td>14.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>123373</td>\n",
              "      <td>11</td>\n",
              "      <td>5</td>\n",
              "      <td>162.56</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>162012</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>27.000</td>\n",
              "      <td>41.000000</td>\n",
              "      <td>36.0</td>\n",
              "      <td>37.467970</td>\n",
              "      <td>16.5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 21 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9a54dc16-8f26-40ca-a6cc-fbe958be00ea')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9a54dc16-8f26-40ca-a6cc-fbe958be00ea button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9a54dc16-8f26-40ca-a6cc-fbe958be00ea');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 데이터 split"
      ],
      "metadata": {
        "id": "PTx1mm6YB9l3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "modcloth_preprocessing3.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pDhHmXwpBcZn",
        "outputId": "bedff019-cad0-4d33-ae25-14fb52393c5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['item_id', 'size', 'rating', 'height', 'length', 'fit', 'user_id',\n",
              "       'review_summary', 'review_text', 'cate_bottoms', 'cate_dresses',\n",
              "       'cate_new', 'cate_outerwear', 'cate_sale', 'cate_tops', 'cate_wedding',\n",
              "       'waist', 'hips', 'bra_size', 'bust_size', 'cup_size_in_cms'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#X_data = modcloth_preprocessing3[(modcloth_preprocessing3['fit'] == 2) & (modcloth_preprocessing3['length'] == 3)][['height', 'waist', 'hips', 'bra_size', 'bust_size', 'cup_size_in_cms', 'cate_bottoms', 'cate_dresses', 'cate_new', 'cate_outerwear', 'cate_sale', 'cate_tops', 'cate_wedding']]\n",
        "\n",
        "X_data = modcloth_preprocessing3[(modcloth_preprocessing3['fit'] == 2) & (modcloth_preprocessing3['length'] == 3)][['height', 'waist', 'hips', 'bra_size', 'bust_size', 'cup_size_in_cms', 'cate_bottoms', 'cate_dresses', 'cate_new', 'cate_outerwear', 'cate_sale', 'cate_tops', 'cate_wedding']]\n",
        "Y_data = modcloth_preprocessing3[(modcloth_preprocessing3['fit'] == 2) & (modcloth_preprocessing3['length'] == 3)]['size']"
      ],
      "metadata": {
        "id": "hiashU4-Eh1S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "zQgGUc1t_1ty",
        "outputId": "f67ff4b1-5b19-4ebf-f02c-00fbb770ce53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    height      waist       hips  bra_size  bust_size  cup_size_in_cms  \\\n",
              "7   167.64  31.800000  41.000000      36.0  39.000000             20.5   \n",
              "8   165.10  29.216667  36.884795      34.0  34.339232             16.5   \n",
              "9   165.10  28.400000  30.000000      34.0  36.587500             20.5   \n",
              "10  160.02  27.850000  36.000000      34.0  34.764329             14.5   \n",
              "11  157.48  31.900000  44.000000      36.0  41.733333             18.5   \n",
              "\n",
              "    cate_bottoms  cate_dresses  cate_new  cate_outerwear  cate_sale  \\\n",
              "7              0             0         1               0          0   \n",
              "8              0             0         1               0          0   \n",
              "9              0             0         1               0          0   \n",
              "10             0             0         1               0          0   \n",
              "11             0             0         1               0          0   \n",
              "\n",
              "    cate_tops  cate_wedding  \n",
              "7           0             0  \n",
              "8           0             0  \n",
              "9           0             0  \n",
              "10          0             0  \n",
              "11          0             0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-437565e8-9c7f-49d2-8c6b-5200f70fa843\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>height</th>\n",
              "      <th>waist</th>\n",
              "      <th>hips</th>\n",
              "      <th>bra_size</th>\n",
              "      <th>bust_size</th>\n",
              "      <th>cup_size_in_cms</th>\n",
              "      <th>cate_bottoms</th>\n",
              "      <th>cate_dresses</th>\n",
              "      <th>cate_new</th>\n",
              "      <th>cate_outerwear</th>\n",
              "      <th>cate_sale</th>\n",
              "      <th>cate_tops</th>\n",
              "      <th>cate_wedding</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>167.64</td>\n",
              "      <td>31.800000</td>\n",
              "      <td>41.000000</td>\n",
              "      <td>36.0</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>20.5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>165.10</td>\n",
              "      <td>29.216667</td>\n",
              "      <td>36.884795</td>\n",
              "      <td>34.0</td>\n",
              "      <td>34.339232</td>\n",
              "      <td>16.5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>165.10</td>\n",
              "      <td>28.400000</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>34.0</td>\n",
              "      <td>36.587500</td>\n",
              "      <td>20.5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>160.02</td>\n",
              "      <td>27.850000</td>\n",
              "      <td>36.000000</td>\n",
              "      <td>34.0</td>\n",
              "      <td>34.764329</td>\n",
              "      <td>14.5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>157.48</td>\n",
              "      <td>31.900000</td>\n",
              "      <td>44.000000</td>\n",
              "      <td>36.0</td>\n",
              "      <td>41.733333</td>\n",
              "      <td>18.5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-437565e8-9c7f-49d2-8c6b-5200f70fa843')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-437565e8-9c7f-49d2-8c6b-5200f70fa843 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-437565e8-9c7f-49d2-8c6b-5200f70fa843');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_data = modcloth_preprocessing3[['size', 'height', 'waist', 'hips', 'bra_size', 'bust_size', 'cup_size_in_cms', 'cate_bottoms', 'cate_dresses', 'cate_new', 'cate_outerwear', 'cate_sale', 'cate_tops', 'cate_wedding']]\n",
        "Y_data = modcloth_preprocessing3['fit']"
      ],
      "metadata": {
        "id": "h91e3VDa1LbN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "bIqg8_VkUWis"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "test_size = 0.2 # taking 70:30 training and test set\n",
        "seed = 1  # Random numbmer seeding for reapeatability of the code\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_data, Y_data, test_size=test_size, random_state=seed)\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler() \n",
        "\n",
        "# 교차검증시\n",
        "scaler.fit(X_train)\n",
        "X_train = scaler.transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n"
      ],
      "metadata": {
        "id": "aC4ppc4jJ36_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.value_counts().sort_index()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "InlZKLpIqsFk",
        "outputId": "88753d39-6053-453e-8a3e-5f02ecc80196"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1     7839\n",
              "2    35819\n",
              "3     6737\n",
              "Name: fit, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 데이터 resampling(선택사항.. 하면 결과 더 안좋아지는 경우 존재)"
      ],
      "metadata": {
        "id": "JSid7uSYCHD6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "sm = SMOTE(sampling_strategy = 'auto' ,k_neighbors = 5, random_state=1)   \n",
        "#Synthetic Minority Over Sampling Technique\n",
        "X_train_res, y_train_res = sm.fit_resample(X_train, y_train.ravel())"
      ],
      "metadata": {
        "id": "02qAUaVOqB7A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_y_train_res = pd.DataFrame(y_train_res, columns = ['size'])\n",
        "\n",
        "df_y_train_res.value_counts().sort_index()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GoqZ6PQrxrKe",
        "outputId": "40b11203-3770-4a38-9b29-f7f0cc7b71b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "size\n",
              "0       8293\n",
              "1       8293\n",
              "2       8293\n",
              "3       8293\n",
              "4       8293\n",
              "5       8293\n",
              "6       8293\n",
              "7       8293\n",
              "8       8293\n",
              "9       8293\n",
              "10      8293\n",
              "11      8293\n",
              "12      8293\n",
              "13      8293\n",
              "14      8293\n",
              "15      8293\n",
              "17      8293\n",
              "18      8293\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DMwR::SMOTE(\n",
        "  form,  # 모델 포뮬러\n",
        "  data,  # 포뮬러를 적용할 데이터\n",
        "  perc.over=200,  # 적은 쪽의 데이터를 얼마나 추가로 샘플링해야 하는지\n",
        "  k=5,            # 고려할 최근접 이웃의 수\n",
        "  # 적은 쪽의 데이터를 추가로 샘플링할 때 각 샘플에 대응해서 많은 쪽의 데이터를\n",
        "  # 얼마나 샘플링할지 지정\n",
        "  perc.under=200\n",
        ")\n",
        "#SMOTE 파라미터 설명 http://glemaitre.github.io/imbalanced-learn/generated/imblearn.over_sampling.SMOTE.html"
      ],
      "metadata": {
        "id": "JMN9TA8mp3d4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 로지스틱 회귀"
      ],
      "metadata": {
        "id": "zrB2fMi9CN3_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "log_reg = LogisticRegression(max_iter=500)#multi_class = 'multinomial')\n",
        "log_reg.fit(X_train, y_train)\n",
        "\n",
        "y_pred_logis = log_reg.predict(X_test)"
      ],
      "metadata": {
        "id": "VF9M90R7p3zo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#scaling\n",
        "#참고사이트 : https://mizykk.tistory.com/101\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Normalization 최소값 0 / 최대값 1\n",
        "#scaler = MinMaxScaler()\n",
        "\n",
        "# 교차검증시\n",
        "#scaler.fit(X_train)\n",
        "#X_train = scaler.transform(X_train)\n",
        "#X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "iHvU10IUKWFA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "?LogisticRegression"
      ],
      "metadata": {
        "id": "fq-jWHnXLSK2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "accuracy_score(y_test, y_pred_logis)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UfINRSE-QME7",
        "outputId": "c878f282-dfdd-480a-f3ff-cde3c83206a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6794084821428571"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "metadata": {
        "id": "NcOEE9wzXhOc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print('\\n', classification_report(y_test, y_pred_logis))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k3leZtwTQlbO",
        "outputId": "d8b966ae-d1d7-40c9-9818-f7de5fc0482f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         1\n",
            "           1       0.74      0.18      0.28       159\n",
            "           2       0.00      0.00      0.00         7\n",
            "           3       0.00      0.00      0.00        13\n",
            "           4       0.71      0.81      0.76      1643\n",
            "           5       0.00      0.00      0.00       111\n",
            "           6       0.50      0.04      0.07        84\n",
            "           7       0.00      0.00      0.00       104\n",
            "           8       0.64      0.79      0.71      2065\n",
            "           9       0.00      0.00      0.00        99\n",
            "          10       0.67      0.07      0.13       135\n",
            "          11       0.00      0.00      0.00        48\n",
            "          12       0.69      0.78      0.73      1917\n",
            "          13       0.00      0.00      0.00        45\n",
            "          14       0.00      0.00      0.00        26\n",
            "          15       0.69      0.56      0.62       670\n",
            "          17       0.00      0.00      0.00        12\n",
            "          18       1.00      0.03      0.07        29\n",
            "\n",
            "    accuracy                           0.68      7168\n",
            "   macro avg       0.31      0.18      0.19      7168\n",
            "weighted avg       0.64      0.68      0.64      7168\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test.value_counts().sort_values(ascending = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u4Oe9PWuSTdW",
        "outputId": "445fe16f-a15c-4f36-c632-edd10605169a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8     2065\n",
              "12    1917\n",
              "4     1643\n",
              "15     670\n",
              "1      159\n",
              "10     135\n",
              "5      111\n",
              "7      104\n",
              "9       99\n",
              "6       84\n",
              "11      48\n",
              "13      45\n",
              "18      29\n",
              "14      26\n",
              "3       13\n",
              "17      12\n",
              "2        7\n",
              "0        1\n",
              "Name: size, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_y_train_res.value_counts().sort_values(ascending = False)"
      ],
      "metadata": {
        "id": "IT0-jqnV2swn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22affdfe-3533-4c21-d54f-c854e8e49252"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "size\n",
              "0       8293\n",
              "1       8293\n",
              "2       8293\n",
              "3       8293\n",
              "4       8293\n",
              "5       8293\n",
              "6       8293\n",
              "7       8293\n",
              "8       8293\n",
              "9       8293\n",
              "10      8293\n",
              "11      8293\n",
              "12      8293\n",
              "13      8293\n",
              "14      8293\n",
              "15      8293\n",
              "17      8293\n",
              "18      8293\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "REnAYFCs2s2_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 랜덤 포레스트 적용"
      ],
      "metadata": {
        "id": "IvZ1SF5RFdUH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# model = RandomForestClassifier()\n",
        "\n",
        "model = RandomForestClassifier(n_estimators=500,\n",
        "                               min_samples_split=10, \n",
        "                               n_jobs=-1)\n",
        "\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v-e4XEcc-IC8",
        "outputId": "79653c95-5a9f-42f0-b8f9-7c6f10c6cfde"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(min_samples_split=10, n_estimators=500, n_jobs=-1)"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A7nJyA-9-IHc",
        "outputId": "a2da4104-bac3-4689-9b13-d60485219599"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(min_samples_split=10, n_estimators=500, n_jobs=-1)"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_random = model.predict(X_test)"
      ],
      "metadata": {
        "id": "q6v7lDK1-RO1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "score = accuracy_score(y_test, y_pred_random) * 100\n",
        "score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1vWBgt77-TSe",
        "outputId": "8f7e118e-efc7-4f74-c276-261b535c6cbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "73.28404017857143"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print('\\n', classification_report(y_test, y_pred_random))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yOO3qO2gA4qy",
        "outputId": "f69d41e1-5d3b-40de-d64d-ac01045430ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         1\n",
            "           1       0.75      0.38      0.51       159\n",
            "           2       0.00      0.00      0.00         7\n",
            "           3       0.00      0.00      0.00        13\n",
            "           4       0.77      0.84      0.80      1643\n",
            "           5       0.88      0.14      0.23       111\n",
            "           6       0.75      0.14      0.24        84\n",
            "           7       0.89      0.23      0.37       104\n",
            "           8       0.71      0.81      0.76      2065\n",
            "           9       0.92      0.12      0.21        99\n",
            "          10       0.69      0.20      0.31       135\n",
            "          11       0.57      0.08      0.15        48\n",
            "          12       0.73      0.83      0.78      1917\n",
            "          13       1.00      0.07      0.12        45\n",
            "          14       0.00      0.00      0.00        26\n",
            "          15       0.71      0.66      0.69       670\n",
            "          17       0.00      0.00      0.00        12\n",
            "          18       1.00      0.14      0.24        29\n",
            "\n",
            "    accuracy                           0.73      7168\n",
            "   macro avg       0.58      0.26      0.30      7168\n",
            "weighted avg       0.73      0.73      0.71      7168\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test.value_counts().sort_values(ascending = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fCbsnlEcFycf",
        "outputId": "2c7e1648-dfee-4ac1-fe3e-ebc32301d4b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8     2065\n",
              "12    1917\n",
              "4     1643\n",
              "15     670\n",
              "1      159\n",
              "10     135\n",
              "5      111\n",
              "7      104\n",
              "9       99\n",
              "6       84\n",
              "11      48\n",
              "13      45\n",
              "18      29\n",
              "14      26\n",
              "3       13\n",
              "17      12\n",
              "2        7\n",
              "0        1\n",
              "Name: size, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "w5tZ7eDGFKw7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 학습결과 결정경계 표기"
      ],
      "metadata": {
        "id": "6HDq2JlTFNa8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib.colors import ListedColormap\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def plot_decision_regions(X, y, classifier, test_idx=None, resolution=0.02):\n",
        "\n",
        "    # 마커와 컬러맵을 설정합니다.\n",
        "    markers = ('s', 'x', 'o', '^', 'v')\n",
        "    colors = ('red', 'blue', 'lightgreen', 'gray', 'cyan')\n",
        "    cmap = ListedColormap(colors[:len(np.unique(y))])\n",
        "\n",
        "    # 결정 경계를 그립니다.\n",
        "    x1_min, x1_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
        "    x2_min, x2_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
        "    xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, resolution),\n",
        "                           np.arange(x2_min, x2_max, resolution))\n",
        "    Z = classifier.predict(np.array([xx1.ravel(), xx2.ravel()]).T)\n",
        "    Z = Z.reshape(xx1.shape)\n",
        "    plt.contourf(xx1, xx2, Z, alpha=0.3, cmap=cmap)\n",
        "    plt.xlim(xx1.min(), xx1.max())\n",
        "    plt.ylim(xx2.min(), xx2.max())\n",
        "\n",
        "    for idx, cl in enumerate(np.unique(y)):\n",
        "        plt.scatter(x=X[y == cl, 0], \n",
        "                    y=X[y == cl, 1],\n",
        "                    alpha=0.8, \n",
        "                    c=colors[idx],\n",
        "                    marker=markers[idx], \n",
        "                    label=cl, \n",
        "                    edgecolor='black')\n",
        "\n",
        "    # 테스트 샘플을 부각하여 그립니다.\n",
        "    if test_idx:\n",
        "        # 모든 샘플을 그립니다.\n",
        "        X_test, y_test = X[test_idx, :], y[test_idx]\n",
        "\n",
        "        plt.scatter(X_test[:, 0],\n",
        "                    X_test[:, 1],\n",
        "                    facecolor='none',\n",
        "                    edgecolor='black',\n",
        "                    alpha=1.0,\n",
        "                    linewidth=1,\n",
        "                    marker='o',\n",
        "                    s=100, \n",
        "                    label='test set')"
      ],
      "metadata": {
        "id": "WygSPZW0KXfx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_combined_std = np.vstack((X_train_std, X_test_std))\n",
        "y_combined = np.hstack((y_train, y_test))\n",
        "\n",
        "plot_decision_regions(X=X_combined_std, y=y_combined,\n",
        "                      classifier=ppn, test_idx=range(105, 150))\n",
        "plt.xlabel('petal length [standardized]')\n",
        "plt.ylabel('petal width [standardized]')\n",
        "plt.legend(loc='upper left')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "69DjxnPmKl3b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print('\\n', classification_report(y_test, y_pred_random))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9K8FSlzHFP7P",
        "outputId": "a1d54c71-eb79-4a54-ce95-18d61795eb7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         1\n",
            "           1       0.74      0.37      0.49       159\n",
            "           2       0.00      0.00      0.00         7\n",
            "           3       0.00      0.00      0.00        13\n",
            "           4       0.77      0.84      0.80      1643\n",
            "           5       0.93      0.13      0.22       111\n",
            "           6       0.76      0.15      0.26        84\n",
            "           7       0.86      0.23      0.36       104\n",
            "           8       0.71      0.81      0.76      2065\n",
            "           9       0.92      0.12      0.21        99\n",
            "          10       0.69      0.19      0.29       135\n",
            "          11       0.75      0.06      0.12        48\n",
            "          12       0.73      0.83      0.78      1917\n",
            "          13       1.00      0.07      0.12        45\n",
            "          14       0.00      0.00      0.00        26\n",
            "          15       0.71      0.66      0.68       670\n",
            "          17       0.00      0.00      0.00        12\n",
            "          18       1.00      0.14      0.24        29\n",
            "\n",
            "    accuracy                           0.73      7168\n",
            "   macro avg       0.59      0.26      0.30      7168\n",
            "weighted avg       0.74      0.73      0.71      7168\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 서포트 벡터 머신\n",
        "#비선형 SVM은??"
      ],
      "metadata": {
        "id": "51bj6rT1KcrB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "svm = SVC(kernel='linear', C=1.0, random_state=1)\n",
        "svm.fit(X_train, y_train)\n",
        "\n",
        "#plot_decision_regions(X_combined_std, \n",
        "#                      y_combined,\n",
        "#                      classifier=svm, \n",
        "#                      test_idx=range(105, 150))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NYBbgrFkFQHS",
        "outputId": "fb80771e-82eb-426f-f387-11c122f9637d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(kernel='linear', random_state=1)"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_svc = svm.predict(X_test)\n",
        "\n",
        "\n",
        "score_svc = accuracy_score(y_test, y_pred_svc) * 100\n",
        "score_svc\n",
        "\n",
        "\n",
        "print('\\n', classification_report(y_test, y_pred_svc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dFKz_ETVFQL2",
        "outputId": "097e778f-e5a6-4a5c-8be4-2e4126e1ed26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         1\n",
            "           1       0.00      0.00      0.00       159\n",
            "           2       0.00      0.00      0.00         7\n",
            "           3       0.00      0.00      0.00        13\n",
            "           4       0.70      0.82      0.76      1643\n",
            "           5       0.00      0.00      0.00       111\n",
            "           6       0.00      0.00      0.00        84\n",
            "           7       0.00      0.00      0.00       104\n",
            "           8       0.65      0.78      0.71      2065\n",
            "           9       0.00      0.00      0.00        99\n",
            "          10       0.00      0.00      0.00       135\n",
            "          11       0.00      0.00      0.00        48\n",
            "          12       0.69      0.79      0.74      1917\n",
            "          13       0.00      0.00      0.00        45\n",
            "          14       0.00      0.00      0.00        26\n",
            "          15       0.69      0.58      0.63       670\n",
            "          17       0.00      0.00      0.00        12\n",
            "          18       0.00      0.00      0.00        29\n",
            "\n",
            "    accuracy                           0.68      7168\n",
            "   macro avg       0.15      0.17      0.16      7168\n",
            "weighted avg       0.60      0.68      0.63      7168\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 결정트리"
      ],
      "metadata": {
        "id": "VGmrv14UFa5i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "tree_model = DecisionTreeClassifier(criterion='gini', \n",
        "                                    max_depth=9, \n",
        "                                    random_state=1)\n",
        "tree_model.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-oY89dW-Fa_k",
        "outputId": "71ea88d5-429d-46d1-b8c2-59857bf1da77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier(max_depth=9, random_state=1)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_tree = tree_model.predict(X_test)\n",
        "\n",
        "\n",
        "score_tree = accuracy_score(y_test, y_pred_tree) * 100\n",
        "score_tree\n",
        "\n",
        "\n",
        "print('\\n', classification_report(y_test, y_pred_tree))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UQtmv6xyO-9V",
        "outputId": "f3d61005-50fd-427b-d988-8730f96a6faf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "72.36328125"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 퍼셉트론"
      ],
      "metadata": {
        "id": "9f_T8XF66lTu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import Perceptron"
      ],
      "metadata": {
        "id": "2DLaHDB_6qsS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ppn = Perceptron(max_iter=40, eta0=0.1, tol=1e-3, random_state=1) \n",
        "ppn = Perceptron()\n",
        "ppn.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2uBMc7I6r_K",
        "outputId": "1975c4ad-be7f-47cf-d953-1ab7e90876a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Perceptron()"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_ppn = ppn.predict(X_test)\n",
        "\n",
        "score_ppn = accuracy_score(y_test, y_pred_ppn) * 100\n",
        "score_ppn\n",
        "\n",
        "\n",
        "print('\\n', classification_report(y_test, y_pred_ppn))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pfpa01R_6q4g",
        "outputId": "8c315cc2-d81c-495e-ec2f-fe0a5be1e530"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         1\n",
            "           1       0.00      0.00      0.00       159\n",
            "           2       0.00      0.00      0.00         7\n",
            "           3       0.00      0.00      0.00        13\n",
            "           4       0.55      0.81      0.65      1643\n",
            "           5       0.03      0.06      0.04       111\n",
            "           6       0.00      0.00      0.00        84\n",
            "           7       0.03      0.03      0.03       104\n",
            "           8       0.44      0.27      0.34      2065\n",
            "           9       0.00      0.00      0.00        99\n",
            "          10       0.33      0.01      0.01       135\n",
            "          11       0.04      0.25      0.07        48\n",
            "          12       0.53      0.56      0.55      1917\n",
            "          13       0.00      0.00      0.00        45\n",
            "          14       0.00      0.00      0.00        26\n",
            "          15       0.51      0.22      0.31       670\n",
            "          17       0.00      0.00      0.00        12\n",
            "          18       0.04      0.76      0.08        29\n",
            "\n",
            "    accuracy                           0.44      7168\n",
            "   macro avg       0.14      0.17      0.12      7168\n",
            "weighted avg       0.45      0.44      0.42      7168\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 딥러닝 관련 import"
      ],
      "metadata": {
        "id": "x5IggBBW_UJj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense # 은닉층 하나씩 정의\n",
        "from tensorflow.keras.optimizers import SGD # 역전파시 사용하는 최적화 알고리즘\n",
        "from tensorflow.keras.losses import mse # y가 수치형인 경우, 성능지표\n",
        "\n",
        "tf.random.set_seed(1234) #random seed 설정"
      ],
      "metadata": {
        "id": "JEnEgCT1_ZgS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ANN"
      ],
      "metadata": {
        "id": "Ylnb0mrS9NB2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 인공신경망 모형 구성(퍼셉트론)\n",
        "model = Sequential()\n",
        "model.add(Dense(4, input_shape = (13, ), activation = 'linear')) #Dense 함수가 은닉층을 표현, input shape 는 은닉층의 입력, x 변수가 두개임을 선언, 첫번째 은닉층은 노드가 3개\n",
        "model.add(Dense(2, activation = 'linear')) #앞에서 이미 은닉층 입력을 지정했으므로 두번째 은닉층은 이전의 input shape x 변수는 2개 동일함\n",
        "model.add(Dense(1, activation = 'linear')) #앞에서 이미 은닉층 입력을 지정했으므로 두번째 은닉층은 이전의 input shape x 변수는 2개 동일함\n",
        "\n",
        "#모형 컴파일\n",
        "model.compile(optimizer = 'SGD', loss = mse, metrics = ['acc']) #평가지표 설정\n",
        "#모형 학습 및 가중치 확인\n",
        "model.fit(X_train,y_train,epochs = 10)\n",
        "model.get_weights() #인공신경망 구성하는 각각의 가중치(2*3 = 6개의 가중치, 그다음 배열은 bias, 첫번째 은닉층에서 두번째 은닉층으로의 가중치 3개, 그 다음 배열은 bias로 총 4개의 배열)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Xlh7ZTI9QJ_",
        "outputId": "444fee61-b503-4812-8beb-aa7f7fafa7c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "896/896 [==============================] - 3s 2ms/step - loss: 4.8035 - acc: 0.0279\n",
            "Epoch 2/10\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 4.1395 - acc: 0.0280\n",
            "Epoch 3/10\n",
            "896/896 [==============================] - 1s 2ms/step - loss: 4.0990 - acc: 0.0280\n",
            "Epoch 4/10\n",
            "896/896 [==============================] - 1s 1ms/step - loss: 4.0873 - acc: 0.0280\n",
            "Epoch 5/10\n",
            "896/896 [==============================] - 1s 1ms/step - loss: 4.0761 - acc: 0.0279\n",
            "Epoch 6/10\n",
            "896/896 [==============================] - 1s 1ms/step - loss: 4.0821 - acc: 0.0280\n",
            "Epoch 7/10\n",
            "896/896 [==============================] - 1s 1ms/step - loss: 4.0720 - acc: 0.0280\n",
            "Epoch 8/10\n",
            "896/896 [==============================] - 1s 1ms/step - loss: 4.0383 - acc: 0.0280\n",
            "Epoch 9/10\n",
            "896/896 [==============================] - 1s 1ms/step - loss: 4.0420 - acc: 0.0280\n",
            "Epoch 10/10\n",
            "896/896 [==============================] - 1s 1ms/step - loss: 4.0417 - acc: 0.0280\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[ 0.09515595, -0.15785068,  0.2927242 ,  0.19948037],\n",
              "        [-0.3130962 , -0.210717  ,  0.2742957 , -0.38431007],\n",
              "        [ 0.0550359 ,  0.1450967 ,  0.53900254,  0.10460538],\n",
              "        [-0.19605368, -0.12739864,  0.2948675 , -0.30061027],\n",
              "        [-0.87825185,  0.23266393,  1.2126726 , -0.36638924],\n",
              "        [-0.13261151, -0.23254238,  0.14286985, -0.05024193],\n",
              "        [-0.11856927,  0.05006108,  0.11007696, -0.22091284],\n",
              "        [ 0.28775868, -0.35263714,  0.2571485 , -0.29493466],\n",
              "        [-0.21059862, -0.035082  ,  0.17928377, -0.23786084],\n",
              "        [-0.01230456,  0.05220146,  0.06849255, -0.32166082],\n",
              "        [ 0.16143246, -0.27261963,  0.22917427,  0.05175973],\n",
              "        [-0.18853676, -0.3709466 ,  0.14753501,  0.1545451 ],\n",
              "        [ 0.00654675,  0.07335532, -0.06558601,  0.05718767]],\n",
              "       dtype=float32),\n",
              " array([-0.6060004 ,  0.42394677,  0.7516385 , -0.063312  ], dtype=float32),\n",
              " array([[ 0.42201507,  0.2199035 ],\n",
              "        [-0.03214638, -0.14772089],\n",
              "        [-0.6961151 , -0.00971379],\n",
              "        [ 0.24967997, -0.13975914]], dtype=float32),\n",
              " array([-2.8779814 , -0.32993096], dtype=float32),\n",
              " array([[-1.4696056 ],\n",
              "        [-0.18461014]], dtype=float32),\n",
              " array([3.1168728], dtype=float32)]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "VdYIAEtA9QX7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DNN"
      ],
      "metadata": {
        "id": "ctAUgY48Z2yi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "y_train_cate = to_categorical(y_train)\n",
        "y_test_cate = to_categorical(y_test)\n",
        "\n"
      ],
      "metadata": {
        "id": "ZPOu3x-IfHgH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 인공신경망 모형 구성(퍼셉트론)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(256, activation = 'relu', input_shape = (13, ) ) ) \n",
        "model.add(Dense(128, activation = 'relu', input_shape = (13, ) ) ) \n",
        "model.add(Dense(64, activation = 'relu' ) ) \n",
        "model.add(Dense(32, activation = 'relu' ) )\n",
        "model.add(Dense(19, activation = 'softmax')) \n",
        "\n",
        "\n",
        "#모형 컴파일\n",
        "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['acc'])\n",
        "#모형 학습 및 가중치 확인\n",
        "history = model.fit(X_train, y_train_cate, epochs = 3000)#,\n",
        "                    #batch_size = 128, validation_data = (x_val,y_val))\n",
        "\n",
        "#model.fit(X_train,y_train,epochs = 10)\n",
        "#model.get_weights() #인공신경망 구성하는 각각의 가중치(2*3 = 6개의 가중치, 그다음 배열은 bias, 첫번째 은닉층에서 두번째 은닉층으로의 가중치 3개, 그 다음 배열은 bias로 총 4개의 배열)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hg3RRJJvZ5qd",
        "outputId": "ca3c044a-1481-4c62-a3a7-3772f08628a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43m스트리밍 출력 내용이 길어서 마지막 5000줄이 삭제되었습니다.\u001b[0m\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2637 - acc: 0.8993\n",
            "Epoch 502/3000\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2605 - acc: 0.9003\n",
            "Epoch 503/3000\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2410 - acc: 0.9075\n",
            "Epoch 504/3000\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2605 - acc: 0.8998\n",
            "Epoch 505/3000\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2543 - acc: 0.9041\n",
            "Epoch 506/3000\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2580 - acc: 0.9006\n",
            "Epoch 507/3000\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2835 - acc: 0.8941\n",
            "Epoch 508/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2448 - acc: 0.9075\n",
            "Epoch 509/3000\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2511 - acc: 0.9038\n",
            "Epoch 510/3000\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2467 - acc: 0.9043\n",
            "Epoch 511/3000\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2659 - acc: 0.9011\n",
            "Epoch 512/3000\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2557 - acc: 0.9035\n",
            "Epoch 513/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2517 - acc: 0.9045\n",
            "Epoch 514/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2788 - acc: 0.8992\n",
            "Epoch 515/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2644 - acc: 0.9012\n",
            "Epoch 516/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2560 - acc: 0.9017\n",
            "Epoch 517/3000\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2433 - acc: 0.9070\n",
            "Epoch 518/3000\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2550 - acc: 0.9038\n",
            "Epoch 519/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2650 - acc: 0.8987\n",
            "Epoch 520/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2517 - acc: 0.9039\n",
            "Epoch 521/3000\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2707 - acc: 0.8997\n",
            "Epoch 522/3000\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2524 - acc: 0.9027\n",
            "Epoch 523/3000\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2507 - acc: 0.9045\n",
            "Epoch 524/3000\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2640 - acc: 0.9011\n",
            "Epoch 525/3000\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2652 - acc: 0.9002\n",
            "Epoch 526/3000\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2487 - acc: 0.9035\n",
            "Epoch 527/3000\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2400 - acc: 0.9068\n",
            "Epoch 528/3000\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2645 - acc: 0.8995\n",
            "Epoch 529/3000\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2587 - acc: 0.9028\n",
            "Epoch 530/3000\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2469 - acc: 0.9044\n",
            "Epoch 531/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2732 - acc: 0.8987\n",
            "Epoch 532/3000\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2510 - acc: 0.9025\n",
            "Epoch 533/3000\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2444 - acc: 0.9060\n",
            "Epoch 534/3000\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2547 - acc: 0.9020\n",
            "Epoch 535/3000\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2536 - acc: 0.9033\n",
            "Epoch 536/3000\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2591 - acc: 0.9005\n",
            "Epoch 537/3000\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2503 - acc: 0.9040\n",
            "Epoch 538/3000\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2578 - acc: 0.9029\n",
            "Epoch 539/3000\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2702 - acc: 0.8981\n",
            "Epoch 540/3000\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2422 - acc: 0.9065\n",
            "Epoch 541/3000\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2456 - acc: 0.9050\n",
            "Epoch 542/3000\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2658 - acc: 0.9009\n",
            "Epoch 543/3000\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2493 - acc: 0.9045\n",
            "Epoch 544/3000\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2551 - acc: 0.9043\n",
            "Epoch 545/3000\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2519 - acc: 0.9028\n",
            "Epoch 546/3000\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2551 - acc: 0.9042\n",
            "Epoch 547/3000\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2445 - acc: 0.9065\n",
            "Epoch 548/3000\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2694 - acc: 0.9004\n",
            "Epoch 549/3000\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2408 - acc: 0.9076\n",
            "Epoch 550/3000\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2676 - acc: 0.9023\n",
            "Epoch 551/3000\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2590 - acc: 0.9020\n",
            "Epoch 552/3000\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2446 - acc: 0.9055\n",
            "Epoch 553/3000\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2456 - acc: 0.9071\n",
            "Epoch 554/3000\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2581 - acc: 0.9031\n",
            "Epoch 555/3000\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2571 - acc: 0.9040\n",
            "Epoch 556/3000\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2534 - acc: 0.9031\n",
            "Epoch 557/3000\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2517 - acc: 0.9039\n",
            "Epoch 558/3000\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2395 - acc: 0.9098\n",
            "Epoch 559/3000\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2675 - acc: 0.8991\n",
            "Epoch 560/3000\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2478 - acc: 0.9044\n",
            "Epoch 561/3000\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2459 - acc: 0.9064\n",
            "Epoch 562/3000\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2416 - acc: 0.9070\n",
            "Epoch 563/3000\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2578 - acc: 0.9018\n",
            "Epoch 564/3000\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2467 - acc: 0.9053\n",
            "Epoch 565/3000\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2566 - acc: 0.9018\n",
            "Epoch 566/3000\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2611 - acc: 0.9028\n",
            "Epoch 567/3000\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2470 - acc: 0.9064\n",
            "Epoch 568/3000\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2459 - acc: 0.9078\n",
            "Epoch 569/3000\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2358 - acc: 0.9088\n",
            "Epoch 570/3000\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2555 - acc: 0.9033\n",
            "Epoch 571/3000\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2452 - acc: 0.9061\n",
            "Epoch 572/3000\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2466 - acc: 0.9063\n",
            "Epoch 573/3000\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2472 - acc: 0.9051\n",
            "Epoch 574/3000\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2575 - acc: 0.9006\n",
            "Epoch 575/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2503 - acc: 0.9056\n",
            "Epoch 576/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2487 - acc: 0.9061\n",
            "Epoch 577/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2524 - acc: 0.9043\n",
            "Epoch 578/3000\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2462 - acc: 0.9080\n",
            "Epoch 579/3000\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2435 - acc: 0.9088\n",
            "Epoch 580/3000\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2415 - acc: 0.9103\n",
            "Epoch 581/3000\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2556 - acc: 0.9046\n",
            "Epoch 582/3000\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2403 - acc: 0.9081\n",
            "Epoch 583/3000\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2372 - acc: 0.9101\n",
            "Epoch 584/3000\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2550 - acc: 0.9039\n",
            "Epoch 585/3000\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2501 - acc: 0.9048\n",
            "Epoch 586/3000\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2430 - acc: 0.9069\n",
            "Epoch 587/3000\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2443 - acc: 0.9084\n",
            "Epoch 588/3000\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2626 - acc: 0.8992\n",
            "Epoch 589/3000\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2424 - acc: 0.9073\n",
            "Epoch 590/3000\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2333 - acc: 0.9112\n",
            "Epoch 591/3000\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2375 - acc: 0.9082\n",
            "Epoch 592/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2623 - acc: 0.9012\n",
            "Epoch 593/3000\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2836 - acc: 0.8990\n",
            "Epoch 594/3000\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2334 - acc: 0.9103\n",
            "Epoch 595/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2447 - acc: 0.9068\n",
            "Epoch 596/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2309 - acc: 0.9096\n",
            "Epoch 597/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2355 - acc: 0.9093\n",
            "Epoch 598/3000\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2532 - acc: 0.9043\n",
            "Epoch 599/3000\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2508 - acc: 0.9045\n",
            "Epoch 600/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2475 - acc: 0.9086\n",
            "Epoch 601/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2451 - acc: 0.9074\n",
            "Epoch 602/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2402 - acc: 0.9075\n",
            "Epoch 603/3000\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2381 - acc: 0.9103\n",
            "Epoch 604/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2456 - acc: 0.9076\n",
            "Epoch 605/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2410 - acc: 0.9091\n",
            "Epoch 606/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2620 - acc: 0.9043\n",
            "Epoch 607/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2420 - acc: 0.9086\n",
            "Epoch 608/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2328 - acc: 0.9123\n",
            "Epoch 609/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2491 - acc: 0.9077\n",
            "Epoch 610/3000\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2642 - acc: 0.8995\n",
            "Epoch 611/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2323 - acc: 0.9112\n",
            "Epoch 612/3000\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2297 - acc: 0.9123\n",
            "Epoch 613/3000\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2583 - acc: 0.9045\n",
            "Epoch 614/3000\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2451 - acc: 0.9080\n",
            "Epoch 615/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2259 - acc: 0.9123\n",
            "Epoch 616/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2489 - acc: 0.9072\n",
            "Epoch 617/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2509 - acc: 0.9044\n",
            "Epoch 618/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2534 - acc: 0.9052\n",
            "Epoch 619/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2368 - acc: 0.9103\n",
            "Epoch 620/3000\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2291 - acc: 0.9119\n",
            "Epoch 621/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2500 - acc: 0.9084\n",
            "Epoch 622/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2439 - acc: 0.9082\n",
            "Epoch 623/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2472 - acc: 0.9050\n",
            "Epoch 624/3000\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2451 - acc: 0.9083\n",
            "Epoch 625/3000\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2361 - acc: 0.9103\n",
            "Epoch 626/3000\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2448 - acc: 0.9080\n",
            "Epoch 627/3000\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2410 - acc: 0.9078\n",
            "Epoch 628/3000\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2313 - acc: 0.9105\n",
            "Epoch 629/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2294 - acc: 0.9133\n",
            "Epoch 630/3000\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2409 - acc: 0.9101\n",
            "Epoch 631/3000\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2425 - acc: 0.9111\n",
            "Epoch 632/3000\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2386 - acc: 0.9086\n",
            "Epoch 633/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2366 - acc: 0.9103\n",
            "Epoch 634/3000\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2497 - acc: 0.9065\n",
            "Epoch 635/3000\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2348 - acc: 0.9115\n",
            "Epoch 636/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2255 - acc: 0.9159\n",
            "Epoch 637/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2356 - acc: 0.9099\n",
            "Epoch 638/3000\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2505 - acc: 0.9052\n",
            "Epoch 639/3000\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2420 - acc: 0.9070\n",
            "Epoch 640/3000\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2295 - acc: 0.9126\n",
            "Epoch 641/3000\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2355 - acc: 0.9102\n",
            "Epoch 642/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2301 - acc: 0.9118\n",
            "Epoch 643/3000\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2343 - acc: 0.9104\n",
            "Epoch 644/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2477 - acc: 0.9045\n",
            "Epoch 645/3000\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2418 - acc: 0.9102\n",
            "Epoch 646/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2338 - acc: 0.9108\n",
            "Epoch 647/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2409 - acc: 0.9069\n",
            "Epoch 648/3000\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2340 - acc: 0.9088\n",
            "Epoch 649/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2283 - acc: 0.9136\n",
            "Epoch 650/3000\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2347 - acc: 0.9118\n",
            "Epoch 651/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2512 - acc: 0.9067\n",
            "Epoch 652/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2327 - acc: 0.9107\n",
            "Epoch 653/3000\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2355 - acc: 0.9118\n",
            "Epoch 654/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2414 - acc: 0.9082\n",
            "Epoch 655/3000\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2376 - acc: 0.9106\n",
            "Epoch 656/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2314 - acc: 0.9113\n",
            "Epoch 657/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2297 - acc: 0.9116\n",
            "Epoch 658/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2437 - acc: 0.9074\n",
            "Epoch 659/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2564 - acc: 0.9042\n",
            "Epoch 660/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2274 - acc: 0.9145\n",
            "Epoch 661/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2427 - acc: 0.9083\n",
            "Epoch 662/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2786 - acc: 0.8990\n",
            "Epoch 663/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2397 - acc: 0.9092\n",
            "Epoch 664/3000\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2336 - acc: 0.9111\n",
            "Epoch 665/3000\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2207 - acc: 0.9153\n",
            "Epoch 666/3000\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2228 - acc: 0.9141\n",
            "Epoch 667/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2380 - acc: 0.9077\n",
            "Epoch 668/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2499 - acc: 0.9055\n",
            "Epoch 669/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2392 - acc: 0.9108\n",
            "Epoch 670/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2207 - acc: 0.9162\n",
            "Epoch 671/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2409 - acc: 0.9083\n",
            "Epoch 672/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2292 - acc: 0.9123\n",
            "Epoch 673/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2364 - acc: 0.9114\n",
            "Epoch 674/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2330 - acc: 0.9108\n",
            "Epoch 675/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2255 - acc: 0.9136\n",
            "Epoch 676/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2707 - acc: 0.9031\n",
            "Epoch 677/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2622 - acc: 0.9041\n",
            "Epoch 678/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2250 - acc: 0.9151\n",
            "Epoch 679/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2294 - acc: 0.9142\n",
            "Epoch 680/3000\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2204 - acc: 0.9155\n",
            "Epoch 681/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2338 - acc: 0.9145\n",
            "Epoch 682/3000\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2429 - acc: 0.9074\n",
            "Epoch 683/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2299 - acc: 0.9131\n",
            "Epoch 684/3000\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2279 - acc: 0.9136\n",
            "Epoch 685/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2356 - acc: 0.9110\n",
            "Epoch 686/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2453 - acc: 0.9095\n",
            "Epoch 687/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2464 - acc: 0.9071\n",
            "Epoch 688/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2348 - acc: 0.9115\n",
            "Epoch 689/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2511 - acc: 0.9094\n",
            "Epoch 690/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2260 - acc: 0.9154\n",
            "Epoch 691/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2281 - acc: 0.9134\n",
            "Epoch 692/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2279 - acc: 0.9118\n",
            "Epoch 693/3000\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2468 - acc: 0.9082\n",
            "Epoch 694/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2201 - acc: 0.9154\n",
            "Epoch 695/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2283 - acc: 0.9135\n",
            "Epoch 696/3000\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2326 - acc: 0.9154\n",
            "Epoch 697/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2487 - acc: 0.9087\n",
            "Epoch 698/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2434 - acc: 0.9098\n",
            "Epoch 699/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2334 - acc: 0.9133\n",
            "Epoch 700/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2183 - acc: 0.9160\n",
            "Epoch 701/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2266 - acc: 0.9128\n",
            "Epoch 702/3000\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2489 - acc: 0.9079\n",
            "Epoch 703/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2305 - acc: 0.9131\n",
            "Epoch 704/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2180 - acc: 0.9164\n",
            "Epoch 705/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2238 - acc: 0.9154\n",
            "Epoch 706/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2505 - acc: 0.9065\n",
            "Epoch 707/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2271 - acc: 0.9132\n",
            "Epoch 708/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2321 - acc: 0.9113\n",
            "Epoch 709/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2373 - acc: 0.9107\n",
            "Epoch 710/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2276 - acc: 0.9135\n",
            "Epoch 711/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2171 - acc: 0.9178\n",
            "Epoch 712/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2552 - acc: 0.9059\n",
            "Epoch 713/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2245 - acc: 0.9148\n",
            "Epoch 714/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2253 - acc: 0.9146\n",
            "Epoch 715/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2500 - acc: 0.9068\n",
            "Epoch 716/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2219 - acc: 0.9157\n",
            "Epoch 717/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2280 - acc: 0.9146\n",
            "Epoch 718/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2411 - acc: 0.9102\n",
            "Epoch 719/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2448 - acc: 0.9108\n",
            "Epoch 720/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2521 - acc: 0.9075\n",
            "Epoch 721/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2093 - acc: 0.9199\n",
            "Epoch 722/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2211 - acc: 0.9172\n",
            "Epoch 723/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2274 - acc: 0.9131\n",
            "Epoch 724/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2366 - acc: 0.9116\n",
            "Epoch 725/3000\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2346 - acc: 0.9129\n",
            "Epoch 726/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2302 - acc: 0.9124\n",
            "Epoch 727/3000\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2140 - acc: 0.9174\n",
            "Epoch 728/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2453 - acc: 0.9082\n",
            "Epoch 729/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2370 - acc: 0.9122\n",
            "Epoch 730/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2450 - acc: 0.9083\n",
            "Epoch 731/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2182 - acc: 0.9154\n",
            "Epoch 732/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2328 - acc: 0.9112\n",
            "Epoch 733/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2229 - acc: 0.9151\n",
            "Epoch 734/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2303 - acc: 0.9146\n",
            "Epoch 735/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2405 - acc: 0.9109\n",
            "Epoch 736/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2269 - acc: 0.9156\n",
            "Epoch 737/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2256 - acc: 0.9146\n",
            "Epoch 738/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2307 - acc: 0.9142\n",
            "Epoch 739/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2226 - acc: 0.9152\n",
            "Epoch 740/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2136 - acc: 0.9164\n",
            "Epoch 741/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2507 - acc: 0.9061\n",
            "Epoch 742/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2276 - acc: 0.9132\n",
            "Epoch 743/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2425 - acc: 0.9087\n",
            "Epoch 744/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2237 - acc: 0.9161\n",
            "Epoch 745/3000\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2688 - acc: 0.9060\n",
            "Epoch 746/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2208 - acc: 0.9173\n",
            "Epoch 747/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2126 - acc: 0.9189\n",
            "Epoch 748/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2288 - acc: 0.9140\n",
            "Epoch 749/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2334 - acc: 0.9130\n",
            "Epoch 750/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2347 - acc: 0.9117\n",
            "Epoch 751/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2364 - acc: 0.9119\n",
            "Epoch 752/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2227 - acc: 0.9134\n",
            "Epoch 753/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2161 - acc: 0.9162\n",
            "Epoch 754/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2410 - acc: 0.9121\n",
            "Epoch 755/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2604 - acc: 0.9050\n",
            "Epoch 756/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2163 - acc: 0.9167\n",
            "Epoch 757/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2188 - acc: 0.9152\n",
            "Epoch 758/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2512 - acc: 0.9095\n",
            "Epoch 759/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2253 - acc: 0.9131\n",
            "Epoch 760/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2499 - acc: 0.9074\n",
            "Epoch 761/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2151 - acc: 0.9191\n",
            "Epoch 762/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2285 - acc: 0.9152\n",
            "Epoch 763/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2318 - acc: 0.9133\n",
            "Epoch 764/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2447 - acc: 0.9091\n",
            "Epoch 765/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2258 - acc: 0.9147\n",
            "Epoch 766/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2338 - acc: 0.9109\n",
            "Epoch 767/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2101 - acc: 0.9197\n",
            "Epoch 768/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2356 - acc: 0.9099\n",
            "Epoch 769/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2277 - acc: 0.9152\n",
            "Epoch 770/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2415 - acc: 0.9077\n",
            "Epoch 771/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2364 - acc: 0.9098\n",
            "Epoch 772/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2538 - acc: 0.9061\n",
            "Epoch 773/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2140 - acc: 0.9190\n",
            "Epoch 774/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2080 - acc: 0.9189\n",
            "Epoch 775/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2157 - acc: 0.9172\n",
            "Epoch 776/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2382 - acc: 0.9127\n",
            "Epoch 777/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2341 - acc: 0.9126\n",
            "Epoch 778/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2600 - acc: 0.9044\n",
            "Epoch 779/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2154 - acc: 0.9171\n",
            "Epoch 780/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2266 - acc: 0.9145\n",
            "Epoch 781/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2092 - acc: 0.9200\n",
            "Epoch 782/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2420 - acc: 0.9103\n",
            "Epoch 783/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2411 - acc: 0.9101\n",
            "Epoch 784/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2044 - acc: 0.9226\n",
            "Epoch 785/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2461 - acc: 0.9085\n",
            "Epoch 786/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2190 - acc: 0.9156\n",
            "Epoch 787/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2197 - acc: 0.9161\n",
            "Epoch 788/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2317 - acc: 0.9134\n",
            "Epoch 789/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2186 - acc: 0.9183\n",
            "Epoch 790/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2260 - acc: 0.9141\n",
            "Epoch 791/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2224 - acc: 0.9163\n",
            "Epoch 792/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2434 - acc: 0.9087\n",
            "Epoch 793/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2152 - acc: 0.9165\n",
            "Epoch 794/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2162 - acc: 0.9187\n",
            "Epoch 795/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2353 - acc: 0.9114\n",
            "Epoch 796/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2229 - acc: 0.9150\n",
            "Epoch 797/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2141 - acc: 0.9186\n",
            "Epoch 798/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2239 - acc: 0.9151\n",
            "Epoch 799/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2411 - acc: 0.9128\n",
            "Epoch 800/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2145 - acc: 0.9177\n",
            "Epoch 801/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2234 - acc: 0.9156\n",
            "Epoch 802/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2188 - acc: 0.9169\n",
            "Epoch 803/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2315 - acc: 0.9118\n",
            "Epoch 804/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2196 - acc: 0.9177\n",
            "Epoch 805/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2473 - acc: 0.9096\n",
            "Epoch 806/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2110 - acc: 0.9180\n",
            "Epoch 807/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2368 - acc: 0.9128\n",
            "Epoch 808/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2298 - acc: 0.9156\n",
            "Epoch 809/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2175 - acc: 0.9170\n",
            "Epoch 810/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2246 - acc: 0.9144\n",
            "Epoch 811/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2437 - acc: 0.9118\n",
            "Epoch 812/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2198 - acc: 0.9175\n",
            "Epoch 813/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2390 - acc: 0.9111\n",
            "Epoch 814/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2190 - acc: 0.9155\n",
            "Epoch 815/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2071 - acc: 0.9209\n",
            "Epoch 816/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2344 - acc: 0.9135\n",
            "Epoch 817/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2376 - acc: 0.9121\n",
            "Epoch 818/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2128 - acc: 0.9184\n",
            "Epoch 819/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2227 - acc: 0.9143\n",
            "Epoch 820/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2192 - acc: 0.9147\n",
            "Epoch 821/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2291 - acc: 0.9147\n",
            "Epoch 822/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2524 - acc: 0.9079\n",
            "Epoch 823/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2181 - acc: 0.9173\n",
            "Epoch 824/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2137 - acc: 0.9185\n",
            "Epoch 825/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2168 - acc: 0.9174\n",
            "Epoch 826/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2102 - acc: 0.9186\n",
            "Epoch 827/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2515 - acc: 0.9110\n",
            "Epoch 828/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2260 - acc: 0.9146\n",
            "Epoch 829/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2128 - acc: 0.9202\n",
            "Epoch 830/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2353 - acc: 0.9125\n",
            "Epoch 831/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2338 - acc: 0.9131\n",
            "Epoch 832/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2031 - acc: 0.9210\n",
            "Epoch 833/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2262 - acc: 0.9154\n",
            "Epoch 834/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2118 - acc: 0.9194\n",
            "Epoch 835/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2287 - acc: 0.9158\n",
            "Epoch 836/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2440 - acc: 0.9104\n",
            "Epoch 837/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2166 - acc: 0.9175\n",
            "Epoch 838/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2350 - acc: 0.9139\n",
            "Epoch 839/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2444 - acc: 0.9097\n",
            "Epoch 840/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2213 - acc: 0.9169\n",
            "Epoch 841/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2145 - acc: 0.9199\n",
            "Epoch 842/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2285 - acc: 0.9145\n",
            "Epoch 843/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2181 - acc: 0.9158\n",
            "Epoch 844/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2508 - acc: 0.9118\n",
            "Epoch 845/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2037 - acc: 0.9217\n",
            "Epoch 846/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2182 - acc: 0.9177\n",
            "Epoch 847/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2397 - acc: 0.9111\n",
            "Epoch 848/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2285 - acc: 0.9165\n",
            "Epoch 849/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2167 - acc: 0.9172\n",
            "Epoch 850/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2070 - acc: 0.9207\n",
            "Epoch 851/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2281 - acc: 0.9165\n",
            "Epoch 852/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2213 - acc: 0.9151\n",
            "Epoch 853/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2070 - acc: 0.9202\n",
            "Epoch 854/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2466 - acc: 0.9109\n",
            "Epoch 855/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2207 - acc: 0.9166\n",
            "Epoch 856/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2436 - acc: 0.9122\n",
            "Epoch 857/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2344 - acc: 0.9120\n",
            "Epoch 858/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2192 - acc: 0.9157\n",
            "Epoch 859/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2516 - acc: 0.9114\n",
            "Epoch 860/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2227 - acc: 0.9179\n",
            "Epoch 861/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2032 - acc: 0.9205\n",
            "Epoch 862/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2178 - acc: 0.9188\n",
            "Epoch 863/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2174 - acc: 0.9165\n",
            "Epoch 864/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2327 - acc: 0.9134\n",
            "Epoch 865/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2149 - acc: 0.9216\n",
            "Epoch 866/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2148 - acc: 0.9181\n",
            "Epoch 867/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2371 - acc: 0.9119\n",
            "Epoch 868/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2174 - acc: 0.9171\n",
            "Epoch 869/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2151 - acc: 0.9166\n",
            "Epoch 870/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2183 - acc: 0.9169\n",
            "Epoch 871/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2190 - acc: 0.9183\n",
            "Epoch 872/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2170 - acc: 0.9178\n",
            "Epoch 873/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2103 - acc: 0.9186\n",
            "Epoch 874/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2249 - acc: 0.9150\n",
            "Epoch 875/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2218 - acc: 0.9170\n",
            "Epoch 876/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2279 - acc: 0.9145\n",
            "Epoch 877/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2225 - acc: 0.9164\n",
            "Epoch 878/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2119 - acc: 0.9210\n",
            "Epoch 879/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2528 - acc: 0.9126\n",
            "Epoch 880/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2123 - acc: 0.9185\n",
            "Epoch 881/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2063 - acc: 0.9226\n",
            "Epoch 882/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2349 - acc: 0.9159\n",
            "Epoch 883/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2128 - acc: 0.9211\n",
            "Epoch 884/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2254 - acc: 0.9172\n",
            "Epoch 885/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2093 - acc: 0.9194\n",
            "Epoch 886/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2385 - acc: 0.9121\n",
            "Epoch 887/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2189 - acc: 0.9182\n",
            "Epoch 888/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2211 - acc: 0.9169\n",
            "Epoch 889/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2082 - acc: 0.9200\n",
            "Epoch 890/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2531 - acc: 0.9094\n",
            "Epoch 891/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2133 - acc: 0.9202\n",
            "Epoch 892/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2318 - acc: 0.9121\n",
            "Epoch 893/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2053 - acc: 0.9216\n",
            "Epoch 894/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2164 - acc: 0.9182\n",
            "Epoch 895/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2066 - acc: 0.9208\n",
            "Epoch 896/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2464 - acc: 0.9101\n",
            "Epoch 897/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2178 - acc: 0.9184\n",
            "Epoch 898/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2070 - acc: 0.9233\n",
            "Epoch 899/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2163 - acc: 0.9198\n",
            "Epoch 900/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2200 - acc: 0.9193\n",
            "Epoch 901/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2110 - acc: 0.9207\n",
            "Epoch 902/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2239 - acc: 0.9171\n",
            "Epoch 903/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2270 - acc: 0.9159\n",
            "Epoch 904/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2302 - acc: 0.9131\n",
            "Epoch 905/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2096 - acc: 0.9193\n",
            "Epoch 906/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2071 - acc: 0.9218\n",
            "Epoch 907/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2062 - acc: 0.9189\n",
            "Epoch 908/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2285 - acc: 0.9146\n",
            "Epoch 909/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2139 - acc: 0.9178\n",
            "Epoch 910/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2075 - acc: 0.9206\n",
            "Epoch 911/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2153 - acc: 0.9188\n",
            "Epoch 912/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2057 - acc: 0.9208\n",
            "Epoch 913/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2179 - acc: 0.9179\n",
            "Epoch 914/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2292 - acc: 0.9164\n",
            "Epoch 915/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2338 - acc: 0.9140\n",
            "Epoch 916/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1950 - acc: 0.9246\n",
            "Epoch 917/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2214 - acc: 0.9183\n",
            "Epoch 918/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2284 - acc: 0.9147\n",
            "Epoch 919/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1989 - acc: 0.9244\n",
            "Epoch 920/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2207 - acc: 0.9170\n",
            "Epoch 921/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2199 - acc: 0.9183\n",
            "Epoch 922/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2329 - acc: 0.9149\n",
            "Epoch 923/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2293 - acc: 0.9172\n",
            "Epoch 924/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2204 - acc: 0.9169\n",
            "Epoch 925/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2170 - acc: 0.9193\n",
            "Epoch 926/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2097 - acc: 0.9223\n",
            "Epoch 927/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2177 - acc: 0.9166\n",
            "Epoch 928/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2214 - acc: 0.9197\n",
            "Epoch 929/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2116 - acc: 0.9194\n",
            "Epoch 930/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2102 - acc: 0.9198\n",
            "Epoch 931/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2226 - acc: 0.9177\n",
            "Epoch 932/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2133 - acc: 0.9177\n",
            "Epoch 933/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2203 - acc: 0.9166\n",
            "Epoch 934/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2358 - acc: 0.9125\n",
            "Epoch 935/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2041 - acc: 0.9212\n",
            "Epoch 936/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2118 - acc: 0.9184\n",
            "Epoch 937/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2516 - acc: 0.9086\n",
            "Epoch 938/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2098 - acc: 0.9201\n",
            "Epoch 939/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1914 - acc: 0.9269\n",
            "Epoch 940/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2289 - acc: 0.9157\n",
            "Epoch 941/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2136 - acc: 0.9198\n",
            "Epoch 942/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2135 - acc: 0.9216\n",
            "Epoch 943/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2346 - acc: 0.9121\n",
            "Epoch 944/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2039 - acc: 0.9207\n",
            "Epoch 945/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2305 - acc: 0.9132\n",
            "Epoch 946/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2151 - acc: 0.9178\n",
            "Epoch 947/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2001 - acc: 0.9250\n",
            "Epoch 948/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2374 - acc: 0.9128\n",
            "Epoch 949/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2354 - acc: 0.9128\n",
            "Epoch 950/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2131 - acc: 0.9198\n",
            "Epoch 951/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2073 - acc: 0.9200\n",
            "Epoch 952/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2000 - acc: 0.9226\n",
            "Epoch 953/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2204 - acc: 0.9168\n",
            "Epoch 954/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2240 - acc: 0.9162\n",
            "Epoch 955/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2181 - acc: 0.9179\n",
            "Epoch 956/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2226 - acc: 0.9182\n",
            "Epoch 957/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2069 - acc: 0.9222\n",
            "Epoch 958/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2012 - acc: 0.9233\n",
            "Epoch 959/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2150 - acc: 0.9204\n",
            "Epoch 960/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2104 - acc: 0.9219\n",
            "Epoch 961/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2165 - acc: 0.9197\n",
            "Epoch 962/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2365 - acc: 0.9117\n",
            "Epoch 963/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2066 - acc: 0.9218\n",
            "Epoch 964/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2012 - acc: 0.9250\n",
            "Epoch 965/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2078 - acc: 0.9215\n",
            "Epoch 966/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2542 - acc: 0.9094\n",
            "Epoch 967/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2223 - acc: 0.9174\n",
            "Epoch 968/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2015 - acc: 0.9217\n",
            "Epoch 969/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2194 - acc: 0.9203\n",
            "Epoch 970/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1981 - acc: 0.9234\n",
            "Epoch 971/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1963 - acc: 0.9257\n",
            "Epoch 972/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2172 - acc: 0.9187\n",
            "Epoch 973/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2324 - acc: 0.9140\n",
            "Epoch 974/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2120 - acc: 0.9201\n",
            "Epoch 975/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2241 - acc: 0.9195\n",
            "Epoch 976/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2175 - acc: 0.9185\n",
            "Epoch 977/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2095 - acc: 0.9203\n",
            "Epoch 978/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2182 - acc: 0.9192\n",
            "Epoch 979/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2112 - acc: 0.9196\n",
            "Epoch 980/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2021 - acc: 0.9238\n",
            "Epoch 981/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2061 - acc: 0.9227\n",
            "Epoch 982/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2316 - acc: 0.9155\n",
            "Epoch 983/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2044 - acc: 0.9218\n",
            "Epoch 984/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1957 - acc: 0.9256\n",
            "Epoch 985/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2120 - acc: 0.9193\n",
            "Epoch 986/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2154 - acc: 0.9204\n",
            "Epoch 987/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2273 - acc: 0.9176\n",
            "Epoch 988/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2021 - acc: 0.9232\n",
            "Epoch 989/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2073 - acc: 0.9209\n",
            "Epoch 990/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2115 - acc: 0.9217\n",
            "Epoch 991/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2304 - acc: 0.9166\n",
            "Epoch 992/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2242 - acc: 0.9171\n",
            "Epoch 993/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2072 - acc: 0.9233\n",
            "Epoch 994/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2008 - acc: 0.9232\n",
            "Epoch 995/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2048 - acc: 0.9221\n",
            "Epoch 996/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2306 - acc: 0.9156\n",
            "Epoch 997/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2233 - acc: 0.9192\n",
            "Epoch 998/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2005 - acc: 0.9242\n",
            "Epoch 999/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2189 - acc: 0.9207\n",
            "Epoch 1000/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2090 - acc: 0.9216\n",
            "Epoch 1001/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2276 - acc: 0.9178\n",
            "Epoch 1002/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2059 - acc: 0.9224\n",
            "Epoch 1003/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2316 - acc: 0.9158\n",
            "Epoch 1004/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2250 - acc: 0.9171\n",
            "Epoch 1005/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2111 - acc: 0.9225\n",
            "Epoch 1006/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1934 - acc: 0.9259\n",
            "Epoch 1007/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2194 - acc: 0.9198\n",
            "Epoch 1008/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1954 - acc: 0.9241\n",
            "Epoch 1009/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2187 - acc: 0.9202\n",
            "Epoch 1010/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2163 - acc: 0.9177\n",
            "Epoch 1011/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2016 - acc: 0.9252\n",
            "Epoch 1012/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2134 - acc: 0.9204\n",
            "Epoch 1013/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2103 - acc: 0.9220\n",
            "Epoch 1014/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2078 - acc: 0.9226\n",
            "Epoch 1015/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2011 - acc: 0.9236\n",
            "Epoch 1016/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2071 - acc: 0.9225\n",
            "Epoch 1017/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2098 - acc: 0.9203\n",
            "Epoch 1018/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2429 - acc: 0.9126\n",
            "Epoch 1019/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2107 - acc: 0.9218\n",
            "Epoch 1020/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2104 - acc: 0.9211\n",
            "Epoch 1021/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2317 - acc: 0.9148\n",
            "Epoch 1022/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2193 - acc: 0.9188\n",
            "Epoch 1023/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2031 - acc: 0.9235\n",
            "Epoch 1024/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1975 - acc: 0.9239\n",
            "Epoch 1025/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2158 - acc: 0.9180\n",
            "Epoch 1026/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2607 - acc: 0.9160\n",
            "Epoch 1027/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2068 - acc: 0.9210\n",
            "Epoch 1028/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2050 - acc: 0.9230\n",
            "Epoch 1029/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2304 - acc: 0.9162\n",
            "Epoch 1030/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2056 - acc: 0.9224\n",
            "Epoch 1031/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1990 - acc: 0.9249\n",
            "Epoch 1032/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2437 - acc: 0.9131\n",
            "Epoch 1033/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2106 - acc: 0.9221\n",
            "Epoch 1034/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2071 - acc: 0.9228\n",
            "Epoch 1035/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2084 - acc: 0.9211\n",
            "Epoch 1036/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2093 - acc: 0.9217\n",
            "Epoch 1037/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2110 - acc: 0.9231\n",
            "Epoch 1038/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2429 - acc: 0.9136\n",
            "Epoch 1039/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2148 - acc: 0.9195\n",
            "Epoch 1040/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2095 - acc: 0.9223\n",
            "Epoch 1041/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2193 - acc: 0.9190\n",
            "Epoch 1042/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2148 - acc: 0.9211\n",
            "Epoch 1043/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2100 - acc: 0.9224\n",
            "Epoch 1044/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1991 - acc: 0.9249\n",
            "Epoch 1045/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2275 - acc: 0.9154\n",
            "Epoch 1046/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2148 - acc: 0.9184\n",
            "Epoch 1047/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1925 - acc: 0.9264\n",
            "Epoch 1048/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2154 - acc: 0.9205\n",
            "Epoch 1049/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2298 - acc: 0.9186\n",
            "Epoch 1050/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2062 - acc: 0.9218\n",
            "Epoch 1051/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2019 - acc: 0.9248\n",
            "Epoch 1052/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2122 - acc: 0.9195\n",
            "Epoch 1053/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2215 - acc: 0.9170\n",
            "Epoch 1054/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1991 - acc: 0.9230\n",
            "Epoch 1055/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2120 - acc: 0.9218\n",
            "Epoch 1056/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2262 - acc: 0.9172\n",
            "Epoch 1057/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2041 - acc: 0.9232\n",
            "Epoch 1058/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2294 - acc: 0.9159\n",
            "Epoch 1059/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1892 - acc: 0.9264\n",
            "Epoch 1060/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2080 - acc: 0.9230\n",
            "Epoch 1061/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1985 - acc: 0.9242\n",
            "Epoch 1062/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2033 - acc: 0.9214\n",
            "Epoch 1063/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2486 - acc: 0.9127\n",
            "Epoch 1064/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2132 - acc: 0.9194\n",
            "Epoch 1065/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1989 - acc: 0.9250\n",
            "Epoch 1066/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2001 - acc: 0.9249\n",
            "Epoch 1067/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2260 - acc: 0.9150\n",
            "Epoch 1068/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2180 - acc: 0.9189\n",
            "Epoch 1069/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1898 - acc: 0.9284\n",
            "Epoch 1070/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2240 - acc: 0.9174\n",
            "Epoch 1071/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1925 - acc: 0.9268\n",
            "Epoch 1072/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2139 - acc: 0.9198\n",
            "Epoch 1073/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2062 - acc: 0.9230\n",
            "Epoch 1074/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2054 - acc: 0.9220\n",
            "Epoch 1075/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1999 - acc: 0.9241\n",
            "Epoch 1076/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2014 - acc: 0.9244\n",
            "Epoch 1077/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2158 - acc: 0.9192\n",
            "Epoch 1078/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2342 - acc: 0.9191\n",
            "Epoch 1079/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2063 - acc: 0.9224\n",
            "Epoch 1080/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1954 - acc: 0.9249\n",
            "Epoch 1081/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2089 - acc: 0.9204\n",
            "Epoch 1082/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2253 - acc: 0.9200\n",
            "Epoch 1083/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1865 - acc: 0.9269\n",
            "Epoch 1084/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2287 - acc: 0.9169\n",
            "Epoch 1085/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1931 - acc: 0.9254\n",
            "Epoch 1086/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2049 - acc: 0.9231\n",
            "Epoch 1087/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2270 - acc: 0.9163\n",
            "Epoch 1088/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2292 - acc: 0.9150\n",
            "Epoch 1089/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1910 - acc: 0.9270\n",
            "Epoch 1090/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1991 - acc: 0.9253\n",
            "Epoch 1091/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2220 - acc: 0.9174\n",
            "Epoch 1092/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2051 - acc: 0.9218\n",
            "Epoch 1093/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2234 - acc: 0.9167\n",
            "Epoch 1094/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2056 - acc: 0.9200\n",
            "Epoch 1095/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1992 - acc: 0.9235\n",
            "Epoch 1096/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1965 - acc: 0.9247\n",
            "Epoch 1097/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2167 - acc: 0.9185\n",
            "Epoch 1098/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2010 - acc: 0.9250\n",
            "Epoch 1099/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2095 - acc: 0.9218\n",
            "Epoch 1100/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2083 - acc: 0.9228\n",
            "Epoch 1101/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1979 - acc: 0.9250\n",
            "Epoch 1102/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2081 - acc: 0.9221\n",
            "Epoch 1103/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2360 - acc: 0.9173\n",
            "Epoch 1104/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2369 - acc: 0.9159\n",
            "Epoch 1105/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1907 - acc: 0.9280\n",
            "Epoch 1106/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1968 - acc: 0.9247\n",
            "Epoch 1107/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2232 - acc: 0.9192\n",
            "Epoch 1108/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2067 - acc: 0.9248\n",
            "Epoch 1109/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2026 - acc: 0.9231\n",
            "Epoch 1110/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2059 - acc: 0.9227\n",
            "Epoch 1111/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2070 - acc: 0.9225\n",
            "Epoch 1112/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2153 - acc: 0.9207\n",
            "Epoch 1113/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2042 - acc: 0.9231\n",
            "Epoch 1114/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2187 - acc: 0.9217\n",
            "Epoch 1115/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2202 - acc: 0.9184\n",
            "Epoch 1116/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1981 - acc: 0.9241\n",
            "Epoch 1117/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1995 - acc: 0.9251\n",
            "Epoch 1118/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2207 - acc: 0.9184\n",
            "Epoch 1119/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1976 - acc: 0.9254\n",
            "Epoch 1120/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2035 - acc: 0.9227\n",
            "Epoch 1121/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2116 - acc: 0.9210\n",
            "Epoch 1122/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2127 - acc: 0.9204\n",
            "Epoch 1123/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2148 - acc: 0.9209\n",
            "Epoch 1124/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2047 - acc: 0.9236\n",
            "Epoch 1125/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2090 - acc: 0.9240\n",
            "Epoch 1126/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2042 - acc: 0.9259\n",
            "Epoch 1127/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2015 - acc: 0.9228\n",
            "Epoch 1128/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2124 - acc: 0.9200\n",
            "Epoch 1129/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2094 - acc: 0.9224\n",
            "Epoch 1130/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2031 - acc: 0.9258\n",
            "Epoch 1131/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2011 - acc: 0.9243\n",
            "Epoch 1132/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2064 - acc: 0.9223\n",
            "Epoch 1133/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2119 - acc: 0.9222\n",
            "Epoch 1134/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1945 - acc: 0.9250\n",
            "Epoch 1135/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2413 - acc: 0.9138\n",
            "Epoch 1136/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1978 - acc: 0.9239\n",
            "Epoch 1137/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1847 - acc: 0.9287\n",
            "Epoch 1138/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1961 - acc: 0.9255\n",
            "Epoch 1139/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2124 - acc: 0.9206\n",
            "Epoch 1140/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2053 - acc: 0.9233\n",
            "Epoch 1141/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2061 - acc: 0.9201\n",
            "Epoch 1142/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2089 - acc: 0.9232\n",
            "Epoch 1143/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2174 - acc: 0.9185\n",
            "Epoch 1144/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2130 - acc: 0.9224\n",
            "Epoch 1145/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2215 - acc: 0.9173\n",
            "Epoch 1146/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2020 - acc: 0.9261\n",
            "Epoch 1147/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2083 - acc: 0.9217\n",
            "Epoch 1148/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2196 - acc: 0.9207\n",
            "Epoch 1149/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2058 - acc: 0.9242\n",
            "Epoch 1150/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2171 - acc: 0.9199\n",
            "Epoch 1151/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2051 - acc: 0.9229\n",
            "Epoch 1152/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2005 - acc: 0.9242\n",
            "Epoch 1153/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2021 - acc: 0.9229\n",
            "Epoch 1154/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2018 - acc: 0.9234\n",
            "Epoch 1155/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2005 - acc: 0.9248\n",
            "Epoch 1156/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2254 - acc: 0.9183\n",
            "Epoch 1157/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2023 - acc: 0.9229\n",
            "Epoch 1158/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2166 - acc: 0.9208\n",
            "Epoch 1159/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1930 - acc: 0.9258\n",
            "Epoch 1160/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1907 - acc: 0.9269\n",
            "Epoch 1161/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2408 - acc: 0.9169\n",
            "Epoch 1162/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2053 - acc: 0.9224\n",
            "Epoch 1163/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2014 - acc: 0.9250\n",
            "Epoch 1164/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2052 - acc: 0.9232\n",
            "Epoch 1165/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2140 - acc: 0.9210\n",
            "Epoch 1166/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2039 - acc: 0.9232\n",
            "Epoch 1167/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1990 - acc: 0.9245\n",
            "Epoch 1168/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1934 - acc: 0.9259\n",
            "Epoch 1169/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2043 - acc: 0.9245\n",
            "Epoch 1170/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2234 - acc: 0.9181\n",
            "Epoch 1171/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1887 - acc: 0.9288\n",
            "Epoch 1172/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2220 - acc: 0.9220\n",
            "Epoch 1173/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2139 - acc: 0.9205\n",
            "Epoch 1174/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2150 - acc: 0.9190\n",
            "Epoch 1175/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1941 - acc: 0.9254\n",
            "Epoch 1176/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1838 - acc: 0.9289\n",
            "Epoch 1177/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2031 - acc: 0.9230\n",
            "Epoch 1178/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2176 - acc: 0.9213\n",
            "Epoch 1179/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2454 - acc: 0.9133\n",
            "Epoch 1180/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2075 - acc: 0.9203\n",
            "Epoch 1181/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1878 - acc: 0.9288\n",
            "Epoch 1182/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1990 - acc: 0.9256\n",
            "Epoch 1183/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1986 - acc: 0.9236\n",
            "Epoch 1184/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1886 - acc: 0.9282\n",
            "Epoch 1185/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2396 - acc: 0.9145\n",
            "Epoch 1186/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2349 - acc: 0.9156\n",
            "Epoch 1187/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1904 - acc: 0.9278\n",
            "Epoch 1188/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1958 - acc: 0.9245\n",
            "Epoch 1189/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2373 - acc: 0.9142\n",
            "Epoch 1190/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1918 - acc: 0.9252\n",
            "Epoch 1191/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2022 - acc: 0.9234\n",
            "Epoch 1192/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1939 - acc: 0.9268\n",
            "Epoch 1193/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2184 - acc: 0.9204\n",
            "Epoch 1194/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1873 - acc: 0.9282\n",
            "Epoch 1195/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2129 - acc: 0.9214\n",
            "Epoch 1196/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2217 - acc: 0.9171\n",
            "Epoch 1197/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1924 - acc: 0.9275\n",
            "Epoch 1198/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1870 - acc: 0.9271\n",
            "Epoch 1199/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2073 - acc: 0.9240\n",
            "Epoch 1200/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1992 - acc: 0.9241\n",
            "Epoch 1201/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1951 - acc: 0.9258\n",
            "Epoch 1202/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2137 - acc: 0.9226\n",
            "Epoch 1203/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2431 - acc: 0.9154\n",
            "Epoch 1204/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2317 - acc: 0.9160\n",
            "Epoch 1205/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1828 - acc: 0.9292\n",
            "Epoch 1206/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2107 - acc: 0.9216\n",
            "Epoch 1207/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1992 - acc: 0.9236\n",
            "Epoch 1208/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2132 - acc: 0.9222\n",
            "Epoch 1209/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1980 - acc: 0.9244\n",
            "Epoch 1210/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2286 - acc: 0.9188\n",
            "Epoch 1211/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1921 - acc: 0.9293\n",
            "Epoch 1212/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1934 - acc: 0.9271\n",
            "Epoch 1213/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2027 - acc: 0.9251\n",
            "Epoch 1214/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1879 - acc: 0.9277\n",
            "Epoch 1215/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1985 - acc: 0.9256\n",
            "Epoch 1216/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2069 - acc: 0.9249\n",
            "Epoch 1217/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2037 - acc: 0.9229\n",
            "Epoch 1218/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1991 - acc: 0.9249\n",
            "Epoch 1219/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2161 - acc: 0.9212\n",
            "Epoch 1220/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1972 - acc: 0.9252\n",
            "Epoch 1221/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1912 - acc: 0.9284\n",
            "Epoch 1222/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2225 - acc: 0.9179\n",
            "Epoch 1223/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1960 - acc: 0.9256\n",
            "Epoch 1224/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1835 - acc: 0.9312\n",
            "Epoch 1225/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2145 - acc: 0.9194\n",
            "Epoch 1226/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2229 - acc: 0.9217\n",
            "Epoch 1227/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2239 - acc: 0.9173\n",
            "Epoch 1228/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2176 - acc: 0.9200\n",
            "Epoch 1229/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1922 - acc: 0.9260\n",
            "Epoch 1230/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2111 - acc: 0.9222\n",
            "Epoch 1231/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2005 - acc: 0.9236\n",
            "Epoch 1232/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2115 - acc: 0.9227\n",
            "Epoch 1233/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2032 - acc: 0.9236\n",
            "Epoch 1234/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1880 - acc: 0.9271\n",
            "Epoch 1235/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2315 - acc: 0.9176\n",
            "Epoch 1236/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2289 - acc: 0.9177\n",
            "Epoch 1237/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1963 - acc: 0.9250\n",
            "Epoch 1238/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2121 - acc: 0.9212\n",
            "Epoch 1239/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1938 - acc: 0.9284\n",
            "Epoch 1240/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2206 - acc: 0.9187\n",
            "Epoch 1241/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1930 - acc: 0.9269\n",
            "Epoch 1242/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1862 - acc: 0.9283\n",
            "Epoch 1243/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2287 - acc: 0.9182\n",
            "Epoch 1244/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1923 - acc: 0.9280\n",
            "Epoch 1245/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1974 - acc: 0.9253\n",
            "Epoch 1246/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2242 - acc: 0.9202\n",
            "Epoch 1247/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2001 - acc: 0.9239\n",
            "Epoch 1248/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1903 - acc: 0.9280\n",
            "Epoch 1249/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2179 - acc: 0.9206\n",
            "Epoch 1250/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2082 - acc: 0.9224\n",
            "Epoch 1251/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2004 - acc: 0.9256\n",
            "Epoch 1252/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1935 - acc: 0.9264\n",
            "Epoch 1253/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2028 - acc: 0.9250\n",
            "Epoch 1254/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2099 - acc: 0.9237\n",
            "Epoch 1255/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1852 - acc: 0.9283\n",
            "Epoch 1256/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2246 - acc: 0.9192\n",
            "Epoch 1257/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2167 - acc: 0.9186\n",
            "Epoch 1258/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1951 - acc: 0.9274\n",
            "Epoch 1259/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1896 - acc: 0.9288\n",
            "Epoch 1260/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2096 - acc: 0.9225\n",
            "Epoch 1261/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1968 - acc: 0.9262\n",
            "Epoch 1262/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1867 - acc: 0.9290\n",
            "Epoch 1263/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2161 - acc: 0.9211\n",
            "Epoch 1264/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1973 - acc: 0.9259\n",
            "Epoch 1265/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2065 - acc: 0.9237\n",
            "Epoch 1266/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1971 - acc: 0.9252\n",
            "Epoch 1267/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2041 - acc: 0.9235\n",
            "Epoch 1268/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2068 - acc: 0.9241\n",
            "Epoch 1269/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2163 - acc: 0.9211\n",
            "Epoch 1270/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1899 - acc: 0.9293\n",
            "Epoch 1271/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2064 - acc: 0.9218\n",
            "Epoch 1272/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2357 - acc: 0.9193\n",
            "Epoch 1273/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1857 - acc: 0.9293\n",
            "Epoch 1274/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1910 - acc: 0.9275\n",
            "Epoch 1275/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2011 - acc: 0.9256\n",
            "Epoch 1276/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2236 - acc: 0.9232\n",
            "Epoch 1277/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2013 - acc: 0.9247\n",
            "Epoch 1278/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1916 - acc: 0.9274\n",
            "Epoch 1279/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2302 - acc: 0.9174\n",
            "Epoch 1280/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2078 - acc: 0.9230\n",
            "Epoch 1281/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1921 - acc: 0.9282\n",
            "Epoch 1282/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1912 - acc: 0.9271\n",
            "Epoch 1283/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1983 - acc: 0.9276\n",
            "Epoch 1284/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2019 - acc: 0.9241\n",
            "Epoch 1285/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2048 - acc: 0.9222\n",
            "Epoch 1286/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1968 - acc: 0.9250\n",
            "Epoch 1287/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1877 - acc: 0.9285\n",
            "Epoch 1288/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2024 - acc: 0.9242\n",
            "Epoch 1289/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2114 - acc: 0.9211\n",
            "Epoch 1290/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1851 - acc: 0.9292\n",
            "Epoch 1291/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2011 - acc: 0.9244\n",
            "Epoch 1292/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2077 - acc: 0.9213\n",
            "Epoch 1293/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1924 - acc: 0.9286\n",
            "Epoch 1294/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1996 - acc: 0.9247\n",
            "Epoch 1295/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2078 - acc: 0.9233\n",
            "Epoch 1296/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1835 - acc: 0.9286\n",
            "Epoch 1297/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1952 - acc: 0.9254\n",
            "Epoch 1298/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1975 - acc: 0.9250\n",
            "Epoch 1299/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1995 - acc: 0.9236\n",
            "Epoch 1300/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1867 - acc: 0.9283\n",
            "Epoch 1301/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2009 - acc: 0.9238\n",
            "Epoch 1302/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1974 - acc: 0.9267\n",
            "Epoch 1303/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1847 - acc: 0.9308\n",
            "Epoch 1304/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2139 - acc: 0.9209\n",
            "Epoch 1305/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2128 - acc: 0.9231\n",
            "Epoch 1306/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1979 - acc: 0.9270\n",
            "Epoch 1307/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1931 - acc: 0.9273\n",
            "Epoch 1308/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1973 - acc: 0.9245\n",
            "Epoch 1309/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1857 - acc: 0.9302\n",
            "Epoch 1310/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2063 - acc: 0.9242\n",
            "Epoch 1311/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2156 - acc: 0.9225\n",
            "Epoch 1312/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2007 - acc: 0.9244\n",
            "Epoch 1313/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1857 - acc: 0.9296\n",
            "Epoch 1314/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2021 - acc: 0.9231\n",
            "Epoch 1315/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2028 - acc: 0.9245\n",
            "Epoch 1316/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1886 - acc: 0.9278\n",
            "Epoch 1317/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1910 - acc: 0.9285\n",
            "Epoch 1318/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1945 - acc: 0.9283\n",
            "Epoch 1319/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2331 - acc: 0.9167\n",
            "Epoch 1320/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2018 - acc: 0.9252\n",
            "Epoch 1321/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2143 - acc: 0.9204\n",
            "Epoch 1322/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2396 - acc: 0.9153\n",
            "Epoch 1323/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2005 - acc: 0.9248\n",
            "Epoch 1324/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1791 - acc: 0.9315\n",
            "Epoch 1325/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1808 - acc: 0.9311\n",
            "Epoch 1326/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2029 - acc: 0.9237\n",
            "Epoch 1327/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1872 - acc: 0.9283\n",
            "Epoch 1328/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1994 - acc: 0.9251\n",
            "Epoch 1329/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1957 - acc: 0.9260\n",
            "Epoch 1330/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2074 - acc: 0.9237\n",
            "Epoch 1331/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2602 - acc: 0.9120\n",
            "Epoch 1332/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2539 - acc: 0.9113\n",
            "Epoch 1333/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1764 - acc: 0.9332\n",
            "Epoch 1334/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1747 - acc: 0.9328\n",
            "Epoch 1335/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2309 - acc: 0.9230\n",
            "Epoch 1336/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2012 - acc: 0.9234\n",
            "Epoch 1337/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2000 - acc: 0.9274\n",
            "Epoch 1338/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2141 - acc: 0.9211\n",
            "Epoch 1339/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1849 - acc: 0.9293\n",
            "Epoch 1340/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1904 - acc: 0.9289\n",
            "Epoch 1341/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2028 - acc: 0.9224\n",
            "Epoch 1342/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1813 - acc: 0.9284\n",
            "Epoch 1343/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2381 - acc: 0.9172\n",
            "Epoch 1344/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1978 - acc: 0.9254\n",
            "Epoch 1345/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1932 - acc: 0.9270\n",
            "Epoch 1346/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2167 - acc: 0.9238\n",
            "Epoch 1347/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2192 - acc: 0.9216\n",
            "Epoch 1348/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1793 - acc: 0.9306\n",
            "Epoch 1349/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2005 - acc: 0.9235\n",
            "Epoch 1350/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2520 - acc: 0.9117\n",
            "Epoch 1351/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1840 - acc: 0.9285\n",
            "Epoch 1352/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1924 - acc: 0.9271\n",
            "Epoch 1353/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2108 - acc: 0.9203\n",
            "Epoch 1354/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2178 - acc: 0.9192\n",
            "Epoch 1355/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2022 - acc: 0.9246\n",
            "Epoch 1356/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1791 - acc: 0.9300\n",
            "Epoch 1357/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1946 - acc: 0.9262\n",
            "Epoch 1358/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1993 - acc: 0.9261\n",
            "Epoch 1359/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1873 - acc: 0.9289\n",
            "Epoch 1360/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2087 - acc: 0.9214\n",
            "Epoch 1361/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2156 - acc: 0.9214\n",
            "Epoch 1362/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2094 - acc: 0.9241\n",
            "Epoch 1363/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2042 - acc: 0.9251\n",
            "Epoch 1364/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1787 - acc: 0.9303\n",
            "Epoch 1365/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1918 - acc: 0.9276\n",
            "Epoch 1366/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2064 - acc: 0.9245\n",
            "Epoch 1367/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1921 - acc: 0.9281\n",
            "Epoch 1368/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2170 - acc: 0.9232\n",
            "Epoch 1369/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2123 - acc: 0.9237\n",
            "Epoch 1370/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1943 - acc: 0.9262\n",
            "Epoch 1371/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1889 - acc: 0.9277\n",
            "Epoch 1372/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2165 - acc: 0.9218\n",
            "Epoch 1373/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1906 - acc: 0.9248\n",
            "Epoch 1374/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1810 - acc: 0.9308\n",
            "Epoch 1375/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2042 - acc: 0.9252\n",
            "Epoch 1376/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2085 - acc: 0.9239\n",
            "Epoch 1377/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2138 - acc: 0.9217\n",
            "Epoch 1378/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2221 - acc: 0.9207\n",
            "Epoch 1379/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2001 - acc: 0.9241\n",
            "Epoch 1380/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1840 - acc: 0.9278\n",
            "Epoch 1381/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1849 - acc: 0.9298\n",
            "Epoch 1382/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1869 - acc: 0.9292\n",
            "Epoch 1383/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2056 - acc: 0.9246\n",
            "Epoch 1384/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2156 - acc: 0.9190\n",
            "Epoch 1385/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1867 - acc: 0.9286\n",
            "Epoch 1386/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1949 - acc: 0.9255\n",
            "Epoch 1387/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1906 - acc: 0.9285\n",
            "Epoch 1388/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2086 - acc: 0.9238\n",
            "Epoch 1389/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2129 - acc: 0.9230\n",
            "Epoch 1390/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1760 - acc: 0.9311\n",
            "Epoch 1391/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1976 - acc: 0.9265\n",
            "Epoch 1392/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2158 - acc: 0.9198\n",
            "Epoch 1393/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1839 - acc: 0.9298\n",
            "Epoch 1394/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1924 - acc: 0.9273\n",
            "Epoch 1395/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2102 - acc: 0.9232\n",
            "Epoch 1396/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2071 - acc: 0.9228\n",
            "Epoch 1397/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1968 - acc: 0.9274\n",
            "Epoch 1398/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1948 - acc: 0.9260\n",
            "Epoch 1399/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2092 - acc: 0.9248\n",
            "Epoch 1400/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2075 - acc: 0.9218\n",
            "Epoch 1401/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1847 - acc: 0.9300\n",
            "Epoch 1402/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2105 - acc: 0.9212\n",
            "Epoch 1403/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1903 - acc: 0.9268\n",
            "Epoch 1404/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1857 - acc: 0.9291\n",
            "Epoch 1405/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2019 - acc: 0.9247\n",
            "Epoch 1406/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1880 - acc: 0.9284\n",
            "Epoch 1407/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1970 - acc: 0.9263\n",
            "Epoch 1408/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2281 - acc: 0.9187\n",
            "Epoch 1409/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1864 - acc: 0.9289\n",
            "Epoch 1410/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2114 - acc: 0.9248\n",
            "Epoch 1411/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2167 - acc: 0.9209\n",
            "Epoch 1412/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1978 - acc: 0.9241\n",
            "Epoch 1413/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2128 - acc: 0.9226\n",
            "Epoch 1414/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1939 - acc: 0.9255\n",
            "Epoch 1415/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1840 - acc: 0.9294\n",
            "Epoch 1416/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1911 - acc: 0.9279\n",
            "Epoch 1417/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1897 - acc: 0.9285\n",
            "Epoch 1418/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2004 - acc: 0.9242\n",
            "Epoch 1419/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2160 - acc: 0.9194\n",
            "Epoch 1420/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2002 - acc: 0.9254\n",
            "Epoch 1421/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2120 - acc: 0.9242\n",
            "Epoch 1422/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2478 - acc: 0.9183\n",
            "Epoch 1423/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2094 - acc: 0.9228\n",
            "Epoch 1424/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1746 - acc: 0.9318\n",
            "Epoch 1425/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1950 - acc: 0.9285\n",
            "Epoch 1426/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1963 - acc: 0.9261\n",
            "Epoch 1427/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1872 - acc: 0.9285\n",
            "Epoch 1428/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2405 - acc: 0.9139\n",
            "Epoch 1429/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1944 - acc: 0.9255\n",
            "Epoch 1430/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2242 - acc: 0.9215\n",
            "Epoch 1431/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2048 - acc: 0.9217\n",
            "Epoch 1432/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1890 - acc: 0.9283\n",
            "Epoch 1433/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1986 - acc: 0.9267\n",
            "Epoch 1434/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2357 - acc: 0.9211\n",
            "Epoch 1435/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2115 - acc: 0.9212\n",
            "Epoch 1436/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1731 - acc: 0.9314\n",
            "Epoch 1437/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1968 - acc: 0.9235\n",
            "Epoch 1438/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1967 - acc: 0.9249\n",
            "Epoch 1439/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2231 - acc: 0.9209\n",
            "Epoch 1440/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2115 - acc: 0.9219\n",
            "Epoch 1441/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1784 - acc: 0.9305\n",
            "Epoch 1442/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1800 - acc: 0.9320\n",
            "Epoch 1443/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1873 - acc: 0.9282\n",
            "Epoch 1444/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2003 - acc: 0.9244\n",
            "Epoch 1445/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1932 - acc: 0.9264\n",
            "Epoch 1446/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2081 - acc: 0.9230\n",
            "Epoch 1447/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1830 - acc: 0.9302\n",
            "Epoch 1448/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1937 - acc: 0.9283\n",
            "Epoch 1449/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1800 - acc: 0.9302\n",
            "Epoch 1450/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1989 - acc: 0.9249\n",
            "Epoch 1451/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2225 - acc: 0.9192\n",
            "Epoch 1452/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2143 - acc: 0.9209\n",
            "Epoch 1453/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1923 - acc: 0.9270\n",
            "Epoch 1454/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1924 - acc: 0.9297\n",
            "Epoch 1455/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2054 - acc: 0.9248\n",
            "Epoch 1456/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1861 - acc: 0.9281\n",
            "Epoch 1457/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2096 - acc: 0.9237\n",
            "Epoch 1458/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1874 - acc: 0.9287\n",
            "Epoch 1459/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1884 - acc: 0.9282\n",
            "Epoch 1460/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1876 - acc: 0.9281\n",
            "Epoch 1461/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2145 - acc: 0.9239\n",
            "Epoch 1462/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2144 - acc: 0.9229\n",
            "Epoch 1463/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1722 - acc: 0.9345\n",
            "Epoch 1464/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2109 - acc: 0.9214\n",
            "Epoch 1465/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1946 - acc: 0.9276\n",
            "Epoch 1466/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1926 - acc: 0.9268\n",
            "Epoch 1467/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1856 - acc: 0.9297\n",
            "Epoch 1468/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1869 - acc: 0.9294\n",
            "Epoch 1469/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1993 - acc: 0.9252\n",
            "Epoch 1470/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1947 - acc: 0.9252\n",
            "Epoch 1471/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1853 - acc: 0.9300\n",
            "Epoch 1472/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2228 - acc: 0.9202\n",
            "Epoch 1473/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1975 - acc: 0.9284\n",
            "Epoch 1474/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1917 - acc: 0.9267\n",
            "Epoch 1475/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1856 - acc: 0.9302\n",
            "Epoch 1476/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2069 - acc: 0.9241\n",
            "Epoch 1477/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2043 - acc: 0.9231\n",
            "Epoch 1478/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1898 - acc: 0.9286\n",
            "Epoch 1479/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1991 - acc: 0.9262\n",
            "Epoch 1480/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1890 - acc: 0.9298\n",
            "Epoch 1481/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2083 - acc: 0.9228\n",
            "Epoch 1482/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1957 - acc: 0.9249\n",
            "Epoch 1483/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1869 - acc: 0.9313\n",
            "Epoch 1484/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1885 - acc: 0.9271\n",
            "Epoch 1485/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2210 - acc: 0.9195\n",
            "Epoch 1486/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1973 - acc: 0.9253\n",
            "Epoch 1487/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1813 - acc: 0.9315\n",
            "Epoch 1488/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1994 - acc: 0.9262\n",
            "Epoch 1489/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1976 - acc: 0.9252\n",
            "Epoch 1490/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1757 - acc: 0.9313\n",
            "Epoch 1491/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2031 - acc: 0.9263\n",
            "Epoch 1492/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1969 - acc: 0.9274\n",
            "Epoch 1493/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1835 - acc: 0.9314\n",
            "Epoch 1494/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2246 - acc: 0.9208\n",
            "Epoch 1495/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1852 - acc: 0.9290\n",
            "Epoch 1496/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1765 - acc: 0.9319\n",
            "Epoch 1497/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1893 - acc: 0.9279\n",
            "Epoch 1498/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1989 - acc: 0.9263\n",
            "Epoch 1499/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1946 - acc: 0.9265\n",
            "Epoch 1500/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1955 - acc: 0.9273\n",
            "Epoch 1501/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2127 - acc: 0.9235\n",
            "Epoch 1502/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1996 - acc: 0.9268\n",
            "Epoch 1503/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1881 - acc: 0.9274\n",
            "Epoch 1504/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1808 - acc: 0.9312\n",
            "Epoch 1505/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2369 - acc: 0.9169\n",
            "Epoch 1506/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1787 - acc: 0.9321\n",
            "Epoch 1507/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1891 - acc: 0.9297\n",
            "Epoch 1508/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1933 - acc: 0.9258\n",
            "Epoch 1509/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1954 - acc: 0.9267\n",
            "Epoch 1510/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1840 - acc: 0.9308\n",
            "Epoch 1511/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2133 - acc: 0.9216\n",
            "Epoch 1512/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1883 - acc: 0.9288\n",
            "Epoch 1513/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2199 - acc: 0.9211\n",
            "Epoch 1514/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2156 - acc: 0.9226\n",
            "Epoch 1515/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2270 - acc: 0.9198\n",
            "Epoch 1516/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1879 - acc: 0.9280\n",
            "Epoch 1517/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1741 - acc: 0.9340\n",
            "Epoch 1518/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1880 - acc: 0.9299\n",
            "Epoch 1519/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2051 - acc: 0.9248\n",
            "Epoch 1520/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1933 - acc: 0.9271\n",
            "Epoch 1521/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1786 - acc: 0.9302\n",
            "Epoch 1522/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2357 - acc: 0.9176\n",
            "Epoch 1523/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1980 - acc: 0.9262\n",
            "Epoch 1524/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1784 - acc: 0.9314\n",
            "Epoch 1525/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1980 - acc: 0.9252\n",
            "Epoch 1526/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2128 - acc: 0.9276\n",
            "Epoch 1527/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2139 - acc: 0.9199\n",
            "Epoch 1528/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1913 - acc: 0.9276\n",
            "Epoch 1529/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1838 - acc: 0.9287\n",
            "Epoch 1530/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1926 - acc: 0.9288\n",
            "Epoch 1531/3000\n",
            "896/896 [==============================] - 4s 5ms/step - loss: 0.1894 - acc: 0.9282\n",
            "Epoch 1532/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2047 - acc: 0.9260\n",
            "Epoch 1533/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2174 - acc: 0.9206\n",
            "Epoch 1534/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1948 - acc: 0.9274\n",
            "Epoch 1535/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2086 - acc: 0.9231\n",
            "Epoch 1536/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1850 - acc: 0.9292\n",
            "Epoch 1537/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2235 - acc: 0.9193\n",
            "Epoch 1538/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1786 - acc: 0.9308\n",
            "Epoch 1539/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1794 - acc: 0.9319\n",
            "Epoch 1540/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1875 - acc: 0.9277\n",
            "Epoch 1541/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2012 - acc: 0.9268\n",
            "Epoch 1542/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2006 - acc: 0.9275\n",
            "Epoch 1543/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1948 - acc: 0.9284\n",
            "Epoch 1544/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1909 - acc: 0.9286\n",
            "Epoch 1545/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2029 - acc: 0.9233\n",
            "Epoch 1546/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1810 - acc: 0.9327\n",
            "Epoch 1547/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1914 - acc: 0.9279\n",
            "Epoch 1548/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2087 - acc: 0.9245\n",
            "Epoch 1549/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1979 - acc: 0.9269\n",
            "Epoch 1550/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1748 - acc: 0.9317\n",
            "Epoch 1551/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1867 - acc: 0.9307\n",
            "Epoch 1552/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2038 - acc: 0.9250\n",
            "Epoch 1553/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1811 - acc: 0.9310\n",
            "Epoch 1554/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1818 - acc: 0.9314\n",
            "Epoch 1555/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1968 - acc: 0.9258\n",
            "Epoch 1556/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1933 - acc: 0.9276\n",
            "Epoch 1557/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2050 - acc: 0.9231\n",
            "Epoch 1558/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1975 - acc: 0.9253\n",
            "Epoch 1559/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1869 - acc: 0.9293\n",
            "Epoch 1560/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2006 - acc: 0.9280\n",
            "Epoch 1561/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1809 - acc: 0.9311\n",
            "Epoch 1562/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2038 - acc: 0.9242\n",
            "Epoch 1563/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1890 - acc: 0.9295\n",
            "Epoch 1564/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1922 - acc: 0.9275\n",
            "Epoch 1565/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1912 - acc: 0.9276\n",
            "Epoch 1566/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2404 - acc: 0.9176\n",
            "Epoch 1567/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2057 - acc: 0.9232\n",
            "Epoch 1568/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1723 - acc: 0.9337\n",
            "Epoch 1569/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1727 - acc: 0.9339\n",
            "Epoch 1570/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1964 - acc: 0.9262\n",
            "Epoch 1571/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2030 - acc: 0.9259\n",
            "Epoch 1572/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2126 - acc: 0.9234\n",
            "Epoch 1573/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2010 - acc: 0.9241\n",
            "Epoch 1574/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1749 - acc: 0.9329\n",
            "Epoch 1575/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2148 - acc: 0.9242\n",
            "Epoch 1576/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1905 - acc: 0.9275\n",
            "Epoch 1577/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1891 - acc: 0.9291\n",
            "Epoch 1578/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1954 - acc: 0.9272\n",
            "Epoch 1579/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1922 - acc: 0.9276\n",
            "Epoch 1580/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2007 - acc: 0.9254\n",
            "Epoch 1581/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1889 - acc: 0.9285\n",
            "Epoch 1582/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1888 - acc: 0.9290\n",
            "Epoch 1583/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2005 - acc: 0.9249\n",
            "Epoch 1584/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2040 - acc: 0.9269\n",
            "Epoch 1585/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1936 - acc: 0.9266\n",
            "Epoch 1586/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2069 - acc: 0.9253\n",
            "Epoch 1587/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2035 - acc: 0.9244\n",
            "Epoch 1588/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1934 - acc: 0.9272\n",
            "Epoch 1589/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2029 - acc: 0.9257\n",
            "Epoch 1590/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2042 - acc: 0.9261\n",
            "Epoch 1591/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2245 - acc: 0.9175\n",
            "Epoch 1592/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1852 - acc: 0.9286\n",
            "Epoch 1593/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1719 - acc: 0.9337\n",
            "Epoch 1594/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1895 - acc: 0.9257\n",
            "Epoch 1595/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1884 - acc: 0.9313\n",
            "Epoch 1596/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1878 - acc: 0.9285\n",
            "Epoch 1597/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2140 - acc: 0.9220\n",
            "Epoch 1598/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2115 - acc: 0.9242\n",
            "Epoch 1599/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1775 - acc: 0.9331\n",
            "Epoch 1600/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2011 - acc: 0.9257\n",
            "Epoch 1601/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1749 - acc: 0.9320\n",
            "Epoch 1602/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1819 - acc: 0.9310\n",
            "Epoch 1603/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1985 - acc: 0.9286\n",
            "Epoch 1604/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2364 - acc: 0.9186\n",
            "Epoch 1605/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1935 - acc: 0.9244\n",
            "Epoch 1606/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1836 - acc: 0.9287\n",
            "Epoch 1607/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1859 - acc: 0.9309\n",
            "Epoch 1608/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2075 - acc: 0.9221\n",
            "Epoch 1609/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2214 - acc: 0.9245\n",
            "Epoch 1610/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1842 - acc: 0.9294\n",
            "Epoch 1611/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1883 - acc: 0.9301\n",
            "Epoch 1612/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1986 - acc: 0.9273\n",
            "Epoch 1613/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1842 - acc: 0.9292\n",
            "Epoch 1614/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1866 - acc: 0.9294\n",
            "Epoch 1615/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1983 - acc: 0.9234\n",
            "Epoch 1616/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1930 - acc: 0.9277\n",
            "Epoch 1617/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2066 - acc: 0.9248\n",
            "Epoch 1618/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1820 - acc: 0.9313\n",
            "Epoch 1619/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2199 - acc: 0.9217\n",
            "Epoch 1620/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2008 - acc: 0.9260\n",
            "Epoch 1621/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2030 - acc: 0.9257\n",
            "Epoch 1622/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2168 - acc: 0.9236\n",
            "Epoch 1623/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1953 - acc: 0.9274\n",
            "Epoch 1624/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2155 - acc: 0.9240\n",
            "Epoch 1625/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1824 - acc: 0.9311\n",
            "Epoch 1626/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1976 - acc: 0.9265\n",
            "Epoch 1627/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1780 - acc: 0.9306\n",
            "Epoch 1628/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1807 - acc: 0.9316\n",
            "Epoch 1629/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1879 - acc: 0.9294\n",
            "Epoch 1630/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1972 - acc: 0.9262\n",
            "Epoch 1631/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1972 - acc: 0.9259\n",
            "Epoch 1632/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1795 - acc: 0.9317\n",
            "Epoch 1633/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2051 - acc: 0.9248\n",
            "Epoch 1634/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2014 - acc: 0.9240\n",
            "Epoch 1635/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1914 - acc: 0.9276\n",
            "Epoch 1636/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1842 - acc: 0.9305\n",
            "Epoch 1637/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1950 - acc: 0.9280\n",
            "Epoch 1638/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2170 - acc: 0.9225\n",
            "Epoch 1639/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1914 - acc: 0.9293\n",
            "Epoch 1640/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1922 - acc: 0.9297\n",
            "Epoch 1641/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1864 - acc: 0.9287\n",
            "Epoch 1642/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1937 - acc: 0.9263\n",
            "Epoch 1643/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2237 - acc: 0.9198\n",
            "Epoch 1644/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1808 - acc: 0.9305\n",
            "Epoch 1645/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1711 - acc: 0.9333\n",
            "Epoch 1646/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2177 - acc: 0.9211\n",
            "Epoch 1647/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1885 - acc: 0.9300\n",
            "Epoch 1648/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1766 - acc: 0.9327\n",
            "Epoch 1649/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1949 - acc: 0.9264\n",
            "Epoch 1650/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2055 - acc: 0.9230\n",
            "Epoch 1651/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2571 - acc: 0.9152\n",
            "Epoch 1652/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1830 - acc: 0.9294\n",
            "Epoch 1653/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1870 - acc: 0.9301\n",
            "Epoch 1654/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1919 - acc: 0.9287\n",
            "Epoch 1655/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2050 - acc: 0.9257\n",
            "Epoch 1656/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1926 - acc: 0.9276\n",
            "Epoch 1657/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2332 - acc: 0.9227\n",
            "Epoch 1658/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2400 - acc: 0.9193\n",
            "Epoch 1659/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1743 - acc: 0.9332\n",
            "Epoch 1660/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2004 - acc: 0.9299\n",
            "Epoch 1661/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1805 - acc: 0.9321\n",
            "Epoch 1662/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1745 - acc: 0.9336\n",
            "Epoch 1663/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1884 - acc: 0.9285\n",
            "Epoch 1664/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2424 - acc: 0.9151\n",
            "Epoch 1665/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1877 - acc: 0.9292\n",
            "Epoch 1666/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1700 - acc: 0.9348\n",
            "Epoch 1667/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1948 - acc: 0.9287\n",
            "Epoch 1668/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2092 - acc: 0.9223\n",
            "Epoch 1669/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2225 - acc: 0.9189\n",
            "Epoch 1670/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1950 - acc: 0.9278\n",
            "Epoch 1671/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1928 - acc: 0.9293\n",
            "Epoch 1672/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2103 - acc: 0.9255\n",
            "Epoch 1673/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1793 - acc: 0.9302\n",
            "Epoch 1674/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2154 - acc: 0.9232\n",
            "Epoch 1675/3000\n",
            "896/896 [==============================] - 5s 5ms/step - loss: 0.1883 - acc: 0.9277\n",
            "Epoch 1676/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1843 - acc: 0.9288\n",
            "Epoch 1677/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1722 - acc: 0.9346\n",
            "Epoch 1678/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1902 - acc: 0.9271\n",
            "Epoch 1679/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2084 - acc: 0.9261\n",
            "Epoch 1680/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1898 - acc: 0.9275\n",
            "Epoch 1681/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2300 - acc: 0.9216\n",
            "Epoch 1682/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2101 - acc: 0.9251\n",
            "Epoch 1683/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2038 - acc: 0.9262\n",
            "Epoch 1684/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2339 - acc: 0.9202\n",
            "Epoch 1685/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1744 - acc: 0.9328\n",
            "Epoch 1686/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1672 - acc: 0.9347\n",
            "Epoch 1687/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1713 - acc: 0.9322\n",
            "Epoch 1688/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1908 - acc: 0.9298\n",
            "Epoch 1689/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1894 - acc: 0.9298\n",
            "Epoch 1690/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1960 - acc: 0.9274\n",
            "Epoch 1691/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2145 - acc: 0.9241\n",
            "Epoch 1692/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1861 - acc: 0.9285\n",
            "Epoch 1693/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1923 - acc: 0.9282\n",
            "Epoch 1694/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1905 - acc: 0.9278\n",
            "Epoch 1695/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1953 - acc: 0.9280\n",
            "Epoch 1696/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1945 - acc: 0.9274\n",
            "Epoch 1697/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2128 - acc: 0.9237\n",
            "Epoch 1698/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2061 - acc: 0.9235\n",
            "Epoch 1699/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1767 - acc: 0.9324\n",
            "Epoch 1700/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1926 - acc: 0.9265\n",
            "Epoch 1701/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1869 - acc: 0.9305\n",
            "Epoch 1702/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2308 - acc: 0.9176\n",
            "Epoch 1703/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2363 - acc: 0.9169\n",
            "Epoch 1704/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1837 - acc: 0.9293\n",
            "Epoch 1705/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1705 - acc: 0.9325\n",
            "Epoch 1706/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1794 - acc: 0.9312\n",
            "Epoch 1707/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1902 - acc: 0.9301\n",
            "Epoch 1708/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2118 - acc: 0.9238\n",
            "Epoch 1709/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1846 - acc: 0.9294\n",
            "Epoch 1710/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1959 - acc: 0.9286\n",
            "Epoch 1711/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1832 - acc: 0.9289\n",
            "Epoch 1712/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2043 - acc: 0.9249\n",
            "Epoch 1713/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2054 - acc: 0.9239\n",
            "Epoch 1714/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2145 - acc: 0.9241\n",
            "Epoch 1715/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1972 - acc: 0.9260\n",
            "Epoch 1716/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1789 - acc: 0.9315\n",
            "Epoch 1717/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2326 - acc: 0.9222\n",
            "Epoch 1718/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1934 - acc: 0.9254\n",
            "Epoch 1719/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1852 - acc: 0.9305\n",
            "Epoch 1720/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1884 - acc: 0.9286\n",
            "Epoch 1721/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1822 - acc: 0.9297\n",
            "Epoch 1722/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1847 - acc: 0.9309\n",
            "Epoch 1723/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1960 - acc: 0.9272\n",
            "Epoch 1724/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1918 - acc: 0.9302\n",
            "Epoch 1725/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2021 - acc: 0.9277\n",
            "Epoch 1726/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1867 - acc: 0.9300\n",
            "Epoch 1727/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1765 - acc: 0.9327\n",
            "Epoch 1728/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2151 - acc: 0.9245\n",
            "Epoch 1729/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2541 - acc: 0.9137\n",
            "Epoch 1730/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2000 - acc: 0.9282\n",
            "Epoch 1731/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1924 - acc: 0.9257\n",
            "Epoch 1732/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1673 - acc: 0.9351\n",
            "Epoch 1733/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2002 - acc: 0.9272\n",
            "Epoch 1734/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1738 - acc: 0.9332\n",
            "Epoch 1735/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1934 - acc: 0.9270\n",
            "Epoch 1736/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1992 - acc: 0.9265\n",
            "Epoch 1737/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2031 - acc: 0.9257\n",
            "Epoch 1738/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1950 - acc: 0.9279\n",
            "Epoch 1739/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1767 - acc: 0.9318\n",
            "Epoch 1740/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2151 - acc: 0.9250\n",
            "Epoch 1741/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2039 - acc: 0.9245\n",
            "Epoch 1742/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2191 - acc: 0.9236\n",
            "Epoch 1743/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1972 - acc: 0.9269\n",
            "Epoch 1744/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2004 - acc: 0.9260\n",
            "Epoch 1745/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1807 - acc: 0.9310\n",
            "Epoch 1746/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1738 - acc: 0.9324\n",
            "Epoch 1747/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1910 - acc: 0.9293\n",
            "Epoch 1748/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1924 - acc: 0.9291\n",
            "Epoch 1749/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1786 - acc: 0.9317\n",
            "Epoch 1750/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2207 - acc: 0.9214\n",
            "Epoch 1751/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1801 - acc: 0.9311\n",
            "Epoch 1752/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1837 - acc: 0.9304\n",
            "Epoch 1753/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1941 - acc: 0.9275\n",
            "Epoch 1754/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2012 - acc: 0.9252\n",
            "Epoch 1755/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1777 - acc: 0.9310\n",
            "Epoch 1756/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1933 - acc: 0.9272\n",
            "Epoch 1757/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.1959 - acc: 0.9249\n",
            "Epoch 1758/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1836 - acc: 0.9297\n",
            "Epoch 1759/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2165 - acc: 0.9210\n",
            "Epoch 1760/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1859 - acc: 0.9291\n",
            "Epoch 1761/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1847 - acc: 0.9303\n",
            "Epoch 1762/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1900 - acc: 0.9264\n",
            "Epoch 1763/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1765 - acc: 0.9321\n",
            "Epoch 1764/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2040 - acc: 0.9261\n",
            "Epoch 1765/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1789 - acc: 0.9314\n",
            "Epoch 1766/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2006 - acc: 0.9255\n",
            "Epoch 1767/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2101 - acc: 0.9211\n",
            "Epoch 1768/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1863 - acc: 0.9296\n",
            "Epoch 1769/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1780 - acc: 0.9284\n",
            "Epoch 1770/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1709 - acc: 0.9343\n",
            "Epoch 1771/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1886 - acc: 0.9304\n",
            "Epoch 1772/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2224 - acc: 0.9214\n",
            "Epoch 1773/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1827 - acc: 0.9322\n",
            "Epoch 1774/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1797 - acc: 0.9299\n",
            "Epoch 1775/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2397 - acc: 0.9198\n",
            "Epoch 1776/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1991 - acc: 0.9256\n",
            "Epoch 1777/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1705 - acc: 0.9338\n",
            "Epoch 1778/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1736 - acc: 0.9342\n",
            "Epoch 1779/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1838 - acc: 0.9290\n",
            "Epoch 1780/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1748 - acc: 0.9331\n",
            "Epoch 1781/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1945 - acc: 0.9289\n",
            "Epoch 1782/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1884 - acc: 0.9293\n",
            "Epoch 1783/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2344 - acc: 0.9167\n",
            "Epoch 1784/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1750 - acc: 0.9323\n",
            "Epoch 1785/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1878 - acc: 0.9282\n",
            "Epoch 1786/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2131 - acc: 0.9224\n",
            "Epoch 1787/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1863 - acc: 0.9304\n",
            "Epoch 1788/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2393 - acc: 0.9199\n",
            "Epoch 1789/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2300 - acc: 0.9203\n",
            "Epoch 1790/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1667 - acc: 0.9346\n",
            "Epoch 1791/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1675 - acc: 0.9351\n",
            "Epoch 1792/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1795 - acc: 0.9322\n",
            "Epoch 1793/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1855 - acc: 0.9291\n",
            "Epoch 1794/3000\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2060 - acc: 0.9237\n",
            "Epoch 1795/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1873 - acc: 0.9307\n",
            "Epoch 1796/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1767 - acc: 0.9319\n",
            "Epoch 1797/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1811 - acc: 0.9308\n",
            "Epoch 1798/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2121 - acc: 0.9223\n",
            "Epoch 1799/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1750 - acc: 0.9316\n",
            "Epoch 1800/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1809 - acc: 0.9311\n",
            "Epoch 1801/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.3240 - acc: 0.9170\n",
            "Epoch 1802/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1963 - acc: 0.9262\n",
            "Epoch 1803/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1743 - acc: 0.9331\n",
            "Epoch 1804/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2113 - acc: 0.9244\n",
            "Epoch 1805/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1868 - acc: 0.9294\n",
            "Epoch 1806/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2052 - acc: 0.9245\n",
            "Epoch 1807/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1938 - acc: 0.9300\n",
            "Epoch 1808/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1795 - acc: 0.9318\n",
            "Epoch 1809/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2116 - acc: 0.9230\n",
            "Epoch 1810/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1881 - acc: 0.9273\n",
            "Epoch 1811/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1803 - acc: 0.9324\n",
            "Epoch 1812/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1880 - acc: 0.9314\n",
            "Epoch 1813/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1941 - acc: 0.9272\n",
            "Epoch 1814/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2426 - acc: 0.9173\n",
            "Epoch 1815/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1951 - acc: 0.9276\n",
            "Epoch 1816/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1900 - acc: 0.9285\n",
            "Epoch 1817/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1710 - acc: 0.9334\n",
            "Epoch 1818/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1981 - acc: 0.9262\n",
            "Epoch 1819/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1839 - acc: 0.9291\n",
            "Epoch 1820/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1726 - acc: 0.9328\n",
            "Epoch 1821/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2056 - acc: 0.9255\n",
            "Epoch 1822/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2576 - acc: 0.9186\n",
            "Epoch 1823/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1768 - acc: 0.9324\n",
            "Epoch 1824/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1660 - acc: 0.9367\n",
            "Epoch 1825/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1847 - acc: 0.9309\n",
            "Epoch 1826/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1770 - acc: 0.9316\n",
            "Epoch 1827/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1799 - acc: 0.9317\n",
            "Epoch 1828/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2068 - acc: 0.9252\n",
            "Epoch 1829/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2050 - acc: 0.9245\n",
            "Epoch 1830/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1786 - acc: 0.9320\n",
            "Epoch 1831/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2131 - acc: 0.9255\n",
            "Epoch 1832/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1805 - acc: 0.9285\n",
            "Epoch 1833/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1872 - acc: 0.9290\n",
            "Epoch 1834/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1723 - acc: 0.9340\n",
            "Epoch 1835/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1840 - acc: 0.9308\n",
            "Epoch 1836/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1956 - acc: 0.9272\n",
            "Epoch 1837/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2028 - acc: 0.9271\n",
            "Epoch 1838/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1936 - acc: 0.9271\n",
            "Epoch 1839/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1986 - acc: 0.9267\n",
            "Epoch 1840/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1880 - acc: 0.9295\n",
            "Epoch 1841/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1900 - acc: 0.9292\n",
            "Epoch 1842/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2103 - acc: 0.9239\n",
            "Epoch 1843/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1803 - acc: 0.9313\n",
            "Epoch 1844/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1821 - acc: 0.9321\n",
            "Epoch 1845/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2055 - acc: 0.9268\n",
            "Epoch 1846/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1872 - acc: 0.9302\n",
            "Epoch 1847/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1877 - acc: 0.9277\n",
            "Epoch 1848/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1850 - acc: 0.9294\n",
            "Epoch 1849/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1754 - acc: 0.9327\n",
            "Epoch 1850/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2156 - acc: 0.9235\n",
            "Epoch 1851/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2059 - acc: 0.9255\n",
            "Epoch 1852/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2289 - acc: 0.9246\n",
            "Epoch 1853/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1943 - acc: 0.9309\n",
            "Epoch 1854/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1790 - acc: 0.9320\n",
            "Epoch 1855/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1749 - acc: 0.9338\n",
            "Epoch 1856/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1954 - acc: 0.9288\n",
            "Epoch 1857/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2085 - acc: 0.9254\n",
            "Epoch 1858/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1756 - acc: 0.9329\n",
            "Epoch 1859/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2043 - acc: 0.9251\n",
            "Epoch 1860/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1981 - acc: 0.9255\n",
            "Epoch 1861/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1827 - acc: 0.9304\n",
            "Epoch 1862/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2144 - acc: 0.9224\n",
            "Epoch 1863/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1743 - acc: 0.9327\n",
            "Epoch 1864/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1872 - acc: 0.9277\n",
            "Epoch 1865/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1922 - acc: 0.9297\n",
            "Epoch 1866/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1982 - acc: 0.9253\n",
            "Epoch 1867/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2007 - acc: 0.9249\n",
            "Epoch 1868/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2019 - acc: 0.9272\n",
            "Epoch 1869/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2398 - acc: 0.9203\n",
            "Epoch 1870/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1773 - acc: 0.9320\n",
            "Epoch 1871/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1677 - acc: 0.9340\n",
            "Epoch 1872/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1842 - acc: 0.9301\n",
            "Epoch 1873/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1820 - acc: 0.9306\n",
            "Epoch 1874/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1811 - acc: 0.9307\n",
            "Epoch 1875/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2049 - acc: 0.9249\n",
            "Epoch 1876/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1735 - acc: 0.9322\n",
            "Epoch 1877/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1782 - acc: 0.9322\n",
            "Epoch 1878/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2094 - acc: 0.9244\n",
            "Epoch 1879/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1852 - acc: 0.9317\n",
            "Epoch 1880/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1903 - acc: 0.9287\n",
            "Epoch 1881/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1755 - acc: 0.9323\n",
            "Epoch 1882/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1910 - acc: 0.9296\n",
            "Epoch 1883/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2086 - acc: 0.9231\n",
            "Epoch 1884/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2536 - acc: 0.9155\n",
            "Epoch 1885/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1860 - acc: 0.9301\n",
            "Epoch 1886/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1755 - acc: 0.9350\n",
            "Epoch 1887/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1738 - acc: 0.9336\n",
            "Epoch 1888/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1804 - acc: 0.9313\n",
            "Epoch 1889/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2572 - acc: 0.9168\n",
            "Epoch 1890/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2105 - acc: 0.9256\n",
            "Epoch 1891/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1693 - acc: 0.9344\n",
            "Epoch 1892/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1638 - acc: 0.9359\n",
            "Epoch 1893/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2038 - acc: 0.9249\n",
            "Epoch 1894/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1730 - acc: 0.9340\n",
            "Epoch 1895/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1907 - acc: 0.9293\n",
            "Epoch 1896/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1989 - acc: 0.9260\n",
            "Epoch 1897/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1784 - acc: 0.9321\n",
            "Epoch 1898/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1955 - acc: 0.9268\n",
            "Epoch 1899/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2124 - acc: 0.9216\n",
            "Epoch 1900/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2247 - acc: 0.9195\n",
            "Epoch 1901/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1729 - acc: 0.9322\n",
            "Epoch 1902/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2143 - acc: 0.9290\n",
            "Epoch 1903/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2104 - acc: 0.9230\n",
            "Epoch 1904/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1609 - acc: 0.9369\n",
            "Epoch 1905/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2021 - acc: 0.9264\n",
            "Epoch 1906/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1792 - acc: 0.9321\n",
            "Epoch 1907/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1729 - acc: 0.9335\n",
            "Epoch 1908/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2060 - acc: 0.9236\n",
            "Epoch 1909/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2504 - acc: 0.9216\n",
            "Epoch 1910/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1830 - acc: 0.9312\n",
            "Epoch 1911/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1898 - acc: 0.9292\n",
            "Epoch 1912/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1671 - acc: 0.9358\n",
            "Epoch 1913/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1693 - acc: 0.9351\n",
            "Epoch 1914/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1857 - acc: 0.9290\n",
            "Epoch 1915/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1819 - acc: 0.9305\n",
            "Epoch 1916/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1941 - acc: 0.9271\n",
            "Epoch 1917/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1879 - acc: 0.9290\n",
            "Epoch 1918/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2169 - acc: 0.9224\n",
            "Epoch 1919/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2024 - acc: 0.9260\n",
            "Epoch 1920/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1840 - acc: 0.9302\n",
            "Epoch 1921/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2259 - acc: 0.9216\n",
            "Epoch 1922/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1831 - acc: 0.9301\n",
            "Epoch 1923/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1791 - acc: 0.9320\n",
            "Epoch 1924/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1816 - acc: 0.9308\n",
            "Epoch 1925/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1914 - acc: 0.9300\n",
            "Epoch 1926/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1808 - acc: 0.9312\n",
            "Epoch 1927/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1872 - acc: 0.9301\n",
            "Epoch 1928/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1923 - acc: 0.9278\n",
            "Epoch 1929/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1831 - acc: 0.9312\n",
            "Epoch 1930/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1761 - acc: 0.9325\n",
            "Epoch 1931/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1827 - acc: 0.9317\n",
            "Epoch 1932/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1772 - acc: 0.9324\n",
            "Epoch 1933/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1779 - acc: 0.9337\n",
            "Epoch 1934/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1955 - acc: 0.9283\n",
            "Epoch 1935/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2078 - acc: 0.9239\n",
            "Epoch 1936/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1807 - acc: 0.9323\n",
            "Epoch 1937/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2006 - acc: 0.9273\n",
            "Epoch 1938/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2069 - acc: 0.9228\n",
            "Epoch 1939/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1740 - acc: 0.9330\n",
            "Epoch 1940/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1684 - acc: 0.9350\n",
            "Epoch 1941/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1732 - acc: 0.9344\n",
            "Epoch 1942/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1939 - acc: 0.9278\n",
            "Epoch 1943/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1970 - acc: 0.9257\n",
            "Epoch 1944/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2237 - acc: 0.9224\n",
            "Epoch 1945/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1894 - acc: 0.9284\n",
            "Epoch 1946/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2083 - acc: 0.9260\n",
            "Epoch 1947/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1890 - acc: 0.9314\n",
            "Epoch 1948/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2131 - acc: 0.9243\n",
            "Epoch 1949/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1703 - acc: 0.9344\n",
            "Epoch 1950/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2147 - acc: 0.9222\n",
            "Epoch 1951/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2170 - acc: 0.9233\n",
            "Epoch 1952/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1729 - acc: 0.9332\n",
            "Epoch 1953/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1907 - acc: 0.9292\n",
            "Epoch 1954/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1896 - acc: 0.9284\n",
            "Epoch 1955/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1745 - acc: 0.9336\n",
            "Epoch 1956/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2271 - acc: 0.9233\n",
            "Epoch 1957/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1986 - acc: 0.9245\n",
            "Epoch 1958/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1710 - acc: 0.9327\n",
            "Epoch 1959/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1855 - acc: 0.9304\n",
            "Epoch 1960/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1821 - acc: 0.9309\n",
            "Epoch 1961/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2023 - acc: 0.9269\n",
            "Epoch 1962/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1837 - acc: 0.9287\n",
            "Epoch 1963/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1772 - acc: 0.9320\n",
            "Epoch 1964/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2048 - acc: 0.9253\n",
            "Epoch 1965/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1722 - acc: 0.9348\n",
            "Epoch 1966/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1875 - acc: 0.9292\n",
            "Epoch 1967/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1766 - acc: 0.9332\n",
            "Epoch 1968/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1866 - acc: 0.9284\n",
            "Epoch 1969/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1979 - acc: 0.9308\n",
            "Epoch 1970/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2050 - acc: 0.9247\n",
            "Epoch 1971/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1671 - acc: 0.9335\n",
            "Epoch 1972/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1911 - acc: 0.9292\n",
            "Epoch 1973/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2267 - acc: 0.9215\n",
            "Epoch 1974/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1803 - acc: 0.9314\n",
            "Epoch 1975/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1889 - acc: 0.9282\n",
            "Epoch 1976/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2155 - acc: 0.9222\n",
            "Epoch 1977/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1839 - acc: 0.9299\n",
            "Epoch 1978/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1912 - acc: 0.9292\n",
            "Epoch 1979/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1712 - acc: 0.9329\n",
            "Epoch 1980/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1727 - acc: 0.9335\n",
            "Epoch 1981/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1714 - acc: 0.9341\n",
            "Epoch 1982/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1803 - acc: 0.9314\n",
            "Epoch 1983/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2204 - acc: 0.9228\n",
            "Epoch 1984/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2483 - acc: 0.9181\n",
            "Epoch 1985/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1580 - acc: 0.9375\n",
            "Epoch 1986/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1645 - acc: 0.9353\n",
            "Epoch 1987/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1790 - acc: 0.9324\n",
            "Epoch 1988/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1786 - acc: 0.9317\n",
            "Epoch 1989/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1810 - acc: 0.9308\n",
            "Epoch 1990/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1943 - acc: 0.9275\n",
            "Epoch 1991/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1887 - acc: 0.9283\n",
            "Epoch 1992/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1709 - acc: 0.9344\n",
            "Epoch 1993/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1777 - acc: 0.9321\n",
            "Epoch 1994/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1857 - acc: 0.9286\n",
            "Epoch 1995/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1876 - acc: 0.9297\n",
            "Epoch 1996/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1843 - acc: 0.9301\n",
            "Epoch 1997/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1771 - acc: 0.9329\n",
            "Epoch 1998/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1809 - acc: 0.9327\n",
            "Epoch 1999/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1859 - acc: 0.9303\n",
            "Epoch 2000/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1874 - acc: 0.9309\n",
            "Epoch 2001/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1813 - acc: 0.9322\n",
            "Epoch 2002/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1913 - acc: 0.9276\n",
            "Epoch 2003/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2047 - acc: 0.9246\n",
            "Epoch 2004/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2006 - acc: 0.9273\n",
            "Epoch 2005/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1659 - acc: 0.9354\n",
            "Epoch 2006/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2006 - acc: 0.9261\n",
            "Epoch 2007/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1879 - acc: 0.9294\n",
            "Epoch 2008/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1992 - acc: 0.9272\n",
            "Epoch 2009/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1736 - acc: 0.9343\n",
            "Epoch 2010/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1811 - acc: 0.9319\n",
            "Epoch 2011/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1860 - acc: 0.9308\n",
            "Epoch 2012/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1790 - acc: 0.9322\n",
            "Epoch 2013/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1917 - acc: 0.9292\n",
            "Epoch 2014/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1832 - acc: 0.9317\n",
            "Epoch 2015/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1857 - acc: 0.9296\n",
            "Epoch 2016/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1928 - acc: 0.9295\n",
            "Epoch 2017/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1748 - acc: 0.9331\n",
            "Epoch 2018/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1872 - acc: 0.9296\n",
            "Epoch 2019/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2361 - acc: 0.9182\n",
            "Epoch 2020/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1899 - acc: 0.9272\n",
            "Epoch 2021/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1693 - acc: 0.9339\n",
            "Epoch 2022/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1827 - acc: 0.9323\n",
            "Epoch 2023/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1929 - acc: 0.9283\n",
            "Epoch 2024/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2024 - acc: 0.9263\n",
            "Epoch 2025/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2558 - acc: 0.9251\n",
            "Epoch 2026/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1991 - acc: 0.9295\n",
            "Epoch 2027/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1833 - acc: 0.9309\n",
            "Epoch 2028/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2080 - acc: 0.9233\n",
            "Epoch 2029/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1952 - acc: 0.9305\n",
            "Epoch 2030/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2137 - acc: 0.9215\n",
            "Epoch 2031/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1837 - acc: 0.9286\n",
            "Epoch 2032/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1811 - acc: 0.9309\n",
            "Epoch 2033/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1835 - acc: 0.9298\n",
            "Epoch 2034/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1765 - acc: 0.9328\n",
            "Epoch 2035/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1777 - acc: 0.9335\n",
            "Epoch 2036/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1893 - acc: 0.9300\n",
            "Epoch 2037/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1816 - acc: 0.9326\n",
            "Epoch 2038/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2311 - acc: 0.9195\n",
            "Epoch 2039/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1831 - acc: 0.9304\n",
            "Epoch 2040/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1763 - acc: 0.9329\n",
            "Epoch 2041/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1826 - acc: 0.9316\n",
            "Epoch 2042/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1995 - acc: 0.9256\n",
            "Epoch 2043/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1799 - acc: 0.9310\n",
            "Epoch 2044/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1791 - acc: 0.9325\n",
            "Epoch 2045/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1727 - acc: 0.9343\n",
            "Epoch 2046/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1822 - acc: 0.9311\n",
            "Epoch 2047/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2165 - acc: 0.9206\n",
            "Epoch 2048/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2131 - acc: 0.9253\n",
            "Epoch 2049/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1864 - acc: 0.9313\n",
            "Epoch 2050/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1732 - acc: 0.9330\n",
            "Epoch 2051/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1805 - acc: 0.9314\n",
            "Epoch 2052/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1769 - acc: 0.9326\n",
            "Epoch 2053/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2075 - acc: 0.9255\n",
            "Epoch 2054/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1828 - acc: 0.9316\n",
            "Epoch 2055/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1853 - acc: 0.9292\n",
            "Epoch 2056/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1638 - acc: 0.9379\n",
            "Epoch 2057/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2147 - acc: 0.9234\n",
            "Epoch 2058/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1724 - acc: 0.9343\n",
            "Epoch 2059/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1797 - acc: 0.9318\n",
            "Epoch 2060/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1755 - acc: 0.9321\n",
            "Epoch 2061/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1963 - acc: 0.9258\n",
            "Epoch 2062/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1835 - acc: 0.9303\n",
            "Epoch 2063/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1681 - acc: 0.9350\n",
            "Epoch 2064/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2127 - acc: 0.9249\n",
            "Epoch 2065/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1799 - acc: 0.9310\n",
            "Epoch 2066/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2872 - acc: 0.9161\n",
            "Epoch 2067/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2076 - acc: 0.9282\n",
            "Epoch 2068/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1818 - acc: 0.9313\n",
            "Epoch 2069/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2290 - acc: 0.9225\n",
            "Epoch 2070/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1785 - acc: 0.9312\n",
            "Epoch 2071/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1640 - acc: 0.9361\n",
            "Epoch 2072/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1802 - acc: 0.9325\n",
            "Epoch 2073/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2069 - acc: 0.9254\n",
            "Epoch 2074/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1760 - acc: 0.9335\n",
            "Epoch 2075/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1735 - acc: 0.9323\n",
            "Epoch 2076/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1792 - acc: 0.9327\n",
            "Epoch 2077/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2058 - acc: 0.9240\n",
            "Epoch 2078/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1847 - acc: 0.9308\n",
            "Epoch 2079/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1766 - acc: 0.9309\n",
            "Epoch 2080/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1950 - acc: 0.9257\n",
            "Epoch 2081/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1760 - acc: 0.9333\n",
            "Epoch 2082/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1925 - acc: 0.9299\n",
            "Epoch 2083/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1754 - acc: 0.9327\n",
            "Epoch 2084/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1769 - acc: 0.9305\n",
            "Epoch 2085/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1686 - acc: 0.9344\n",
            "Epoch 2086/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1792 - acc: 0.9322\n",
            "Epoch 2087/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1775 - acc: 0.9330\n",
            "Epoch 2088/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2110 - acc: 0.9242\n",
            "Epoch 2089/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2125 - acc: 0.9275\n",
            "Epoch 2090/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1995 - acc: 0.9258\n",
            "Epoch 2091/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1837 - acc: 0.9293\n",
            "Epoch 2092/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2234 - acc: 0.9211\n",
            "Epoch 2093/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1664 - acc: 0.9349\n",
            "Epoch 2094/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1712 - acc: 0.9343\n",
            "Epoch 2095/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2230 - acc: 0.9210\n",
            "Epoch 2096/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2099 - acc: 0.9249\n",
            "Epoch 2097/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1618 - acc: 0.9359\n",
            "Epoch 2098/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1587 - acc: 0.9375\n",
            "Epoch 2099/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1934 - acc: 0.9263\n",
            "Epoch 2100/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2166 - acc: 0.9233\n",
            "Epoch 2101/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2210 - acc: 0.9189\n",
            "Epoch 2102/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1704 - acc: 0.9339\n",
            "Epoch 2103/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1757 - acc: 0.9323\n",
            "Epoch 2104/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1817 - acc: 0.9318\n",
            "Epoch 2105/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1687 - acc: 0.9352\n",
            "Epoch 2106/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1700 - acc: 0.9347\n",
            "Epoch 2107/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1830 - acc: 0.9312\n",
            "Epoch 2108/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2030 - acc: 0.9285\n",
            "Epoch 2109/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2089 - acc: 0.9238\n",
            "Epoch 2110/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2041 - acc: 0.9264\n",
            "Epoch 2111/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1697 - acc: 0.9340\n",
            "Epoch 2112/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1708 - acc: 0.9331\n",
            "Epoch 2113/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2275 - acc: 0.9234\n",
            "Epoch 2114/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2075 - acc: 0.9231\n",
            "Epoch 2115/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1738 - acc: 0.9319\n",
            "Epoch 2116/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1854 - acc: 0.9304\n",
            "Epoch 2117/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1670 - acc: 0.9342\n",
            "Epoch 2118/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1792 - acc: 0.9317\n",
            "Epoch 2119/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1751 - acc: 0.9332\n",
            "Epoch 2120/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2080 - acc: 0.9255\n",
            "Epoch 2121/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2117 - acc: 0.9297\n",
            "Epoch 2122/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2161 - acc: 0.9254\n",
            "Epoch 2123/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2271 - acc: 0.9244\n",
            "Epoch 2124/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1870 - acc: 0.9315\n",
            "Epoch 2125/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1883 - acc: 0.9308\n",
            "Epoch 2126/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1837 - acc: 0.9317\n",
            "Epoch 2127/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1633 - acc: 0.9364\n",
            "Epoch 2128/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1811 - acc: 0.9311\n",
            "Epoch 2129/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2119 - acc: 0.9234\n",
            "Epoch 2130/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1842 - acc: 0.9302\n",
            "Epoch 2131/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1772 - acc: 0.9339\n",
            "Epoch 2132/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1788 - acc: 0.9322\n",
            "Epoch 2133/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1839 - acc: 0.9315\n",
            "Epoch 2134/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1731 - acc: 0.9345\n",
            "Epoch 2135/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2029 - acc: 0.9247\n",
            "Epoch 2136/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1762 - acc: 0.9322\n",
            "Epoch 2137/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2103 - acc: 0.9244\n",
            "Epoch 2138/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1797 - acc: 0.9330\n",
            "Epoch 2139/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1658 - acc: 0.9361\n",
            "Epoch 2140/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1996 - acc: 0.9291\n",
            "Epoch 2141/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2020 - acc: 0.9254\n",
            "Epoch 2142/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2386 - acc: 0.9259\n",
            "Epoch 2143/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2002 - acc: 0.9276\n",
            "Epoch 2144/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1775 - acc: 0.9323\n",
            "Epoch 2145/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1827 - acc: 0.9304\n",
            "Epoch 2146/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1617 - acc: 0.9363\n",
            "Epoch 2147/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1823 - acc: 0.9313\n",
            "Epoch 2148/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1899 - acc: 0.9320\n",
            "Epoch 2149/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1868 - acc: 0.9284\n",
            "Epoch 2150/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1986 - acc: 0.9289\n",
            "Epoch 2151/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2023 - acc: 0.9260\n",
            "Epoch 2152/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1735 - acc: 0.9331\n",
            "Epoch 2153/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1915 - acc: 0.9300\n",
            "Epoch 2154/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1894 - acc: 0.9290\n",
            "Epoch 2155/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1733 - acc: 0.9335\n",
            "Epoch 2156/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1827 - acc: 0.9326\n",
            "Epoch 2157/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1816 - acc: 0.9315\n",
            "Epoch 2158/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2050 - acc: 0.9255\n",
            "Epoch 2159/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1825 - acc: 0.9300\n",
            "Epoch 2160/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1781 - acc: 0.9318\n",
            "Epoch 2161/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1842 - acc: 0.9323\n",
            "Epoch 2162/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1740 - acc: 0.9327\n",
            "Epoch 2163/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1776 - acc: 0.9335\n",
            "Epoch 2164/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2090 - acc: 0.9297\n",
            "Epoch 2165/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2271 - acc: 0.9230\n",
            "Epoch 2166/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1782 - acc: 0.9331\n",
            "Epoch 2167/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1623 - acc: 0.9362\n",
            "Epoch 2168/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1929 - acc: 0.9278\n",
            "Epoch 2169/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1666 - acc: 0.9351\n",
            "Epoch 2170/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1747 - acc: 0.9322\n",
            "Epoch 2171/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2350 - acc: 0.9240\n",
            "Epoch 2172/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1808 - acc: 0.9297\n",
            "Epoch 2173/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1634 - acc: 0.9354\n",
            "Epoch 2174/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1779 - acc: 0.9332\n",
            "Epoch 2175/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1855 - acc: 0.9302\n",
            "Epoch 2176/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2469 - acc: 0.9204\n",
            "Epoch 2177/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1898 - acc: 0.9291\n",
            "Epoch 2178/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1608 - acc: 0.9367\n",
            "Epoch 2179/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1700 - acc: 0.9340\n",
            "Epoch 2180/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1801 - acc: 0.9322\n",
            "Epoch 2181/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1856 - acc: 0.9300\n",
            "Epoch 2182/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1705 - acc: 0.9340\n",
            "Epoch 2183/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1789 - acc: 0.9309\n",
            "Epoch 2184/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1881 - acc: 0.9286\n",
            "Epoch 2185/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1751 - acc: 0.9332\n",
            "Epoch 2186/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1853 - acc: 0.9309\n",
            "Epoch 2187/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2221 - acc: 0.9229\n",
            "Epoch 2188/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2106 - acc: 0.9246\n",
            "Epoch 2189/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1731 - acc: 0.9333\n",
            "Epoch 2190/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1688 - acc: 0.9359\n",
            "Epoch 2191/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1690 - acc: 0.9349\n",
            "Epoch 2192/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2016 - acc: 0.9262\n",
            "Epoch 2193/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1824 - acc: 0.9292\n",
            "Epoch 2194/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1691 - acc: 0.9352\n",
            "Epoch 2195/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1817 - acc: 0.9306\n",
            "Epoch 2196/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1775 - acc: 0.9325\n",
            "Epoch 2197/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1726 - acc: 0.9342\n",
            "Epoch 2198/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1788 - acc: 0.9312\n",
            "Epoch 2199/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2008 - acc: 0.9267\n",
            "Epoch 2200/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1953 - acc: 0.9271\n",
            "Epoch 2201/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1691 - acc: 0.9326\n",
            "Epoch 2202/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1928 - acc: 0.9284\n",
            "Epoch 2203/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2000 - acc: 0.9265\n",
            "Epoch 2204/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1820 - acc: 0.9315\n",
            "Epoch 2205/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1718 - acc: 0.9336\n",
            "Epoch 2206/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1703 - acc: 0.9351\n",
            "Epoch 2207/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1930 - acc: 0.9284\n",
            "Epoch 2208/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2029 - acc: 0.9274\n",
            "Epoch 2209/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2138 - acc: 0.9227\n",
            "Epoch 2210/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1698 - acc: 0.9352\n",
            "Epoch 2211/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1672 - acc: 0.9345\n",
            "Epoch 2212/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1745 - acc: 0.9328\n",
            "Epoch 2213/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1915 - acc: 0.9291\n",
            "Epoch 2214/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1891 - acc: 0.9295\n",
            "Epoch 2215/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1832 - acc: 0.9318\n",
            "Epoch 2216/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2177 - acc: 0.9245\n",
            "Epoch 2217/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1650 - acc: 0.9365\n",
            "Epoch 2218/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1948 - acc: 0.9292\n",
            "Epoch 2219/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1746 - acc: 0.9321\n",
            "Epoch 2220/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1772 - acc: 0.9325\n",
            "Epoch 2221/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1912 - acc: 0.9303\n",
            "Epoch 2222/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2470 - acc: 0.9136\n",
            "Epoch 2223/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1659 - acc: 0.9360\n",
            "Epoch 2224/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1702 - acc: 0.9340\n",
            "Epoch 2225/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1755 - acc: 0.9337\n",
            "Epoch 2226/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1867 - acc: 0.9306\n",
            "Epoch 2227/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2103 - acc: 0.9274\n",
            "Epoch 2228/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1734 - acc: 0.9332\n",
            "Epoch 2229/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1826 - acc: 0.9308\n",
            "Epoch 2230/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1977 - acc: 0.9285\n",
            "Epoch 2231/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1884 - acc: 0.9325\n",
            "Epoch 2232/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1655 - acc: 0.9355\n",
            "Epoch 2233/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2282 - acc: 0.9185\n",
            "Epoch 2234/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1877 - acc: 0.9309\n",
            "Epoch 2235/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1599 - acc: 0.9369\n",
            "Epoch 2236/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1658 - acc: 0.9362\n",
            "Epoch 2237/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1804 - acc: 0.9332\n",
            "Epoch 2238/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2376 - acc: 0.9212\n",
            "Epoch 2239/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1791 - acc: 0.9308\n",
            "Epoch 2240/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1666 - acc: 0.9364\n",
            "Epoch 2241/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2750 - acc: 0.9159\n",
            "Epoch 2242/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1758 - acc: 0.9333\n",
            "Epoch 2243/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1665 - acc: 0.9343\n",
            "Epoch 2244/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1739 - acc: 0.9342\n",
            "Epoch 2245/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1780 - acc: 0.9331\n",
            "Epoch 2246/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1986 - acc: 0.9280\n",
            "Epoch 2247/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2079 - acc: 0.9240\n",
            "Epoch 2248/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1889 - acc: 0.9286\n",
            "Epoch 2249/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1999 - acc: 0.9272\n",
            "Epoch 2250/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1811 - acc: 0.9312\n",
            "Epoch 2251/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1646 - acc: 0.9358\n",
            "Epoch 2252/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1736 - acc: 0.9357\n",
            "Epoch 2253/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1793 - acc: 0.9324\n",
            "Epoch 2254/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1850 - acc: 0.9289\n",
            "Epoch 2255/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1686 - acc: 0.9352\n",
            "Epoch 2256/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1882 - acc: 0.9293\n",
            "Epoch 2257/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2021 - acc: 0.9269\n",
            "Epoch 2258/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2062 - acc: 0.9263\n",
            "Epoch 2259/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2068 - acc: 0.9253\n",
            "Epoch 2260/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1756 - acc: 0.9342\n",
            "Epoch 2261/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2014 - acc: 0.9266\n",
            "Epoch 2262/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1866 - acc: 0.9306\n",
            "Epoch 2263/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1645 - acc: 0.9361\n",
            "Epoch 2264/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1823 - acc: 0.9315\n",
            "Epoch 2265/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1802 - acc: 0.9318\n",
            "Epoch 2266/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1828 - acc: 0.9304\n",
            "Epoch 2267/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1759 - acc: 0.9335\n",
            "Epoch 2268/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2048 - acc: 0.9239\n",
            "Epoch 2269/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1940 - acc: 0.9284\n",
            "Epoch 2270/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1796 - acc: 0.9326\n",
            "Epoch 2271/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1803 - acc: 0.9313\n",
            "Epoch 2272/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1852 - acc: 0.9310\n",
            "Epoch 2273/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1750 - acc: 0.9326\n",
            "Epoch 2274/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1656 - acc: 0.9362\n",
            "Epoch 2275/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1759 - acc: 0.9345\n",
            "Epoch 2276/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1951 - acc: 0.9297\n",
            "Epoch 2277/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1781 - acc: 0.9328\n",
            "Epoch 2278/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2520 - acc: 0.9198\n",
            "Epoch 2279/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1728 - acc: 0.9340\n",
            "Epoch 2280/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1724 - acc: 0.9333\n",
            "Epoch 2281/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1772 - acc: 0.9338\n",
            "Epoch 2282/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1936 - acc: 0.9259\n",
            "Epoch 2283/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1912 - acc: 0.9303\n",
            "Epoch 2284/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1703 - acc: 0.9342\n",
            "Epoch 2285/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1763 - acc: 0.9333\n",
            "Epoch 2286/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1769 - acc: 0.9330\n",
            "Epoch 2287/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1707 - acc: 0.9354\n",
            "Epoch 2288/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1936 - acc: 0.9295\n",
            "Epoch 2289/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1693 - acc: 0.9354\n",
            "Epoch 2290/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1983 - acc: 0.9274\n",
            "Epoch 2291/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1981 - acc: 0.9259\n",
            "Epoch 2292/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2469 - acc: 0.9222\n",
            "Epoch 2293/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1567 - acc: 0.9388\n",
            "Epoch 2294/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1795 - acc: 0.9326\n",
            "Epoch 2295/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2050 - acc: 0.9263\n",
            "Epoch 2296/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1839 - acc: 0.9305\n",
            "Epoch 2297/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1680 - acc: 0.9340\n",
            "Epoch 2298/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1618 - acc: 0.9375\n",
            "Epoch 2299/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1829 - acc: 0.9330\n",
            "Epoch 2300/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1889 - acc: 0.9321\n",
            "Epoch 2301/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2028 - acc: 0.9264\n",
            "Epoch 2302/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1894 - acc: 0.9315\n",
            "Epoch 2303/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1707 - acc: 0.9351\n",
            "Epoch 2304/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1824 - acc: 0.9325\n",
            "Epoch 2305/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1860 - acc: 0.9330\n",
            "Epoch 2306/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1844 - acc: 0.9328\n",
            "Epoch 2307/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1636 - acc: 0.9347\n",
            "Epoch 2308/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1995 - acc: 0.9268\n",
            "Epoch 2309/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2099 - acc: 0.9257\n",
            "Epoch 2310/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1921 - acc: 0.9294\n",
            "Epoch 2311/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1919 - acc: 0.9338\n",
            "Epoch 2312/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1768 - acc: 0.9316\n",
            "Epoch 2313/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1750 - acc: 0.9316\n",
            "Epoch 2314/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1784 - acc: 0.9330\n",
            "Epoch 2315/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1929 - acc: 0.9304\n",
            "Epoch 2316/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1939 - acc: 0.9290\n",
            "Epoch 2317/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2061 - acc: 0.9308\n",
            "Epoch 2318/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2246 - acc: 0.9203\n",
            "Epoch 2319/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1932 - acc: 0.9303\n",
            "Epoch 2320/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1706 - acc: 0.9336\n",
            "Epoch 2321/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1570 - acc: 0.9383\n",
            "Epoch 2322/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1676 - acc: 0.9355\n",
            "Epoch 2323/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1828 - acc: 0.9320\n",
            "Epoch 2324/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1822 - acc: 0.9289\n",
            "Epoch 2325/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2018 - acc: 0.9272\n",
            "Epoch 2326/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2018 - acc: 0.9252\n",
            "Epoch 2327/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1801 - acc: 0.9324\n",
            "Epoch 2328/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1734 - acc: 0.9343\n",
            "Epoch 2329/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2051 - acc: 0.9252\n",
            "Epoch 2330/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1919 - acc: 0.9297\n",
            "Epoch 2331/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2233 - acc: 0.9236\n",
            "Epoch 2332/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2048 - acc: 0.9267\n",
            "Epoch 2333/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1819 - acc: 0.9329\n",
            "Epoch 2334/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1620 - acc: 0.9368\n",
            "Epoch 2335/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1801 - acc: 0.9327\n",
            "Epoch 2336/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1773 - acc: 0.9325\n",
            "Epoch 2337/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.2184 - acc: 0.9235\n",
            "Epoch 2338/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2071 - acc: 0.9253\n",
            "Epoch 2339/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1630 - acc: 0.9359\n",
            "Epoch 2340/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1630 - acc: 0.9373\n",
            "Epoch 2341/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2156 - acc: 0.9238\n",
            "Epoch 2342/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1753 - acc: 0.9331\n",
            "Epoch 2343/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1745 - acc: 0.9340\n",
            "Epoch 2344/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1677 - acc: 0.9358\n",
            "Epoch 2345/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1945 - acc: 0.9285\n",
            "Epoch 2346/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1910 - acc: 0.9300\n",
            "Epoch 2347/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1700 - acc: 0.9341\n",
            "Epoch 2348/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1899 - acc: 0.9291\n",
            "Epoch 2349/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1880 - acc: 0.9298\n",
            "Epoch 2350/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1900 - acc: 0.9291\n",
            "Epoch 2351/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1943 - acc: 0.9299\n",
            "Epoch 2352/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1831 - acc: 0.9316\n",
            "Epoch 2353/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1646 - acc: 0.9367\n",
            "Epoch 2354/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1783 - acc: 0.9329\n",
            "Epoch 2355/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2283 - acc: 0.9206\n",
            "Epoch 2356/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1627 - acc: 0.9356\n",
            "Epoch 2357/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1813 - acc: 0.9344\n",
            "Epoch 2358/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2347 - acc: 0.9255\n",
            "Epoch 2359/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1909 - acc: 0.9294\n",
            "Epoch 2360/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1677 - acc: 0.9358\n",
            "Epoch 2361/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1607 - acc: 0.9370\n",
            "Epoch 2362/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1816 - acc: 0.9297\n",
            "Epoch 2363/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1955 - acc: 0.9281\n",
            "Epoch 2364/3000\n",
            "896/896 [==============================] - 3s 4ms/step - loss: 0.1917 - acc: 0.9301\n",
            "Epoch 2365/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1617 - acc: 0.9366\n",
            "Epoch 2366/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1980 - acc: 0.9314\n",
            "Epoch 2367/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1869 - acc: 0.9295\n",
            "Epoch 2368/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1780 - acc: 0.9320\n",
            "Epoch 2369/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2111 - acc: 0.9221\n",
            "Epoch 2370/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2061 - acc: 0.9296\n",
            "Epoch 2371/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1807 - acc: 0.9317\n",
            "Epoch 2372/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1600 - acc: 0.9373\n",
            "Epoch 2373/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1628 - acc: 0.9362\n",
            "Epoch 2374/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1930 - acc: 0.9295\n",
            "Epoch 2375/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2045 - acc: 0.9285\n",
            "Epoch 2376/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1739 - acc: 0.9359\n",
            "Epoch 2377/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1981 - acc: 0.9248\n",
            "Epoch 2378/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1902 - acc: 0.9302\n",
            "Epoch 2379/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2121 - acc: 0.9273\n",
            "Epoch 2380/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1675 - acc: 0.9345\n",
            "Epoch 2381/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1624 - acc: 0.9369\n",
            "Epoch 2382/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1979 - acc: 0.9277\n",
            "Epoch 2383/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1825 - acc: 0.9319\n",
            "Epoch 2384/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2192 - acc: 0.9229\n",
            "Epoch 2385/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1982 - acc: 0.9245\n",
            "Epoch 2386/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1655 - acc: 0.9363\n",
            "Epoch 2387/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1580 - acc: 0.9380\n",
            "Epoch 2388/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1816 - acc: 0.9322\n",
            "Epoch 2389/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1978 - acc: 0.9298\n",
            "Epoch 2390/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1944 - acc: 0.9277\n",
            "Epoch 2391/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2072 - acc: 0.9292\n",
            "Epoch 2392/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2050 - acc: 0.9280\n",
            "Epoch 2393/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1695 - acc: 0.9343\n",
            "Epoch 2394/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1774 - acc: 0.9362\n",
            "Epoch 2395/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1799 - acc: 0.9311\n",
            "Epoch 2396/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1787 - acc: 0.9343\n",
            "Epoch 2397/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1774 - acc: 0.9330\n",
            "Epoch 2398/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1687 - acc: 0.9353\n",
            "Epoch 2399/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1914 - acc: 0.9307\n",
            "Epoch 2400/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1868 - acc: 0.9297\n",
            "Epoch 2401/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1702 - acc: 0.9361\n",
            "Epoch 2402/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2176 - acc: 0.9247\n",
            "Epoch 2403/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1886 - acc: 0.9317\n",
            "Epoch 2404/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1596 - acc: 0.9368\n",
            "Epoch 2405/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2283 - acc: 0.9244\n",
            "Epoch 2406/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1906 - acc: 0.9286\n",
            "Epoch 2407/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1600 - acc: 0.9365\n",
            "Epoch 2408/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2175 - acc: 0.9243\n",
            "Epoch 2409/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2042 - acc: 0.9276\n",
            "Epoch 2410/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2042 - acc: 0.9274\n",
            "Epoch 2411/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1610 - acc: 0.9349\n",
            "Epoch 2412/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1680 - acc: 0.9330\n",
            "Epoch 2413/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1729 - acc: 0.9321\n",
            "Epoch 2414/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1842 - acc: 0.9304\n",
            "Epoch 2415/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1941 - acc: 0.9284\n",
            "Epoch 2416/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1862 - acc: 0.9313\n",
            "Epoch 2417/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1850 - acc: 0.9327\n",
            "Epoch 2418/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1904 - acc: 0.9285\n",
            "Epoch 2419/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2024 - acc: 0.9270\n",
            "Epoch 2420/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1765 - acc: 0.9322\n",
            "Epoch 2421/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1796 - acc: 0.9317\n",
            "Epoch 2422/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1747 - acc: 0.9325\n",
            "Epoch 2423/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1754 - acc: 0.9342\n",
            "Epoch 2424/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1743 - acc: 0.9330\n",
            "Epoch 2425/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1963 - acc: 0.9278\n",
            "Epoch 2426/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2090 - acc: 0.9260\n",
            "Epoch 2427/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2041 - acc: 0.9263\n",
            "Epoch 2428/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2255 - acc: 0.9241\n",
            "Epoch 2429/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2030 - acc: 0.9251\n",
            "Epoch 2430/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1657 - acc: 0.9358\n",
            "Epoch 2431/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1718 - acc: 0.9351\n",
            "Epoch 2432/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1759 - acc: 0.9326\n",
            "Epoch 2433/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1880 - acc: 0.9283\n",
            "Epoch 2434/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1889 - acc: 0.9306\n",
            "Epoch 2435/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1719 - acc: 0.9337\n",
            "Epoch 2436/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1781 - acc: 0.9329\n",
            "Epoch 2437/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1955 - acc: 0.9267\n",
            "Epoch 2438/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1666 - acc: 0.9363\n",
            "Epoch 2439/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1695 - acc: 0.9351\n",
            "Epoch 2440/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1675 - acc: 0.9346\n",
            "Epoch 2441/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1790 - acc: 0.9313\n",
            "Epoch 2442/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2264 - acc: 0.9205\n",
            "Epoch 2443/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1730 - acc: 0.9330\n",
            "Epoch 2444/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1723 - acc: 0.9337\n",
            "Epoch 2445/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1751 - acc: 0.9340\n",
            "Epoch 2446/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2118 - acc: 0.9250\n",
            "Epoch 2447/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1825 - acc: 0.9312\n",
            "Epoch 2448/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1620 - acc: 0.9384\n",
            "Epoch 2449/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2275 - acc: 0.9223\n",
            "Epoch 2450/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1841 - acc: 0.9295\n",
            "Epoch 2451/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1869 - acc: 0.9302\n",
            "Epoch 2452/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1808 - acc: 0.9338\n",
            "Epoch 2453/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1685 - acc: 0.9355\n",
            "Epoch 2454/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1601 - acc: 0.9382\n",
            "Epoch 2455/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2105 - acc: 0.9252\n",
            "Epoch 2456/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1862 - acc: 0.9304\n",
            "Epoch 2457/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1779 - acc: 0.9328\n",
            "Epoch 2458/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1795 - acc: 0.9316\n",
            "Epoch 2459/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1883 - acc: 0.9314\n",
            "Epoch 2460/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2136 - acc: 0.9231\n",
            "Epoch 2461/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1772 - acc: 0.9333\n",
            "Epoch 2462/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1711 - acc: 0.9335\n",
            "Epoch 2463/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1663 - acc: 0.9360\n",
            "Epoch 2464/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1879 - acc: 0.9318\n",
            "Epoch 2465/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2097 - acc: 0.9237\n",
            "Epoch 2466/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2463 - acc: 0.9211\n",
            "Epoch 2467/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2093 - acc: 0.9253\n",
            "Epoch 2468/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1769 - acc: 0.9328\n",
            "Epoch 2469/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1614 - acc: 0.9376\n",
            "Epoch 2470/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2493 - acc: 0.9259\n",
            "Epoch 2471/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2209 - acc: 0.9194\n",
            "Epoch 2472/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1685 - acc: 0.9346\n",
            "Epoch 2473/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1888 - acc: 0.9288\n",
            "Epoch 2474/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1900 - acc: 0.9291\n",
            "Epoch 2475/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1677 - acc: 0.9359\n",
            "Epoch 2476/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1714 - acc: 0.9347\n",
            "Epoch 2477/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1808 - acc: 0.9317\n",
            "Epoch 2478/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1814 - acc: 0.9312\n",
            "Epoch 2479/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1875 - acc: 0.9308\n",
            "Epoch 2480/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1674 - acc: 0.9357\n",
            "Epoch 2481/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1662 - acc: 0.9352\n",
            "Epoch 2482/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1704 - acc: 0.9362\n",
            "Epoch 2483/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1831 - acc: 0.9315\n",
            "Epoch 2484/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1868 - acc: 0.9316\n",
            "Epoch 2485/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1884 - acc: 0.9318\n",
            "Epoch 2486/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1626 - acc: 0.9354\n",
            "Epoch 2487/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1816 - acc: 0.9314\n",
            "Epoch 2488/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1763 - acc: 0.9335\n",
            "Epoch 2489/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1990 - acc: 0.9256\n",
            "Epoch 2490/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1680 - acc: 0.9345\n",
            "Epoch 2491/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1782 - acc: 0.9320\n",
            "Epoch 2492/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1756 - acc: 0.9324\n",
            "Epoch 2493/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1813 - acc: 0.9325\n",
            "Epoch 2494/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1764 - acc: 0.9351\n",
            "Epoch 2495/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1754 - acc: 0.9348\n",
            "Epoch 2496/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1962 - acc: 0.9274\n",
            "Epoch 2497/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1862 - acc: 0.9302\n",
            "Epoch 2498/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1700 - acc: 0.9350\n",
            "Epoch 2499/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1770 - acc: 0.9324\n",
            "Epoch 2500/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1897 - acc: 0.9325\n",
            "Epoch 2501/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1750 - acc: 0.9328\n",
            "Epoch 2502/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1726 - acc: 0.9335\n",
            "Epoch 2503/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1935 - acc: 0.9311\n",
            "Epoch 2504/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2003 - acc: 0.9283\n",
            "Epoch 2505/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1636 - acc: 0.9360\n",
            "Epoch 2506/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1864 - acc: 0.9328\n",
            "Epoch 2507/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2022 - acc: 0.9250\n",
            "Epoch 2508/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2231 - acc: 0.9268\n",
            "Epoch 2509/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1943 - acc: 0.9301\n",
            "Epoch 2510/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1850 - acc: 0.9316\n",
            "Epoch 2511/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1803 - acc: 0.9318\n",
            "Epoch 2512/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2617 - acc: 0.9151\n",
            "Epoch 2513/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1844 - acc: 0.9296\n",
            "Epoch 2514/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1712 - acc: 0.9327\n",
            "Epoch 2515/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1940 - acc: 0.9297\n",
            "Epoch 2516/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1722 - acc: 0.9343\n",
            "Epoch 2517/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1692 - acc: 0.9341\n",
            "Epoch 2518/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1956 - acc: 0.9280\n",
            "Epoch 2519/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1944 - acc: 0.9294\n",
            "Epoch 2520/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1948 - acc: 0.9296\n",
            "Epoch 2521/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2687 - acc: 0.9240\n",
            "Epoch 2522/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1960 - acc: 0.9275\n",
            "Epoch 2523/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1695 - acc: 0.9362\n",
            "Epoch 2524/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1766 - acc: 0.9365\n",
            "Epoch 2525/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1900 - acc: 0.9291\n",
            "Epoch 2526/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1799 - acc: 0.9315\n",
            "Epoch 2527/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1722 - acc: 0.9345\n",
            "Epoch 2528/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1978 - acc: 0.9275\n",
            "Epoch 2529/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1981 - acc: 0.9286\n",
            "Epoch 2530/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1822 - acc: 0.9316\n",
            "Epoch 2531/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1724 - acc: 0.9331\n",
            "Epoch 2532/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1618 - acc: 0.9374\n",
            "Epoch 2533/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1788 - acc: 0.9327\n",
            "Epoch 2534/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1923 - acc: 0.9296\n",
            "Epoch 2535/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1691 - acc: 0.9353\n",
            "Epoch 2536/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2511 - acc: 0.9240\n",
            "Epoch 2537/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1922 - acc: 0.9299\n",
            "Epoch 2538/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1738 - acc: 0.9333\n",
            "Epoch 2539/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2390 - acc: 0.9194\n",
            "Epoch 2540/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1939 - acc: 0.9305\n",
            "Epoch 2541/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1680 - acc: 0.9345\n",
            "Epoch 2542/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1962 - acc: 0.9291\n",
            "Epoch 2543/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1714 - acc: 0.9351\n",
            "Epoch 2544/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1698 - acc: 0.9341\n",
            "Epoch 2545/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1786 - acc: 0.9324\n",
            "Epoch 2546/3000\n",
            "896/896 [==============================] - 4s 5ms/step - loss: 0.2100 - acc: 0.9289\n",
            "Epoch 2547/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2135 - acc: 0.9222\n",
            "Epoch 2548/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1743 - acc: 0.9352\n",
            "Epoch 2549/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1871 - acc: 0.9291\n",
            "Epoch 2550/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1604 - acc: 0.9388\n",
            "Epoch 2551/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2073 - acc: 0.9275\n",
            "Epoch 2552/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2448 - acc: 0.9170\n",
            "Epoch 2553/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1763 - acc: 0.9344\n",
            "Epoch 2554/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1651 - acc: 0.9346\n",
            "Epoch 2555/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1721 - acc: 0.9341\n",
            "Epoch 2556/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1945 - acc: 0.9290\n",
            "Epoch 2557/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1983 - acc: 0.9282\n",
            "Epoch 2558/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1627 - acc: 0.9365\n",
            "Epoch 2559/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1717 - acc: 0.9339\n",
            "Epoch 2560/3000\n",
            "896/896 [==============================] - 4s 5ms/step - loss: 0.1688 - acc: 0.9360\n",
            "Epoch 2561/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1967 - acc: 0.9272\n",
            "Epoch 2562/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2470 - acc: 0.9239\n",
            "Epoch 2563/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2120 - acc: 0.9265\n",
            "Epoch 2564/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1656 - acc: 0.9340\n",
            "Epoch 2565/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1937 - acc: 0.9286\n",
            "Epoch 2566/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1897 - acc: 0.9294\n",
            "Epoch 2567/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1605 - acc: 0.9383\n",
            "Epoch 2568/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1706 - acc: 0.9362\n",
            "Epoch 2569/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1806 - acc: 0.9317\n",
            "Epoch 2570/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1795 - acc: 0.9331\n",
            "Epoch 2571/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1692 - acc: 0.9347\n",
            "Epoch 2572/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1945 - acc: 0.9301\n",
            "Epoch 2573/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1984 - acc: 0.9277\n",
            "Epoch 2574/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2006 - acc: 0.9277\n",
            "Epoch 2575/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1750 - acc: 0.9352\n",
            "Epoch 2576/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1667 - acc: 0.9360\n",
            "Epoch 2577/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1615 - acc: 0.9367\n",
            "Epoch 2578/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1823 - acc: 0.9331\n",
            "Epoch 2579/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1941 - acc: 0.9296\n",
            "Epoch 2580/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2194 - acc: 0.9241\n",
            "Epoch 2581/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1926 - acc: 0.9311\n",
            "Epoch 2582/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1743 - acc: 0.9330\n",
            "Epoch 2583/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1659 - acc: 0.9357\n",
            "Epoch 2584/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2105 - acc: 0.9332\n",
            "Epoch 2585/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2322 - acc: 0.9217\n",
            "Epoch 2586/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1578 - acc: 0.9379\n",
            "Epoch 2587/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1843 - acc: 0.9315\n",
            "Epoch 2588/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1797 - acc: 0.9321\n",
            "Epoch 2589/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1801 - acc: 0.9330\n",
            "Epoch 2590/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1731 - acc: 0.9338\n",
            "Epoch 2591/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1748 - acc: 0.9321\n",
            "Epoch 2592/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1643 - acc: 0.9366\n",
            "Epoch 2593/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1854 - acc: 0.9318\n",
            "Epoch 2594/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1789 - acc: 0.9313\n",
            "Epoch 2595/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1768 - acc: 0.9328\n",
            "Epoch 2596/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1722 - acc: 0.9360\n",
            "Epoch 2597/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1993 - acc: 0.9313\n",
            "Epoch 2598/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2605 - acc: 0.9146\n",
            "Epoch 2599/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1773 - acc: 0.9345\n",
            "Epoch 2600/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1765 - acc: 0.9321\n",
            "Epoch 2601/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1642 - acc: 0.9355\n",
            "Epoch 2602/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1793 - acc: 0.9327\n",
            "Epoch 2603/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1713 - acc: 0.9323\n",
            "Epoch 2604/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1571 - acc: 0.9380\n",
            "Epoch 2605/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2260 - acc: 0.9201\n",
            "Epoch 2606/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1880 - acc: 0.9304\n",
            "Epoch 2607/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1640 - acc: 0.9357\n",
            "Epoch 2608/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1972 - acc: 0.9278\n",
            "Epoch 2609/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2012 - acc: 0.9265\n",
            "Epoch 2610/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1857 - acc: 0.9309\n",
            "Epoch 2611/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1674 - acc: 0.9362\n",
            "Epoch 2612/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1737 - acc: 0.9349\n",
            "Epoch 2613/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2137 - acc: 0.9288\n",
            "Epoch 2614/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2093 - acc: 0.9287\n",
            "Epoch 2615/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1615 - acc: 0.9368\n",
            "Epoch 2616/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2011 - acc: 0.9302\n",
            "Epoch 2617/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1705 - acc: 0.9343\n",
            "Epoch 2618/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1828 - acc: 0.9322\n",
            "Epoch 2619/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2114 - acc: 0.9262\n",
            "Epoch 2620/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1789 - acc: 0.9293\n",
            "Epoch 2621/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1574 - acc: 0.9368\n",
            "Epoch 2622/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2012 - acc: 0.9306\n",
            "Epoch 2623/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1749 - acc: 0.9342\n",
            "Epoch 2624/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1666 - acc: 0.9362\n",
            "Epoch 2625/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1779 - acc: 0.9333\n",
            "Epoch 2626/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1962 - acc: 0.9296\n",
            "Epoch 2627/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1744 - acc: 0.9332\n",
            "Epoch 2628/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1757 - acc: 0.9354\n",
            "Epoch 2629/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1928 - acc: 0.9293\n",
            "Epoch 2630/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1769 - acc: 0.9351\n",
            "Epoch 2631/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2134 - acc: 0.9236\n",
            "Epoch 2632/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2167 - acc: 0.9222\n",
            "Epoch 2633/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1873 - acc: 0.9310\n",
            "Epoch 2634/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1762 - acc: 0.9339\n",
            "Epoch 2635/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1730 - acc: 0.9343\n",
            "Epoch 2636/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1746 - acc: 0.9346\n",
            "Epoch 2637/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2793 - acc: 0.9246\n",
            "Epoch 2638/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2430 - acc: 0.9197\n",
            "Epoch 2639/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1914 - acc: 0.9286\n",
            "Epoch 2640/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1751 - acc: 0.9351\n",
            "Epoch 2641/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1770 - acc: 0.9319\n",
            "Epoch 2642/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1748 - acc: 0.9340\n",
            "Epoch 2643/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1816 - acc: 0.9325\n",
            "Epoch 2644/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2361 - acc: 0.9208\n",
            "Epoch 2645/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2089 - acc: 0.9247\n",
            "Epoch 2646/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1578 - acc: 0.9365\n",
            "Epoch 2647/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1691 - acc: 0.9364\n",
            "Epoch 2648/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1955 - acc: 0.9285\n",
            "Epoch 2649/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1646 - acc: 0.9354\n",
            "Epoch 2650/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1716 - acc: 0.9338\n",
            "Epoch 2651/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1854 - acc: 0.9332\n",
            "Epoch 2652/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2171 - acc: 0.9230\n",
            "Epoch 2653/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1891 - acc: 0.9282\n",
            "Epoch 2654/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1717 - acc: 0.9347\n",
            "Epoch 2655/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1988 - acc: 0.9290\n",
            "Epoch 2656/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1845 - acc: 0.9310\n",
            "Epoch 2657/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1779 - acc: 0.9316\n",
            "Epoch 2658/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1888 - acc: 0.9300\n",
            "Epoch 2659/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1758 - acc: 0.9331\n",
            "Epoch 2660/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1857 - acc: 0.9325\n",
            "Epoch 2661/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2323 - acc: 0.9261\n",
            "Epoch 2662/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1801 - acc: 0.9327\n",
            "Epoch 2663/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1788 - acc: 0.9333\n",
            "Epoch 2664/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1657 - acc: 0.9372\n",
            "Epoch 2665/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1812 - acc: 0.9330\n",
            "Epoch 2666/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1781 - acc: 0.9325\n",
            "Epoch 2667/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2049 - acc: 0.9272\n",
            "Epoch 2668/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1877 - acc: 0.9299\n",
            "Epoch 2669/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1624 - acc: 0.9359\n",
            "Epoch 2670/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1858 - acc: 0.9318\n",
            "Epoch 2671/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2591 - acc: 0.9214\n",
            "Epoch 2672/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1946 - acc: 0.9263\n",
            "Epoch 2673/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1693 - acc: 0.9353\n",
            "Epoch 2674/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1925 - acc: 0.9278\n",
            "Epoch 2675/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1703 - acc: 0.9343\n",
            "Epoch 2676/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2137 - acc: 0.9239\n",
            "Epoch 2677/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1558 - acc: 0.9372\n",
            "Epoch 2678/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1686 - acc: 0.9356\n",
            "Epoch 2679/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1759 - acc: 0.9336\n",
            "Epoch 2680/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2046 - acc: 0.9266\n",
            "Epoch 2681/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1853 - acc: 0.9307\n",
            "Epoch 2682/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1750 - acc: 0.9308\n",
            "Epoch 2683/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1860 - acc: 0.9297\n",
            "Epoch 2684/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1707 - acc: 0.9332\n",
            "Epoch 2685/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1862 - acc: 0.9324\n",
            "Epoch 2686/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1918 - acc: 0.9282\n",
            "Epoch 2687/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1700 - acc: 0.9365\n",
            "Epoch 2688/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1727 - acc: 0.9333\n",
            "Epoch 2689/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2532 - acc: 0.9270\n",
            "Epoch 2690/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2158 - acc: 0.9249\n",
            "Epoch 2691/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1713 - acc: 0.9328\n",
            "Epoch 2692/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1783 - acc: 0.9336\n",
            "Epoch 2693/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1799 - acc: 0.9323\n",
            "Epoch 2694/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1689 - acc: 0.9357\n",
            "Epoch 2695/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1598 - acc: 0.9376\n",
            "Epoch 2696/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2142 - acc: 0.9259\n",
            "Epoch 2697/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2215 - acc: 0.9243\n",
            "Epoch 2698/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1654 - acc: 0.9373\n",
            "Epoch 2699/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1580 - acc: 0.9382\n",
            "Epoch 2700/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1704 - acc: 0.9363\n",
            "Epoch 2701/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2143 - acc: 0.9231\n",
            "Epoch 2702/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2295 - acc: 0.9208\n",
            "Epoch 2703/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1773 - acc: 0.9339\n",
            "Epoch 2704/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1748 - acc: 0.9334\n",
            "Epoch 2705/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1663 - acc: 0.9344\n",
            "Epoch 2706/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1995 - acc: 0.9284\n",
            "Epoch 2707/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1913 - acc: 0.9305\n",
            "Epoch 2708/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1845 - acc: 0.9309\n",
            "Epoch 2709/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1646 - acc: 0.9376\n",
            "Epoch 2710/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1852 - acc: 0.9328\n",
            "Epoch 2711/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1977 - acc: 0.9282\n",
            "Epoch 2712/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1675 - acc: 0.9354\n",
            "Epoch 2713/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1806 - acc: 0.9323\n",
            "Epoch 2714/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1954 - acc: 0.9274\n",
            "Epoch 2715/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1620 - acc: 0.9374\n",
            "Epoch 2716/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1596 - acc: 0.9363\n",
            "Epoch 2717/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1958 - acc: 0.9287\n",
            "Epoch 2718/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2312 - acc: 0.9219\n",
            "Epoch 2719/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1689 - acc: 0.9355\n",
            "Epoch 2720/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1647 - acc: 0.9355\n",
            "Epoch 2721/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1738 - acc: 0.9353\n",
            "Epoch 2722/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1879 - acc: 0.9312\n",
            "Epoch 2723/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1633 - acc: 0.9361\n",
            "Epoch 2724/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2063 - acc: 0.9240\n",
            "Epoch 2725/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1779 - acc: 0.9313\n",
            "Epoch 2726/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1755 - acc: 0.9340\n",
            "Epoch 2727/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1671 - acc: 0.9365\n",
            "Epoch 2728/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1818 - acc: 0.9330\n",
            "Epoch 2729/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1747 - acc: 0.9326\n",
            "Epoch 2730/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1649 - acc: 0.9358\n",
            "Epoch 2731/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1803 - acc: 0.9338\n",
            "Epoch 2732/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2161 - acc: 0.9222\n",
            "Epoch 2733/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1632 - acc: 0.9352\n",
            "Epoch 2734/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1873 - acc: 0.9309\n",
            "Epoch 2735/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1601 - acc: 0.9369\n",
            "Epoch 2736/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2154 - acc: 0.9249\n",
            "Epoch 2737/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1805 - acc: 0.9314\n",
            "Epoch 2738/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1689 - acc: 0.9357\n",
            "Epoch 2739/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1751 - acc: 0.9336\n",
            "Epoch 2740/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1822 - acc: 0.9310\n",
            "Epoch 2741/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2151 - acc: 0.9339\n",
            "Epoch 2742/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2206 - acc: 0.9237\n",
            "Epoch 2743/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1753 - acc: 0.9318\n",
            "Epoch 2744/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1518 - acc: 0.9393\n",
            "Epoch 2745/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1776 - acc: 0.9343\n",
            "Epoch 2746/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1971 - acc: 0.9291\n",
            "Epoch 2747/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2047 - acc: 0.9322\n",
            "Epoch 2748/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2112 - acc: 0.9239\n",
            "Epoch 2749/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1621 - acc: 0.9357\n",
            "Epoch 2750/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1584 - acc: 0.9376\n",
            "Epoch 2751/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1678 - acc: 0.9360\n",
            "Epoch 2752/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1751 - acc: 0.9336\n",
            "Epoch 2753/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1878 - acc: 0.9298\n",
            "Epoch 2754/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2099 - acc: 0.9248\n",
            "Epoch 2755/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1722 - acc: 0.9332\n",
            "Epoch 2756/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1814 - acc: 0.9313\n",
            "Epoch 2757/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1625 - acc: 0.9368\n",
            "Epoch 2758/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1692 - acc: 0.9363\n",
            "Epoch 2759/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1932 - acc: 0.9297\n",
            "Epoch 2760/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2077 - acc: 0.9247\n",
            "Epoch 2761/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1638 - acc: 0.9358\n",
            "Epoch 2762/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1640 - acc: 0.9357\n",
            "Epoch 2763/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1953 - acc: 0.9294\n",
            "Epoch 2764/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2082 - acc: 0.9281\n",
            "Epoch 2765/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1567 - acc: 0.9379\n",
            "Epoch 2766/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1628 - acc: 0.9373\n",
            "Epoch 2767/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1771 - acc: 0.9342\n",
            "Epoch 2768/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1628 - acc: 0.9358\n",
            "Epoch 2769/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2018 - acc: 0.9259\n",
            "Epoch 2770/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1666 - acc: 0.9349\n",
            "Epoch 2771/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1761 - acc: 0.9328\n",
            "Epoch 2772/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1774 - acc: 0.9322\n",
            "Epoch 2773/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2451 - acc: 0.9181\n",
            "Epoch 2774/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2128 - acc: 0.9244\n",
            "Epoch 2775/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1626 - acc: 0.9364\n",
            "Epoch 2776/3000\n",
            "896/896 [==============================] - 4s 5ms/step - loss: 0.1562 - acc: 0.9377\n",
            "Epoch 2777/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1611 - acc: 0.9369\n",
            "Epoch 2778/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1772 - acc: 0.9325\n",
            "Epoch 2779/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2513 - acc: 0.9149\n",
            "Epoch 2780/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2906 - acc: 0.9287\n",
            "Epoch 2781/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1579 - acc: 0.9367\n",
            "Epoch 2782/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1672 - acc: 0.9340\n",
            "Epoch 2783/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1678 - acc: 0.9363\n",
            "Epoch 2784/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2109 - acc: 0.9274\n",
            "Epoch 2785/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1790 - acc: 0.9329\n",
            "Epoch 2786/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1902 - acc: 0.9300\n",
            "Epoch 2787/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1957 - acc: 0.9282\n",
            "Epoch 2788/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1835 - acc: 0.9320\n",
            "Epoch 2789/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1922 - acc: 0.9283\n",
            "Epoch 2790/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2016 - acc: 0.9267\n",
            "Epoch 2791/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1604 - acc: 0.9374\n",
            "Epoch 2792/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2289 - acc: 0.9202\n",
            "Epoch 2793/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2200 - acc: 0.9281\n",
            "Epoch 2794/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1658 - acc: 0.9357\n",
            "Epoch 2795/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1671 - acc: 0.9365\n",
            "Epoch 2796/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1886 - acc: 0.9278\n",
            "Epoch 2797/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1720 - acc: 0.9342\n",
            "Epoch 2798/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2115 - acc: 0.9236\n",
            "Epoch 2799/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1665 - acc: 0.9348\n",
            "Epoch 2800/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1722 - acc: 0.9337\n",
            "Epoch 2801/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1827 - acc: 0.9343\n",
            "Epoch 2802/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1753 - acc: 0.9333\n",
            "Epoch 2803/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1776 - acc: 0.9324\n",
            "Epoch 2804/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1667 - acc: 0.9354\n",
            "Epoch 2805/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1672 - acc: 0.9353\n",
            "Epoch 2806/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1932 - acc: 0.9313\n",
            "Epoch 2807/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2225 - acc: 0.9225\n",
            "Epoch 2808/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1952 - acc: 0.9279\n",
            "Epoch 2809/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1498 - acc: 0.9398\n",
            "Epoch 2810/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1641 - acc: 0.9373\n",
            "Epoch 2811/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1839 - acc: 0.9318\n",
            "Epoch 2812/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1656 - acc: 0.9359\n",
            "Epoch 2813/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1610 - acc: 0.9373\n",
            "Epoch 2814/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2480 - acc: 0.9257\n",
            "Epoch 2815/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2566 - acc: 0.9164\n",
            "Epoch 2816/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1599 - acc: 0.9366\n",
            "Epoch 2817/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1539 - acc: 0.9388\n",
            "Epoch 2818/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1616 - acc: 0.9387\n",
            "Epoch 2819/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1944 - acc: 0.9289\n",
            "Epoch 2820/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2163 - acc: 0.9247\n",
            "Epoch 2821/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1616 - acc: 0.9352\n",
            "Epoch 2822/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1867 - acc: 0.9332\n",
            "Epoch 2823/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1986 - acc: 0.9276\n",
            "Epoch 2824/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1612 - acc: 0.9373\n",
            "Epoch 2825/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1785 - acc: 0.9334\n",
            "Epoch 2826/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1715 - acc: 0.9347\n",
            "Epoch 2827/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1795 - acc: 0.9345\n",
            "Epoch 2828/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2174 - acc: 0.9237\n",
            "Epoch 2829/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2602 - acc: 0.9249\n",
            "Epoch 2830/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1747 - acc: 0.9362\n",
            "Epoch 2831/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1911 - acc: 0.9292\n",
            "Epoch 2832/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1700 - acc: 0.9346\n",
            "Epoch 2833/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1610 - acc: 0.9369\n",
            "Epoch 2834/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1814 - acc: 0.9314\n",
            "Epoch 2835/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1972 - acc: 0.9284\n",
            "Epoch 2836/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1675 - acc: 0.9363\n",
            "Epoch 2837/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1925 - acc: 0.9323\n",
            "Epoch 2838/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1827 - acc: 0.9316\n",
            "Epoch 2839/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1570 - acc: 0.9373\n",
            "Epoch 2840/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1660 - acc: 0.9365\n",
            "Epoch 2841/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1800 - acc: 0.9332\n",
            "Epoch 2842/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1895 - acc: 0.9288\n",
            "Epoch 2843/3000\n",
            "896/896 [==============================] - 4s 5ms/step - loss: 0.1772 - acc: 0.9341\n",
            "Epoch 2844/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2453 - acc: 0.9200\n",
            "Epoch 2845/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2166 - acc: 0.9215\n",
            "Epoch 2846/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1608 - acc: 0.9361\n",
            "Epoch 2847/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1657 - acc: 0.9344\n",
            "Epoch 2848/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1668 - acc: 0.9358\n",
            "Epoch 2849/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1690 - acc: 0.9348\n",
            "Epoch 2850/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1719 - acc: 0.9325\n",
            "Epoch 2851/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1750 - acc: 0.9348\n",
            "Epoch 2852/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1756 - acc: 0.9359\n",
            "Epoch 2853/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2480 - acc: 0.9158\n",
            "Epoch 2854/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1572 - acc: 0.9385\n",
            "Epoch 2855/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1650 - acc: 0.9367\n",
            "Epoch 2856/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1725 - acc: 0.9332\n",
            "Epoch 2857/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1935 - acc: 0.9287\n",
            "Epoch 2858/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1645 - acc: 0.9348\n",
            "Epoch 2859/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1923 - acc: 0.9284\n",
            "Epoch 2860/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1649 - acc: 0.9373\n",
            "Epoch 2861/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1648 - acc: 0.9358\n",
            "Epoch 2862/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1775 - acc: 0.9322\n",
            "Epoch 2863/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1718 - acc: 0.9345\n",
            "Epoch 2864/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1928 - acc: 0.9289\n",
            "Epoch 2865/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1751 - acc: 0.9315\n",
            "Epoch 2866/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1659 - acc: 0.9362\n",
            "Epoch 2867/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1606 - acc: 0.9374\n",
            "Epoch 2868/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2074 - acc: 0.9253\n",
            "Epoch 2869/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1767 - acc: 0.9326\n",
            "Epoch 2870/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1807 - acc: 0.9319\n",
            "Epoch 2871/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1671 - acc: 0.9341\n",
            "Epoch 2872/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1798 - acc: 0.9319\n",
            "Epoch 2873/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2320 - acc: 0.9211\n",
            "Epoch 2874/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1764 - acc: 0.9320\n",
            "Epoch 2875/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1545 - acc: 0.9389\n",
            "Epoch 2876/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1732 - acc: 0.9331\n",
            "Epoch 2877/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1786 - acc: 0.9323\n",
            "Epoch 2878/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1991 - acc: 0.9302\n",
            "Epoch 2879/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2032 - acc: 0.9284\n",
            "Epoch 2880/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1836 - acc: 0.9335\n",
            "Epoch 2881/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1620 - acc: 0.9372\n",
            "Epoch 2882/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1655 - acc: 0.9363\n",
            "Epoch 2883/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1818 - acc: 0.9313\n",
            "Epoch 2884/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2185 - acc: 0.9258\n",
            "Epoch 2885/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1845 - acc: 0.9338\n",
            "Epoch 2886/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1698 - acc: 0.9354\n",
            "Epoch 2887/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1776 - acc: 0.9315\n",
            "Epoch 2888/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1852 - acc: 0.9312\n",
            "Epoch 2889/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1588 - acc: 0.9370\n",
            "Epoch 2890/3000\n",
            "896/896 [==============================] - 4s 5ms/step - loss: 0.1554 - acc: 0.9386\n",
            "Epoch 2891/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1721 - acc: 0.9339\n",
            "Epoch 2892/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1739 - acc: 0.9347\n",
            "Epoch 2893/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2010 - acc: 0.9286\n",
            "Epoch 2894/3000\n",
            "896/896 [==============================] - 4s 5ms/step - loss: 0.1797 - acc: 0.9327\n",
            "Epoch 2895/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1750 - acc: 0.9337\n",
            "Epoch 2896/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1737 - acc: 0.9348\n",
            "Epoch 2897/3000\n",
            "896/896 [==============================] - 4s 5ms/step - loss: 0.1737 - acc: 0.9348\n",
            "Epoch 2898/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1657 - acc: 0.9357\n",
            "Epoch 2899/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1618 - acc: 0.9358\n",
            "Epoch 2900/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2035 - acc: 0.9265\n",
            "Epoch 2901/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1693 - acc: 0.9343\n",
            "Epoch 2902/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1624 - acc: 0.9362\n",
            "Epoch 2903/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1664 - acc: 0.9359\n",
            "Epoch 2904/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2020 - acc: 0.9255\n",
            "Epoch 2905/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1663 - acc: 0.9360\n",
            "Epoch 2906/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1587 - acc: 0.9392\n",
            "Epoch 2907/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1950 - acc: 0.9292\n",
            "Epoch 2908/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1821 - acc: 0.9320\n",
            "Epoch 2909/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1921 - acc: 0.9279\n",
            "Epoch 2910/3000\n",
            "896/896 [==============================] - 4s 5ms/step - loss: 0.1615 - acc: 0.9371\n",
            "Epoch 2911/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2149 - acc: 0.9313\n",
            "Epoch 2912/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1930 - acc: 0.9293\n",
            "Epoch 2913/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2355 - acc: 0.9223\n",
            "Epoch 2914/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1729 - acc: 0.9342\n",
            "Epoch 2915/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1629 - acc: 0.9354\n",
            "Epoch 2916/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1755 - acc: 0.9343\n",
            "Epoch 2917/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1842 - acc: 0.9289\n",
            "Epoch 2918/3000\n",
            "896/896 [==============================] - 4s 5ms/step - loss: 0.1887 - acc: 0.9310\n",
            "Epoch 2919/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1640 - acc: 0.9354\n",
            "Epoch 2920/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1695 - acc: 0.9349\n",
            "Epoch 2921/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1783 - acc: 0.9322\n",
            "Epoch 2922/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1865 - acc: 0.9328\n",
            "Epoch 2923/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1675 - acc: 0.9354\n",
            "Epoch 2924/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1560 - acc: 0.9393\n",
            "Epoch 2925/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2293 - acc: 0.9195\n",
            "Epoch 2926/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1607 - acc: 0.9384\n",
            "Epoch 2927/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1746 - acc: 0.9332\n",
            "Epoch 2928/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2003 - acc: 0.9275\n",
            "Epoch 2929/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1642 - acc: 0.9372\n",
            "Epoch 2930/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1970 - acc: 0.9300\n",
            "Epoch 2931/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1605 - acc: 0.9361\n",
            "Epoch 2932/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1562 - acc: 0.9391\n",
            "Epoch 2933/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2137 - acc: 0.9262\n",
            "Epoch 2934/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1952 - acc: 0.9266\n",
            "Epoch 2935/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1682 - acc: 0.9354\n",
            "Epoch 2936/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1655 - acc: 0.9377\n",
            "Epoch 2937/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1965 - acc: 0.9289\n",
            "Epoch 2938/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1763 - acc: 0.9343\n",
            "Epoch 2939/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2160 - acc: 0.9267\n",
            "Epoch 2940/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1604 - acc: 0.9368\n",
            "Epoch 2941/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1577 - acc: 0.9380\n",
            "Epoch 2942/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1607 - acc: 0.9384\n",
            "Epoch 2943/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1823 - acc: 0.9315\n",
            "Epoch 2944/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2011 - acc: 0.9295\n",
            "Epoch 2945/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1713 - acc: 0.9358\n",
            "Epoch 2946/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1658 - acc: 0.9363\n",
            "Epoch 2947/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1787 - acc: 0.9312\n",
            "Epoch 2948/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1912 - acc: 0.9313\n",
            "Epoch 2949/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2111 - acc: 0.9275\n",
            "Epoch 2950/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1803 - acc: 0.9322\n",
            "Epoch 2951/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1534 - acc: 0.9381\n",
            "Epoch 2952/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1600 - acc: 0.9373\n",
            "Epoch 2953/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2142 - acc: 0.9246\n",
            "Epoch 2954/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1947 - acc: 0.9303\n",
            "Epoch 2955/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1698 - acc: 0.9343\n",
            "Epoch 2956/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1922 - acc: 0.9307\n",
            "Epoch 2957/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1707 - acc: 0.9333\n",
            "Epoch 2958/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1806 - acc: 0.9323\n",
            "Epoch 2959/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1646 - acc: 0.9363\n",
            "Epoch 2960/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1668 - acc: 0.9360\n",
            "Epoch 2961/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1756 - acc: 0.9346\n",
            "Epoch 2962/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1929 - acc: 0.9271\n",
            "Epoch 2963/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1709 - acc: 0.9350\n",
            "Epoch 2964/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1717 - acc: 0.9342\n",
            "Epoch 2965/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1706 - acc: 0.9348\n",
            "Epoch 2966/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1818 - acc: 0.9334\n",
            "Epoch 2967/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1803 - acc: 0.9338\n",
            "Epoch 2968/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1596 - acc: 0.9389\n",
            "Epoch 2969/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1667 - acc: 0.9362\n",
            "Epoch 2970/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1740 - acc: 0.9330\n",
            "Epoch 2971/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1783 - acc: 0.9312\n",
            "Epoch 2972/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1907 - acc: 0.9304\n",
            "Epoch 2973/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1717 - acc: 0.9347\n",
            "Epoch 2974/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1655 - acc: 0.9365\n",
            "Epoch 2975/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1932 - acc: 0.9305\n",
            "Epoch 2976/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1694 - acc: 0.9363\n",
            "Epoch 2977/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1785 - acc: 0.9326\n",
            "Epoch 2978/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1664 - acc: 0.9357\n",
            "Epoch 2979/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1703 - acc: 0.9335\n",
            "Epoch 2980/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1617 - acc: 0.9365\n",
            "Epoch 2981/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1835 - acc: 0.9307\n",
            "Epoch 2982/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2017 - acc: 0.9291\n",
            "Epoch 2983/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1570 - acc: 0.9369\n",
            "Epoch 2984/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1991 - acc: 0.9278\n",
            "Epoch 2985/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1874 - acc: 0.9350\n",
            "Epoch 2986/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1915 - acc: 0.9312\n",
            "Epoch 2987/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1826 - acc: 0.9354\n",
            "Epoch 2988/3000\n",
            "896/896 [==============================] - 4s 5ms/step - loss: 0.1831 - acc: 0.9315\n",
            "Epoch 2989/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1535 - acc: 0.9380\n",
            "Epoch 2990/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1748 - acc: 0.9352\n",
            "Epoch 2991/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2749 - acc: 0.9112\n",
            "Epoch 2992/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1883 - acc: 0.9285\n",
            "Epoch 2993/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1555 - acc: 0.9372\n",
            "Epoch 2994/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1702 - acc: 0.9362\n",
            "Epoch 2995/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1713 - acc: 0.9358\n",
            "Epoch 2996/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1654 - acc: 0.9370\n",
            "Epoch 2997/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1666 - acc: 0.9357\n",
            "Epoch 2998/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2078 - acc: 0.9258\n",
            "Epoch 2999/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.2751 - acc: 0.9183\n",
            "Epoch 3000/3000\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.1671 - acc: 0.9345\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 인공신경망 모형 구성(퍼셉트론)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(256, activation = 'relu', input_shape = (13, ) ) ) \n",
        "model.add(Dense(128, activation = 'relu', input_shape = (13, ) ) ) \n",
        "model.add(Dense(64, activation = 'relu' ) ) \n",
        "model.add(Dense(32, activation = 'relu' ) )\n",
        "model.add(Dense(19, activation = 'softmax')) \n",
        "\n",
        "\n",
        "#모형 컴파일\n",
        "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['acc'])\n",
        "#모형 학습 및 가중치 확인\n",
        "history = model.fit(X_train, y_train_cate, epochs = 3000)#,\n",
        "                    #batch_size = 128, validation_data = (x_val,y_val))\n",
        "\n",
        "#model.fit(X_train,y_train,epochs = 10)\n",
        "#model.get_weights() #인공신경망 구성하는 각각의 가중치(2*3 = 6개의 가중치, 그다음 배열은 bias, 첫번째 은닉층에서 두번째 은닉층으로의 가중치 3개, 그 다음 배열은 bias로 총 4개의 배열)"
      ],
      "metadata": {
        "id": "_yvaRTGNc4OX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 인공신경망 모형 구성(퍼셉트론)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(256, activation = 'relu', input_shape = (13, ) ) ) \n",
        "model.add(Dense(128, activation = 'relu', input_shape = (13, ) ) ) \n",
        "model.add(Dense(64, activation = 'relu' ) ) \n",
        "model.add(Dense(32, activation = 'relu' ) )\n",
        "model.add(Dense(19, activation = 'softmax')) \n",
        "\n",
        "\n",
        "#모형 컴파일\n",
        "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['acc'])\n",
        "#모형 학습 및 가중치 확인\n",
        "history = model.fit(X_train, y_train_cate, epochs = 800)#,\n",
        "                    #batch_size = 128, validation_data = (x_val,y_val))\n",
        "\n",
        "#model.fit(X_train,y_train,epochs = 10)\n",
        "#model.get_weights() #인공신경망 구성하는 각각의 가중치(2*3 = 6개의 가중치, 그다음 배열은 bias, 첫번째 은닉층에서 두번째 은닉층으로의 가중치 3개, 그 다음 배열은 bias로 총 4개의 배열)\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "results_DNN = model.predict( X_test)\n",
        "#혼동행렬을 만듬.\n",
        "#plt.figure(figsize = (7,7))\n",
        "#cm = confusion_matrix(np.argmax(y_test, axis = -1), np.argmax(results, axis = -1))\n",
        "#sns.heatmap(cm, annot = True, fmt = 'd')\n",
        "#plt.xlabel('predicted')\n",
        "#plt.ylabel('actual')\n",
        "#plt.show() \n",
        "\n",
        "#분류 보고서\n",
        "print('\\n', classification_report(np.argmax(y_test_cate, axis = -1), np.argmax(results_DNN, axis = -1)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oq34CVBvd01O",
        "outputId": "6349651b-d6dc-4bda-d2e6-1cd133d7af50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 1.1270 - acc: 0.6444\n",
            "Epoch 2/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.9989 - acc: 0.6765\n",
            "Epoch 3/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.9714 - acc: 0.6801\n",
            "Epoch 4/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.9593 - acc: 0.6829\n",
            "Epoch 5/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.9469 - acc: 0.6860\n",
            "Epoch 6/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.9382 - acc: 0.6884\n",
            "Epoch 7/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.9304 - acc: 0.6880\n",
            "Epoch 8/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.9226 - acc: 0.6914\n",
            "Epoch 9/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.9165 - acc: 0.6934\n",
            "Epoch 10/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.9082 - acc: 0.6941\n",
            "Epoch 11/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.9045 - acc: 0.6961\n",
            "Epoch 12/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.8978 - acc: 0.6973\n",
            "Epoch 13/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.8923 - acc: 0.6981\n",
            "Epoch 14/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.8854 - acc: 0.6986\n",
            "Epoch 15/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.8815 - acc: 0.7008\n",
            "Epoch 16/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.8746 - acc: 0.7050\n",
            "Epoch 17/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.8702 - acc: 0.7032\n",
            "Epoch 18/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.8659 - acc: 0.7047\n",
            "Epoch 19/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.8602 - acc: 0.7053\n",
            "Epoch 20/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.8554 - acc: 0.7078\n",
            "Epoch 21/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.8503 - acc: 0.7072\n",
            "Epoch 22/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.8463 - acc: 0.7104\n",
            "Epoch 23/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.8407 - acc: 0.7116\n",
            "Epoch 24/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.8360 - acc: 0.7103\n",
            "Epoch 25/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.8310 - acc: 0.7116\n",
            "Epoch 26/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.8252 - acc: 0.7140\n",
            "Epoch 27/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.8208 - acc: 0.7145\n",
            "Epoch 28/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.8130 - acc: 0.7166\n",
            "Epoch 29/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.8105 - acc: 0.7186\n",
            "Epoch 30/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.8074 - acc: 0.7173\n",
            "Epoch 31/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.7999 - acc: 0.7200\n",
            "Epoch 32/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.7970 - acc: 0.7197\n",
            "Epoch 33/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.7891 - acc: 0.7243\n",
            "Epoch 34/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.7873 - acc: 0.7238\n",
            "Epoch 35/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.7802 - acc: 0.7264\n",
            "Epoch 36/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.7745 - acc: 0.7273\n",
            "Epoch 37/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.7715 - acc: 0.7267\n",
            "Epoch 38/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.7653 - acc: 0.7278\n",
            "Epoch 39/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.7606 - acc: 0.7308\n",
            "Epoch 40/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.7566 - acc: 0.7312\n",
            "Epoch 41/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.7500 - acc: 0.7327\n",
            "Epoch 42/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.7447 - acc: 0.7355\n",
            "Epoch 43/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.7391 - acc: 0.7379\n",
            "Epoch 44/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.7393 - acc: 0.7340\n",
            "Epoch 45/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.7343 - acc: 0.7358\n",
            "Epoch 46/800\n",
            "896/896 [==============================] - 4s 4ms/step - loss: 0.7302 - acc: 0.7397\n",
            "Epoch 47/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.7241 - acc: 0.7402\n",
            "Epoch 48/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.7197 - acc: 0.7422\n",
            "Epoch 49/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.7141 - acc: 0.7449\n",
            "Epoch 50/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.7098 - acc: 0.7440\n",
            "Epoch 51/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.7068 - acc: 0.7471\n",
            "Epoch 52/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.7017 - acc: 0.7457\n",
            "Epoch 53/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.6978 - acc: 0.7487\n",
            "Epoch 54/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.6965 - acc: 0.7481\n",
            "Epoch 55/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.6854 - acc: 0.7514\n",
            "Epoch 56/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.6826 - acc: 0.7512\n",
            "Epoch 57/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.6834 - acc: 0.7512\n",
            "Epoch 58/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.6767 - acc: 0.7536\n",
            "Epoch 59/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.6726 - acc: 0.7561\n",
            "Epoch 60/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.6699 - acc: 0.7550\n",
            "Epoch 61/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.6655 - acc: 0.7563\n",
            "Epoch 62/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.6606 - acc: 0.7566\n",
            "Epoch 63/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.6537 - acc: 0.7607\n",
            "Epoch 64/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.6540 - acc: 0.7596\n",
            "Epoch 65/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.6477 - acc: 0.7601\n",
            "Epoch 66/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.6463 - acc: 0.7624\n",
            "Epoch 67/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.6397 - acc: 0.7648\n",
            "Epoch 68/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.6409 - acc: 0.7624\n",
            "Epoch 69/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.6314 - acc: 0.7677\n",
            "Epoch 70/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.6312 - acc: 0.7673\n",
            "Epoch 71/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.6307 - acc: 0.7676\n",
            "Epoch 72/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.6229 - acc: 0.7680\n",
            "Epoch 73/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.6222 - acc: 0.7707\n",
            "Epoch 74/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.6153 - acc: 0.7741\n",
            "Epoch 75/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.6148 - acc: 0.7732\n",
            "Epoch 76/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.6119 - acc: 0.7743\n",
            "Epoch 77/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.6078 - acc: 0.7750\n",
            "Epoch 78/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.6080 - acc: 0.7764\n",
            "Epoch 79/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.6011 - acc: 0.7771\n",
            "Epoch 80/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.5986 - acc: 0.7776\n",
            "Epoch 81/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.5938 - acc: 0.7793\n",
            "Epoch 82/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.5916 - acc: 0.7792\n",
            "Epoch 83/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.5889 - acc: 0.7801\n",
            "Epoch 84/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.5877 - acc: 0.7815\n",
            "Epoch 85/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.5871 - acc: 0.7837\n",
            "Epoch 86/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.5793 - acc: 0.7830\n",
            "Epoch 87/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.5757 - acc: 0.7859\n",
            "Epoch 88/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.5770 - acc: 0.7841\n",
            "Epoch 89/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.5760 - acc: 0.7857\n",
            "Epoch 90/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.5709 - acc: 0.7861\n",
            "Epoch 91/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.5665 - acc: 0.7868\n",
            "Epoch 92/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.5658 - acc: 0.7884\n",
            "Epoch 93/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.5614 - acc: 0.7896\n",
            "Epoch 94/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.5606 - acc: 0.7909\n",
            "Epoch 95/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.5538 - acc: 0.7930\n",
            "Epoch 96/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.5529 - acc: 0.7930\n",
            "Epoch 97/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.5539 - acc: 0.7912\n",
            "Epoch 98/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.5510 - acc: 0.7935\n",
            "Epoch 99/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.5496 - acc: 0.7929\n",
            "Epoch 100/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.5407 - acc: 0.7977\n",
            "Epoch 101/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.5410 - acc: 0.7959\n",
            "Epoch 102/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.5378 - acc: 0.7982\n",
            "Epoch 103/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.5373 - acc: 0.7998\n",
            "Epoch 104/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.5334 - acc: 0.7981\n",
            "Epoch 105/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.5280 - acc: 0.8026\n",
            "Epoch 106/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.5309 - acc: 0.7992\n",
            "Epoch 107/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.5275 - acc: 0.8033\n",
            "Epoch 108/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.5222 - acc: 0.8052\n",
            "Epoch 109/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.5217 - acc: 0.8034\n",
            "Epoch 110/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.5221 - acc: 0.8042\n",
            "Epoch 111/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.5142 - acc: 0.8053\n",
            "Epoch 112/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.5174 - acc: 0.8050\n",
            "Epoch 113/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.5220 - acc: 0.8035\n",
            "Epoch 114/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.5154 - acc: 0.8061\n",
            "Epoch 115/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.5044 - acc: 0.8085\n",
            "Epoch 116/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.5066 - acc: 0.8090\n",
            "Epoch 117/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.5091 - acc: 0.8063\n",
            "Epoch 118/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.5074 - acc: 0.8081\n",
            "Epoch 119/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.5047 - acc: 0.8090\n",
            "Epoch 120/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.5017 - acc: 0.8104\n",
            "Epoch 121/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.4976 - acc: 0.8118\n",
            "Epoch 122/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.4964 - acc: 0.8117\n",
            "Epoch 123/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.4970 - acc: 0.8103\n",
            "Epoch 124/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.4931 - acc: 0.8142\n",
            "Epoch 125/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.4923 - acc: 0.8151\n",
            "Epoch 126/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.4937 - acc: 0.8111\n",
            "Epoch 127/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.4857 - acc: 0.8150\n",
            "Epoch 128/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.4868 - acc: 0.8167\n",
            "Epoch 129/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.4847 - acc: 0.8168\n",
            "Epoch 130/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.4821 - acc: 0.8185\n",
            "Epoch 131/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.4839 - acc: 0.8158\n",
            "Epoch 132/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.4800 - acc: 0.8187\n",
            "Epoch 133/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.4809 - acc: 0.8183\n",
            "Epoch 134/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.4749 - acc: 0.8201\n",
            "Epoch 135/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.4771 - acc: 0.8198\n",
            "Epoch 136/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.4774 - acc: 0.8181\n",
            "Epoch 137/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.4728 - acc: 0.8213\n",
            "Epoch 138/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.4634 - acc: 0.8244\n",
            "Epoch 139/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.4698 - acc: 0.8222\n",
            "Epoch 140/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.4631 - acc: 0.8222\n",
            "Epoch 141/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.4619 - acc: 0.8243\n",
            "Epoch 142/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.4633 - acc: 0.8245\n",
            "Epoch 143/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.4719 - acc: 0.8226\n",
            "Epoch 144/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.4605 - acc: 0.8250\n",
            "Epoch 145/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.4601 - acc: 0.8274\n",
            "Epoch 146/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.4578 - acc: 0.8265\n",
            "Epoch 147/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.4599 - acc: 0.8257\n",
            "Epoch 148/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.4545 - acc: 0.8276\n",
            "Epoch 149/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.4643 - acc: 0.8244\n",
            "Epoch 150/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.4635 - acc: 0.8229\n",
            "Epoch 151/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.4497 - acc: 0.8290\n",
            "Epoch 152/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.4492 - acc: 0.8282\n",
            "Epoch 153/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.4475 - acc: 0.8310\n",
            "Epoch 154/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.4558 - acc: 0.8284\n",
            "Epoch 155/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.4468 - acc: 0.8301\n",
            "Epoch 156/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.4494 - acc: 0.8298\n",
            "Epoch 157/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.4425 - acc: 0.8299\n",
            "Epoch 158/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.4408 - acc: 0.8323\n",
            "Epoch 159/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.4318 - acc: 0.8359\n",
            "Epoch 160/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.4390 - acc: 0.8314\n",
            "Epoch 161/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.4450 - acc: 0.8313\n",
            "Epoch 162/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.4344 - acc: 0.8336\n",
            "Epoch 163/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.4380 - acc: 0.8311\n",
            "Epoch 164/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.4394 - acc: 0.8323\n",
            "Epoch 165/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.4368 - acc: 0.8342\n",
            "Epoch 166/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.4315 - acc: 0.8372\n",
            "Epoch 167/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.4414 - acc: 0.8322\n",
            "Epoch 168/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.4224 - acc: 0.8390\n",
            "Epoch 169/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.4348 - acc: 0.8328\n",
            "Epoch 170/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.4237 - acc: 0.8378\n",
            "Epoch 171/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.4228 - acc: 0.8420\n",
            "Epoch 172/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.4242 - acc: 0.8382\n",
            "Epoch 173/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.4276 - acc: 0.8374\n",
            "Epoch 174/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.4219 - acc: 0.8397\n",
            "Epoch 175/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.4208 - acc: 0.8401\n",
            "Epoch 176/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.4291 - acc: 0.8368\n",
            "Epoch 177/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.4216 - acc: 0.8364\n",
            "Epoch 178/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.4160 - acc: 0.8415\n",
            "Epoch 179/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.4209 - acc: 0.8396\n",
            "Epoch 180/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.4152 - acc: 0.8393\n",
            "Epoch 181/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.4115 - acc: 0.8431\n",
            "Epoch 182/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.4186 - acc: 0.8406\n",
            "Epoch 183/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.4209 - acc: 0.8391\n",
            "Epoch 184/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.4138 - acc: 0.8411\n",
            "Epoch 185/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.4138 - acc: 0.8395\n",
            "Epoch 186/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.4102 - acc: 0.8434\n",
            "Epoch 187/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.4171 - acc: 0.8401\n",
            "Epoch 188/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.4125 - acc: 0.8417\n",
            "Epoch 189/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.4079 - acc: 0.8437\n",
            "Epoch 190/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.3987 - acc: 0.8469\n",
            "Epoch 191/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.4121 - acc: 0.8442\n",
            "Epoch 192/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.4096 - acc: 0.8455\n",
            "Epoch 193/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.4035 - acc: 0.8470\n",
            "Epoch 194/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.4056 - acc: 0.8466\n",
            "Epoch 195/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.4003 - acc: 0.8468\n",
            "Epoch 196/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.4044 - acc: 0.8453\n",
            "Epoch 197/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.3952 - acc: 0.8507\n",
            "Epoch 198/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.4146 - acc: 0.8431\n",
            "Epoch 199/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.4033 - acc: 0.8465\n",
            "Epoch 200/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.3965 - acc: 0.8487\n",
            "Epoch 201/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.3970 - acc: 0.8476\n",
            "Epoch 202/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.3881 - acc: 0.8499\n",
            "Epoch 203/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.3976 - acc: 0.8486\n",
            "Epoch 204/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.3937 - acc: 0.8499\n",
            "Epoch 205/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.3940 - acc: 0.8488\n",
            "Epoch 206/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.3955 - acc: 0.8477\n",
            "Epoch 207/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.3999 - acc: 0.8477\n",
            "Epoch 208/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.3860 - acc: 0.8513\n",
            "Epoch 209/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.3874 - acc: 0.8526\n",
            "Epoch 210/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.3964 - acc: 0.8489\n",
            "Epoch 211/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.3809 - acc: 0.8530\n",
            "Epoch 212/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.3916 - acc: 0.8518\n",
            "Epoch 213/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.3877 - acc: 0.8522\n",
            "Epoch 214/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.3840 - acc: 0.8534\n",
            "Epoch 215/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.3891 - acc: 0.8503\n",
            "Epoch 216/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.3915 - acc: 0.8495\n",
            "Epoch 217/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.3813 - acc: 0.8556\n",
            "Epoch 218/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.3786 - acc: 0.8554\n",
            "Epoch 219/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.3876 - acc: 0.8515\n",
            "Epoch 220/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.3784 - acc: 0.8539\n",
            "Epoch 221/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.3840 - acc: 0.8529\n",
            "Epoch 222/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.3797 - acc: 0.8539\n",
            "Epoch 223/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.3805 - acc: 0.8541\n",
            "Epoch 224/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.3834 - acc: 0.8556\n",
            "Epoch 225/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.3761 - acc: 0.8598\n",
            "Epoch 226/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.3744 - acc: 0.8558\n",
            "Epoch 227/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.3812 - acc: 0.8534\n",
            "Epoch 228/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.3698 - acc: 0.8589\n",
            "Epoch 229/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.3747 - acc: 0.8561\n",
            "Epoch 230/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.3741 - acc: 0.8551\n",
            "Epoch 231/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.3833 - acc: 0.8507\n",
            "Epoch 232/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.3727 - acc: 0.8570\n",
            "Epoch 233/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.3632 - acc: 0.8599\n",
            "Epoch 234/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.3724 - acc: 0.8567\n",
            "Epoch 235/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.3707 - acc: 0.8551\n",
            "Epoch 236/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.3771 - acc: 0.8556\n",
            "Epoch 237/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.3709 - acc: 0.8591\n",
            "Epoch 238/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.3702 - acc: 0.8586\n",
            "Epoch 239/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.3690 - acc: 0.8592\n",
            "Epoch 240/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.3732 - acc: 0.8555\n",
            "Epoch 241/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.3512 - acc: 0.8641\n",
            "Epoch 242/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.3716 - acc: 0.8577\n",
            "Epoch 243/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.3625 - acc: 0.8598\n",
            "Epoch 244/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.3759 - acc: 0.8575\n",
            "Epoch 245/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.3547 - acc: 0.8624\n",
            "Epoch 246/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.3552 - acc: 0.8627\n",
            "Epoch 247/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.3709 - acc: 0.8571\n",
            "Epoch 248/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.3646 - acc: 0.8614\n",
            "Epoch 249/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.3535 - acc: 0.8645\n",
            "Epoch 250/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.3601 - acc: 0.8627\n",
            "Epoch 251/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.3635 - acc: 0.8607\n",
            "Epoch 252/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.3552 - acc: 0.8646\n",
            "Epoch 253/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.3615 - acc: 0.8600\n",
            "Epoch 254/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.3678 - acc: 0.8596\n",
            "Epoch 255/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.3461 - acc: 0.8687\n",
            "Epoch 256/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.3653 - acc: 0.8621\n",
            "Epoch 257/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.3616 - acc: 0.8625\n",
            "Epoch 258/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.3523 - acc: 0.8640\n",
            "Epoch 259/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.3541 - acc: 0.8636\n",
            "Epoch 260/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.3514 - acc: 0.8662\n",
            "Epoch 261/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.3487 - acc: 0.8674\n",
            "Epoch 262/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.3735 - acc: 0.8602\n",
            "Epoch 263/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.3543 - acc: 0.8644\n",
            "Epoch 264/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.3501 - acc: 0.8664\n",
            "Epoch 265/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.3505 - acc: 0.8642\n",
            "Epoch 266/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.3548 - acc: 0.8656\n",
            "Epoch 267/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.3507 - acc: 0.8644\n",
            "Epoch 268/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.3494 - acc: 0.8644\n",
            "Epoch 269/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.3474 - acc: 0.8665\n",
            "Epoch 270/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.3486 - acc: 0.8664\n",
            "Epoch 271/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.3686 - acc: 0.8620\n",
            "Epoch 272/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.3484 - acc: 0.8676\n",
            "Epoch 273/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.3410 - acc: 0.8700\n",
            "Epoch 274/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.3392 - acc: 0.8692\n",
            "Epoch 275/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.3496 - acc: 0.8663\n",
            "Epoch 276/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.3450 - acc: 0.8664\n",
            "Epoch 277/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.3409 - acc: 0.8700\n",
            "Epoch 278/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.3517 - acc: 0.8660\n",
            "Epoch 279/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.3417 - acc: 0.8676\n",
            "Epoch 280/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.3373 - acc: 0.8710\n",
            "Epoch 281/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.3382 - acc: 0.8704\n",
            "Epoch 282/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.3452 - acc: 0.8675\n",
            "Epoch 283/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.3394 - acc: 0.8691\n",
            "Epoch 284/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.3396 - acc: 0.8691\n",
            "Epoch 285/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.3518 - acc: 0.8662\n",
            "Epoch 286/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.3444 - acc: 0.8679\n",
            "Epoch 287/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.3336 - acc: 0.8714\n",
            "Epoch 288/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.3456 - acc: 0.8680\n",
            "Epoch 289/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.3496 - acc: 0.8663\n",
            "Epoch 290/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.3434 - acc: 0.8705\n",
            "Epoch 291/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.3451 - acc: 0.8660\n",
            "Epoch 292/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.3235 - acc: 0.8756\n",
            "Epoch 293/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.3365 - acc: 0.8721\n",
            "Epoch 294/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.3353 - acc: 0.8689\n",
            "Epoch 295/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.3498 - acc: 0.8664\n",
            "Epoch 296/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.3247 - acc: 0.8758\n",
            "Epoch 297/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.3296 - acc: 0.8754\n",
            "Epoch 298/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.3429 - acc: 0.8697\n",
            "Epoch 299/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.3342 - acc: 0.8716\n",
            "Epoch 300/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.3350 - acc: 0.8694\n",
            "Epoch 301/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.3290 - acc: 0.8742\n",
            "Epoch 302/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.3280 - acc: 0.8759\n",
            "Epoch 303/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.3388 - acc: 0.8697\n",
            "Epoch 304/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.3369 - acc: 0.8707\n",
            "Epoch 305/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.3345 - acc: 0.8708\n",
            "Epoch 306/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.3307 - acc: 0.8743\n",
            "Epoch 307/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.3209 - acc: 0.8776\n",
            "Epoch 308/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.3353 - acc: 0.8723\n",
            "Epoch 309/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.3334 - acc: 0.8727\n",
            "Epoch 310/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.3329 - acc: 0.8738\n",
            "Epoch 311/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.3221 - acc: 0.8751\n",
            "Epoch 312/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.3344 - acc: 0.8731\n",
            "Epoch 313/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.3295 - acc: 0.8741\n",
            "Epoch 314/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.3325 - acc: 0.8715\n",
            "Epoch 315/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.3245 - acc: 0.8749\n",
            "Epoch 316/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.3218 - acc: 0.8763\n",
            "Epoch 317/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.3245 - acc: 0.8756\n",
            "Epoch 318/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.3386 - acc: 0.8718\n",
            "Epoch 319/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.3228 - acc: 0.8768\n",
            "Epoch 320/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.3279 - acc: 0.8772\n",
            "Epoch 321/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.3290 - acc: 0.8744\n",
            "Epoch 322/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.3193 - acc: 0.8745\n",
            "Epoch 323/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.3213 - acc: 0.8768\n",
            "Epoch 324/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.3263 - acc: 0.8788\n",
            "Epoch 325/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.3264 - acc: 0.8749\n",
            "Epoch 326/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.3200 - acc: 0.8778\n",
            "Epoch 327/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.3191 - acc: 0.8768\n",
            "Epoch 328/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.3261 - acc: 0.8759\n",
            "Epoch 329/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.3160 - acc: 0.8776\n",
            "Epoch 330/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.3362 - acc: 0.8764\n",
            "Epoch 331/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.3149 - acc: 0.8803\n",
            "Epoch 332/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.3103 - acc: 0.8807\n",
            "Epoch 333/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.3187 - acc: 0.8788\n",
            "Epoch 334/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.3268 - acc: 0.8760\n",
            "Epoch 335/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.3160 - acc: 0.8783\n",
            "Epoch 336/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.3245 - acc: 0.8760\n",
            "Epoch 337/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.3098 - acc: 0.8818\n",
            "Epoch 338/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.3142 - acc: 0.8801\n",
            "Epoch 339/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.3163 - acc: 0.8779\n",
            "Epoch 340/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.3274 - acc: 0.8737\n",
            "Epoch 341/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.3127 - acc: 0.8804\n",
            "Epoch 342/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.3179 - acc: 0.8785\n",
            "Epoch 343/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.3118 - acc: 0.8810\n",
            "Epoch 344/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.3173 - acc: 0.8795\n",
            "Epoch 345/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.3254 - acc: 0.8775\n",
            "Epoch 346/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.3124 - acc: 0.8773\n",
            "Epoch 347/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.3108 - acc: 0.8826\n",
            "Epoch 348/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.3106 - acc: 0.8811\n",
            "Epoch 349/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.3183 - acc: 0.8801\n",
            "Epoch 350/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.3122 - acc: 0.8806\n",
            "Epoch 351/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.3085 - acc: 0.8783\n",
            "Epoch 352/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.3101 - acc: 0.8826\n",
            "Epoch 353/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.3122 - acc: 0.8793\n",
            "Epoch 354/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.3117 - acc: 0.8795\n",
            "Epoch 355/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.3011 - acc: 0.8851\n",
            "Epoch 356/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.3293 - acc: 0.8772\n",
            "Epoch 357/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.3001 - acc: 0.8865\n",
            "Epoch 358/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.3199 - acc: 0.8797\n",
            "Epoch 359/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.3160 - acc: 0.8802\n",
            "Epoch 360/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.3010 - acc: 0.8855\n",
            "Epoch 361/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.3043 - acc: 0.8827\n",
            "Epoch 362/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.3164 - acc: 0.8809\n",
            "Epoch 363/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.3035 - acc: 0.8815\n",
            "Epoch 364/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.3176 - acc: 0.8802\n",
            "Epoch 365/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.3157 - acc: 0.8809\n",
            "Epoch 366/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.3008 - acc: 0.8840\n",
            "Epoch 367/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2997 - acc: 0.8847\n",
            "Epoch 368/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.3061 - acc: 0.8826\n",
            "Epoch 369/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.3044 - acc: 0.8835\n",
            "Epoch 370/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2990 - acc: 0.8856\n",
            "Epoch 371/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.3147 - acc: 0.8796\n",
            "Epoch 372/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.3095 - acc: 0.8809\n",
            "Epoch 373/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.3008 - acc: 0.8854\n",
            "Epoch 374/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.3043 - acc: 0.8838\n",
            "Epoch 375/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.3094 - acc: 0.8811\n",
            "Epoch 376/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.3043 - acc: 0.8855\n",
            "Epoch 377/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.3137 - acc: 0.8819\n",
            "Epoch 378/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2976 - acc: 0.8874\n",
            "Epoch 379/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.3010 - acc: 0.8849\n",
            "Epoch 380/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.3130 - acc: 0.8820\n",
            "Epoch 381/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.2976 - acc: 0.8857\n",
            "Epoch 382/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.3112 - acc: 0.8818\n",
            "Epoch 383/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.3063 - acc: 0.8830\n",
            "Epoch 384/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2856 - acc: 0.8897\n",
            "Epoch 385/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.3114 - acc: 0.8828\n",
            "Epoch 386/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.3077 - acc: 0.8839\n",
            "Epoch 387/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.3498 - acc: 0.8770\n",
            "Epoch 388/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.3068 - acc: 0.8833\n",
            "Epoch 389/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2942 - acc: 0.8905\n",
            "Epoch 390/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2891 - acc: 0.8899\n",
            "Epoch 391/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2958 - acc: 0.8873\n",
            "Epoch 392/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.3167 - acc: 0.8798\n",
            "Epoch 393/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2929 - acc: 0.8879\n",
            "Epoch 394/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2976 - acc: 0.8870\n",
            "Epoch 395/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2892 - acc: 0.8898\n",
            "Epoch 396/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.3099 - acc: 0.8842\n",
            "Epoch 397/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.3037 - acc: 0.8843\n",
            "Epoch 398/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2984 - acc: 0.8854\n",
            "Epoch 399/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2935 - acc: 0.8856\n",
            "Epoch 400/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.3020 - acc: 0.8856\n",
            "Epoch 401/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2856 - acc: 0.8894\n",
            "Epoch 402/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2894 - acc: 0.8882\n",
            "Epoch 403/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.3031 - acc: 0.8857\n",
            "Epoch 404/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.2931 - acc: 0.8888\n",
            "Epoch 405/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.3003 - acc: 0.8878\n",
            "Epoch 406/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2936 - acc: 0.8853\n",
            "Epoch 407/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2888 - acc: 0.8896\n",
            "Epoch 408/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2898 - acc: 0.8896\n",
            "Epoch 409/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2909 - acc: 0.8897\n",
            "Epoch 410/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.3046 - acc: 0.8860\n",
            "Epoch 411/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.3063 - acc: 0.8842\n",
            "Epoch 412/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.3033 - acc: 0.8881\n",
            "Epoch 413/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2797 - acc: 0.8945\n",
            "Epoch 414/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2882 - acc: 0.8893\n",
            "Epoch 415/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2794 - acc: 0.8941\n",
            "Epoch 416/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2873 - acc: 0.8889\n",
            "Epoch 417/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2998 - acc: 0.8873\n",
            "Epoch 418/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.3024 - acc: 0.8831\n",
            "Epoch 419/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.3018 - acc: 0.8875\n",
            "Epoch 420/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2837 - acc: 0.8906\n",
            "Epoch 421/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2840 - acc: 0.8924\n",
            "Epoch 422/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2861 - acc: 0.8900\n",
            "Epoch 423/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2888 - acc: 0.8936\n",
            "Epoch 424/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.3047 - acc: 0.8858\n",
            "Epoch 425/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2908 - acc: 0.8901\n",
            "Epoch 426/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2856 - acc: 0.8914\n",
            "Epoch 427/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2832 - acc: 0.8901\n",
            "Epoch 428/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2850 - acc: 0.8916\n",
            "Epoch 429/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2829 - acc: 0.8913\n",
            "Epoch 430/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.3019 - acc: 0.8843\n",
            "Epoch 431/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.3154 - acc: 0.8839\n",
            "Epoch 432/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2726 - acc: 0.8955\n",
            "Epoch 433/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2893 - acc: 0.8907\n",
            "Epoch 434/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2870 - acc: 0.8912\n",
            "Epoch 435/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.3146 - acc: 0.8833\n",
            "Epoch 436/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2752 - acc: 0.8937\n",
            "Epoch 437/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2929 - acc: 0.8883\n",
            "Epoch 438/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2795 - acc: 0.8932\n",
            "Epoch 439/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2871 - acc: 0.8900\n",
            "Epoch 440/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2991 - acc: 0.8873\n",
            "Epoch 441/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2847 - acc: 0.8918\n",
            "Epoch 442/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2878 - acc: 0.8932\n",
            "Epoch 443/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2844 - acc: 0.8923\n",
            "Epoch 444/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2919 - acc: 0.8883\n",
            "Epoch 445/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2713 - acc: 0.8966\n",
            "Epoch 446/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2905 - acc: 0.8896\n",
            "Epoch 447/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2931 - acc: 0.8902\n",
            "Epoch 448/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2879 - acc: 0.8895\n",
            "Epoch 449/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2758 - acc: 0.8926\n",
            "Epoch 450/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2779 - acc: 0.8930\n",
            "Epoch 451/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2909 - acc: 0.8907\n",
            "Epoch 452/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2842 - acc: 0.8931\n",
            "Epoch 453/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2771 - acc: 0.8933\n",
            "Epoch 454/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2909 - acc: 0.8905\n",
            "Epoch 455/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2753 - acc: 0.8950\n",
            "Epoch 456/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2813 - acc: 0.8932\n",
            "Epoch 457/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2910 - acc: 0.8890\n",
            "Epoch 458/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2834 - acc: 0.8924\n",
            "Epoch 459/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2810 - acc: 0.8935\n",
            "Epoch 460/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2908 - acc: 0.8908\n",
            "Epoch 461/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2688 - acc: 0.8964\n",
            "Epoch 462/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2803 - acc: 0.8950\n",
            "Epoch 463/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2850 - acc: 0.8916\n",
            "Epoch 464/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2913 - acc: 0.8915\n",
            "Epoch 465/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2798 - acc: 0.8937\n",
            "Epoch 466/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2830 - acc: 0.8921\n",
            "Epoch 467/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2790 - acc: 0.8937\n",
            "Epoch 468/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2675 - acc: 0.8982\n",
            "Epoch 469/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2937 - acc: 0.8893\n",
            "Epoch 470/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2821 - acc: 0.8940\n",
            "Epoch 471/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2739 - acc: 0.8964\n",
            "Epoch 472/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2772 - acc: 0.8953\n",
            "Epoch 473/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2750 - acc: 0.8941\n",
            "Epoch 474/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2731 - acc: 0.8979\n",
            "Epoch 475/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2783 - acc: 0.8949\n",
            "Epoch 476/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.3174 - acc: 0.8844\n",
            "Epoch 477/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2686 - acc: 0.8965\n",
            "Epoch 478/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2626 - acc: 0.8992\n",
            "Epoch 479/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2776 - acc: 0.8944\n",
            "Epoch 480/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2778 - acc: 0.8934\n",
            "Epoch 481/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2842 - acc: 0.8928\n",
            "Epoch 482/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2864 - acc: 0.8916\n",
            "Epoch 483/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2787 - acc: 0.8939\n",
            "Epoch 484/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2747 - acc: 0.8944\n",
            "Epoch 485/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2666 - acc: 0.8977\n",
            "Epoch 486/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2726 - acc: 0.8973\n",
            "Epoch 487/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2751 - acc: 0.8954\n",
            "Epoch 488/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2693 - acc: 0.8965\n",
            "Epoch 489/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2809 - acc: 0.8960\n",
            "Epoch 490/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2912 - acc: 0.8926\n",
            "Epoch 491/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2683 - acc: 0.8960\n",
            "Epoch 492/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2645 - acc: 0.8992\n",
            "Epoch 493/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2626 - acc: 0.8983\n",
            "Epoch 494/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2802 - acc: 0.8945\n",
            "Epoch 495/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2763 - acc: 0.8946\n",
            "Epoch 496/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2781 - acc: 0.8947\n",
            "Epoch 497/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2650 - acc: 0.8982\n",
            "Epoch 498/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2625 - acc: 0.8981\n",
            "Epoch 499/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2734 - acc: 0.8978\n",
            "Epoch 500/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2760 - acc: 0.8964\n",
            "Epoch 501/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2726 - acc: 0.8955\n",
            "Epoch 502/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2762 - acc: 0.8969\n",
            "Epoch 503/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2685 - acc: 0.8970\n",
            "Epoch 504/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2770 - acc: 0.8936\n",
            "Epoch 505/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2709 - acc: 0.8964\n",
            "Epoch 506/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2610 - acc: 0.9011\n",
            "Epoch 507/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2749 - acc: 0.8971\n",
            "Epoch 508/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2748 - acc: 0.8968\n",
            "Epoch 509/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2693 - acc: 0.8964\n",
            "Epoch 510/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2717 - acc: 0.8963\n",
            "Epoch 511/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2722 - acc: 0.8961\n",
            "Epoch 512/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2727 - acc: 0.8972\n",
            "Epoch 513/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2740 - acc: 0.8947\n",
            "Epoch 514/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2497 - acc: 0.9049\n",
            "Epoch 515/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2738 - acc: 0.8956\n",
            "Epoch 516/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2666 - acc: 0.8981\n",
            "Epoch 517/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2726 - acc: 0.8985\n",
            "Epoch 518/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2793 - acc: 0.8955\n",
            "Epoch 519/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2656 - acc: 0.8979\n",
            "Epoch 520/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2684 - acc: 0.8986\n",
            "Epoch 521/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2724 - acc: 0.8986\n",
            "Epoch 522/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2692 - acc: 0.8986\n",
            "Epoch 523/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2846 - acc: 0.8966\n",
            "Epoch 524/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2604 - acc: 0.9014\n",
            "Epoch 525/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2695 - acc: 0.8984\n",
            "Epoch 526/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2785 - acc: 0.8958\n",
            "Epoch 527/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2628 - acc: 0.9007\n",
            "Epoch 528/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2649 - acc: 0.9003\n",
            "Epoch 529/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2878 - acc: 0.8936\n",
            "Epoch 530/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2723 - acc: 0.8984\n",
            "Epoch 531/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2603 - acc: 0.9005\n",
            "Epoch 532/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2647 - acc: 0.8995\n",
            "Epoch 533/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2607 - acc: 0.8991\n",
            "Epoch 534/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2675 - acc: 0.8985\n",
            "Epoch 535/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2792 - acc: 0.8952\n",
            "Epoch 536/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2746 - acc: 0.8962\n",
            "Epoch 537/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2580 - acc: 0.9011\n",
            "Epoch 538/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2707 - acc: 0.8986\n",
            "Epoch 539/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2719 - acc: 0.8974\n",
            "Epoch 540/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2659 - acc: 0.8993\n",
            "Epoch 541/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2776 - acc: 0.8965\n",
            "Epoch 542/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2550 - acc: 0.9026\n",
            "Epoch 543/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2784 - acc: 0.8988\n",
            "Epoch 544/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2597 - acc: 0.8992\n",
            "Epoch 545/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2691 - acc: 0.8976\n",
            "Epoch 546/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2549 - acc: 0.9012\n",
            "Epoch 547/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2560 - acc: 0.9042\n",
            "Epoch 548/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2780 - acc: 0.8934\n",
            "Epoch 549/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2667 - acc: 0.8985\n",
            "Epoch 550/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2618 - acc: 0.9006\n",
            "Epoch 551/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2612 - acc: 0.9010\n",
            "Epoch 552/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2766 - acc: 0.8969\n",
            "Epoch 553/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2605 - acc: 0.9016\n",
            "Epoch 554/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2608 - acc: 0.9029\n",
            "Epoch 555/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2616 - acc: 0.8998\n",
            "Epoch 556/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2652 - acc: 0.8974\n",
            "Epoch 557/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2652 - acc: 0.8999\n",
            "Epoch 558/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2591 - acc: 0.9011\n",
            "Epoch 559/800\n",
            "896/896 [==============================] - 2s 2ms/step - loss: 0.2603 - acc: 0.9011\n",
            "Epoch 560/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2566 - acc: 0.9027\n",
            "Epoch 561/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2755 - acc: 0.8952\n",
            "Epoch 562/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2547 - acc: 0.9009\n",
            "Epoch 563/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2795 - acc: 0.8978\n",
            "Epoch 564/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2485 - acc: 0.9054\n",
            "Epoch 565/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2543 - acc: 0.9049\n",
            "Epoch 566/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2683 - acc: 0.8984\n",
            "Epoch 567/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2561 - acc: 0.9016\n",
            "Epoch 568/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2531 - acc: 0.9023\n",
            "Epoch 569/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2703 - acc: 0.8996\n",
            "Epoch 570/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2777 - acc: 0.8974\n",
            "Epoch 571/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2550 - acc: 0.9015\n",
            "Epoch 572/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2490 - acc: 0.9051\n",
            "Epoch 573/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2588 - acc: 0.9015\n",
            "Epoch 574/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2676 - acc: 0.8982\n",
            "Epoch 575/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2649 - acc: 0.9000\n",
            "Epoch 576/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2644 - acc: 0.9006\n",
            "Epoch 577/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2634 - acc: 0.8997\n",
            "Epoch 578/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2580 - acc: 0.9036\n",
            "Epoch 579/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2550 - acc: 0.9016\n",
            "Epoch 580/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2640 - acc: 0.9012\n",
            "Epoch 581/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2483 - acc: 0.9048\n",
            "Epoch 582/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2682 - acc: 0.9001\n",
            "Epoch 583/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2552 - acc: 0.9041\n",
            "Epoch 584/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2562 - acc: 0.9024\n",
            "Epoch 585/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2574 - acc: 0.9031\n",
            "Epoch 586/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2704 - acc: 0.8969\n",
            "Epoch 587/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2569 - acc: 0.9039\n",
            "Epoch 588/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2627 - acc: 0.9026\n",
            "Epoch 589/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2500 - acc: 0.9037\n",
            "Epoch 590/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2699 - acc: 0.9001\n",
            "Epoch 591/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2559 - acc: 0.9045\n",
            "Epoch 592/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2669 - acc: 0.8991\n",
            "Epoch 593/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2570 - acc: 0.9024\n",
            "Epoch 594/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2643 - acc: 0.9027\n",
            "Epoch 595/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2483 - acc: 0.9052\n",
            "Epoch 596/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2555 - acc: 0.9024\n",
            "Epoch 597/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2526 - acc: 0.9081\n",
            "Epoch 598/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2618 - acc: 0.9021\n",
            "Epoch 599/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2629 - acc: 0.9010\n",
            "Epoch 600/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2577 - acc: 0.9029\n",
            "Epoch 601/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2519 - acc: 0.9056\n",
            "Epoch 602/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2517 - acc: 0.9050\n",
            "Epoch 603/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2549 - acc: 0.9043\n",
            "Epoch 604/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2803 - acc: 0.8985\n",
            "Epoch 605/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2519 - acc: 0.9033\n",
            "Epoch 606/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2616 - acc: 0.9033\n",
            "Epoch 607/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2465 - acc: 0.9060\n",
            "Epoch 608/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2496 - acc: 0.9065\n",
            "Epoch 609/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2658 - acc: 0.8986\n",
            "Epoch 610/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2451 - acc: 0.9080\n",
            "Epoch 611/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2675 - acc: 0.9027\n",
            "Epoch 612/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2488 - acc: 0.9065\n",
            "Epoch 613/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2528 - acc: 0.9044\n",
            "Epoch 614/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2676 - acc: 0.9000\n",
            "Epoch 615/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2545 - acc: 0.9049\n",
            "Epoch 616/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2471 - acc: 0.9052\n",
            "Epoch 617/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2522 - acc: 0.9032\n",
            "Epoch 618/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2515 - acc: 0.9066\n",
            "Epoch 619/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2559 - acc: 0.9030\n",
            "Epoch 620/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2587 - acc: 0.9024\n",
            "Epoch 621/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2542 - acc: 0.9049\n",
            "Epoch 622/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2541 - acc: 0.9051\n",
            "Epoch 623/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2600 - acc: 0.9023\n",
            "Epoch 624/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2557 - acc: 0.9035\n",
            "Epoch 625/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2453 - acc: 0.9051\n",
            "Epoch 626/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2534 - acc: 0.9039\n",
            "Epoch 627/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2508 - acc: 0.9056\n",
            "Epoch 628/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2589 - acc: 0.9041\n",
            "Epoch 629/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2423 - acc: 0.9087\n",
            "Epoch 630/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2529 - acc: 0.9044\n",
            "Epoch 631/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2431 - acc: 0.9076\n",
            "Epoch 632/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2525 - acc: 0.9034\n",
            "Epoch 633/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2610 - acc: 0.9039\n",
            "Epoch 634/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2697 - acc: 0.9005\n",
            "Epoch 635/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2702 - acc: 0.9060\n",
            "Epoch 636/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2378 - acc: 0.9098\n",
            "Epoch 637/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2515 - acc: 0.9062\n",
            "Epoch 638/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2593 - acc: 0.9030\n",
            "Epoch 639/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2524 - acc: 0.9039\n",
            "Epoch 640/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2411 - acc: 0.9083\n",
            "Epoch 641/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2526 - acc: 0.9060\n",
            "Epoch 642/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2494 - acc: 0.9040\n",
            "Epoch 643/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2570 - acc: 0.9018\n",
            "Epoch 644/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2745 - acc: 0.8977\n",
            "Epoch 645/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2718 - acc: 0.8971\n",
            "Epoch 646/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2483 - acc: 0.9053\n",
            "Epoch 647/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2362 - acc: 0.9095\n",
            "Epoch 648/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2401 - acc: 0.9074\n",
            "Epoch 649/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2493 - acc: 0.9045\n",
            "Epoch 650/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2552 - acc: 0.9029\n",
            "Epoch 651/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2434 - acc: 0.9091\n",
            "Epoch 652/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2500 - acc: 0.9038\n",
            "Epoch 653/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2538 - acc: 0.9046\n",
            "Epoch 654/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2670 - acc: 0.8999\n",
            "Epoch 655/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2611 - acc: 0.9040\n",
            "Epoch 656/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2308 - acc: 0.9124\n",
            "Epoch 657/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2590 - acc: 0.9037\n",
            "Epoch 658/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2445 - acc: 0.9086\n",
            "Epoch 659/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2471 - acc: 0.9060\n",
            "Epoch 660/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2384 - acc: 0.9094\n",
            "Epoch 661/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2602 - acc: 0.9038\n",
            "Epoch 662/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2536 - acc: 0.9037\n",
            "Epoch 663/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2447 - acc: 0.9088\n",
            "Epoch 664/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2483 - acc: 0.9068\n",
            "Epoch 665/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2463 - acc: 0.9080\n",
            "Epoch 666/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2500 - acc: 0.9073\n",
            "Epoch 667/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2658 - acc: 0.8999\n",
            "Epoch 668/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2454 - acc: 0.9096\n",
            "Epoch 669/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2546 - acc: 0.9044\n",
            "Epoch 670/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2412 - acc: 0.9081\n",
            "Epoch 671/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2476 - acc: 0.9068\n",
            "Epoch 672/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2685 - acc: 0.9013\n",
            "Epoch 673/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2504 - acc: 0.9051\n",
            "Epoch 674/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2347 - acc: 0.9090\n",
            "Epoch 675/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2299 - acc: 0.9134\n",
            "Epoch 676/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2592 - acc: 0.9018\n",
            "Epoch 677/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2385 - acc: 0.9088\n",
            "Epoch 678/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2575 - acc: 0.9052\n",
            "Epoch 679/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2402 - acc: 0.9102\n",
            "Epoch 680/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2483 - acc: 0.9076\n",
            "Epoch 681/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2663 - acc: 0.8999\n",
            "Epoch 682/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2313 - acc: 0.9121\n",
            "Epoch 683/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2356 - acc: 0.9102\n",
            "Epoch 684/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2655 - acc: 0.9022\n",
            "Epoch 685/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2434 - acc: 0.9076\n",
            "Epoch 686/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2682 - acc: 0.9009\n",
            "Epoch 687/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2533 - acc: 0.9070\n",
            "Epoch 688/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2247 - acc: 0.9149\n",
            "Epoch 689/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2411 - acc: 0.9072\n",
            "Epoch 690/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2413 - acc: 0.9094\n",
            "Epoch 691/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2753 - acc: 0.9008\n",
            "Epoch 692/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2414 - acc: 0.9084\n",
            "Epoch 693/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2353 - acc: 0.9099\n",
            "Epoch 694/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2326 - acc: 0.9100\n",
            "Epoch 695/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2425 - acc: 0.9103\n",
            "Epoch 696/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2478 - acc: 0.9090\n",
            "Epoch 697/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2616 - acc: 0.9049\n",
            "Epoch 698/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2891 - acc: 0.8977\n",
            "Epoch 699/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2462 - acc: 0.9078\n",
            "Epoch 700/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2401 - acc: 0.9095\n",
            "Epoch 701/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2362 - acc: 0.9108\n",
            "Epoch 702/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2525 - acc: 0.9042\n",
            "Epoch 703/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2313 - acc: 0.9120\n",
            "Epoch 704/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2431 - acc: 0.9088\n",
            "Epoch 705/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2462 - acc: 0.9071\n",
            "Epoch 706/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2477 - acc: 0.9066\n",
            "Epoch 707/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2369 - acc: 0.9105\n",
            "Epoch 708/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2482 - acc: 0.9070\n",
            "Epoch 709/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2465 - acc: 0.9065\n",
            "Epoch 710/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2510 - acc: 0.9065\n",
            "Epoch 711/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2399 - acc: 0.9101\n",
            "Epoch 712/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2398 - acc: 0.9102\n",
            "Epoch 713/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2318 - acc: 0.9137\n",
            "Epoch 714/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2599 - acc: 0.9038\n",
            "Epoch 715/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2344 - acc: 0.9120\n",
            "Epoch 716/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2452 - acc: 0.9066\n",
            "Epoch 717/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2617 - acc: 0.9049\n",
            "Epoch 718/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2464 - acc: 0.9067\n",
            "Epoch 719/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2344 - acc: 0.9117\n",
            "Epoch 720/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2346 - acc: 0.9114\n",
            "Epoch 721/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2624 - acc: 0.9023\n",
            "Epoch 722/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2583 - acc: 0.9065\n",
            "Epoch 723/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2394 - acc: 0.9081\n",
            "Epoch 724/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2337 - acc: 0.9110\n",
            "Epoch 725/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2466 - acc: 0.9090\n",
            "Epoch 726/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2512 - acc: 0.9076\n",
            "Epoch 727/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2343 - acc: 0.9118\n",
            "Epoch 728/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2296 - acc: 0.9130\n",
            "Epoch 729/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2434 - acc: 0.9092\n",
            "Epoch 730/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2634 - acc: 0.9034\n",
            "Epoch 731/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2361 - acc: 0.9107\n",
            "Epoch 732/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2330 - acc: 0.9137\n",
            "Epoch 733/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2363 - acc: 0.9121\n",
            "Epoch 734/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2481 - acc: 0.9063\n",
            "Epoch 735/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2282 - acc: 0.9115\n",
            "Epoch 736/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2495 - acc: 0.9099\n",
            "Epoch 737/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2361 - acc: 0.9099\n",
            "Epoch 738/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2502 - acc: 0.9067\n",
            "Epoch 739/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2441 - acc: 0.9074\n",
            "Epoch 740/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2293 - acc: 0.9122\n",
            "Epoch 741/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2502 - acc: 0.9071\n",
            "Epoch 742/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2364 - acc: 0.9112\n",
            "Epoch 743/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2361 - acc: 0.9113\n",
            "Epoch 744/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2397 - acc: 0.9087\n",
            "Epoch 745/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2257 - acc: 0.9137\n",
            "Epoch 746/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2572 - acc: 0.9050\n",
            "Epoch 747/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2439 - acc: 0.9088\n",
            "Epoch 748/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2382 - acc: 0.9112\n",
            "Epoch 749/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2318 - acc: 0.9111\n",
            "Epoch 750/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2325 - acc: 0.9122\n",
            "Epoch 751/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2467 - acc: 0.9086\n",
            "Epoch 752/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2274 - acc: 0.9137\n",
            "Epoch 753/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2307 - acc: 0.9143\n",
            "Epoch 754/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2471 - acc: 0.9069\n",
            "Epoch 755/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2502 - acc: 0.9055\n",
            "Epoch 756/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2346 - acc: 0.9105\n",
            "Epoch 757/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2518 - acc: 0.9057\n",
            "Epoch 758/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2250 - acc: 0.9140\n",
            "Epoch 759/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2423 - acc: 0.9096\n",
            "Epoch 760/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2772 - acc: 0.9012\n",
            "Epoch 761/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2336 - acc: 0.9126\n",
            "Epoch 762/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2201 - acc: 0.9161\n",
            "Epoch 763/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2386 - acc: 0.9116\n",
            "Epoch 764/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2561 - acc: 0.9070\n",
            "Epoch 765/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2478 - acc: 0.9087\n",
            "Epoch 766/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2530 - acc: 0.9076\n",
            "Epoch 767/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2277 - acc: 0.9117\n",
            "Epoch 768/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2352 - acc: 0.9117\n",
            "Epoch 769/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2378 - acc: 0.9100\n",
            "Epoch 770/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2325 - acc: 0.9107\n",
            "Epoch 771/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2292 - acc: 0.9125\n",
            "Epoch 772/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2406 - acc: 0.9105\n",
            "Epoch 773/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2426 - acc: 0.9088\n",
            "Epoch 774/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2285 - acc: 0.9135\n",
            "Epoch 775/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2422 - acc: 0.9088\n",
            "Epoch 776/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2412 - acc: 0.9079\n",
            "Epoch 777/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2365 - acc: 0.9107\n",
            "Epoch 778/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2507 - acc: 0.9055\n",
            "Epoch 779/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2291 - acc: 0.9127\n",
            "Epoch 780/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2250 - acc: 0.9137\n",
            "Epoch 781/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2345 - acc: 0.9107\n",
            "Epoch 782/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2384 - acc: 0.9112\n",
            "Epoch 783/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2550 - acc: 0.9059\n",
            "Epoch 784/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2278 - acc: 0.9126\n",
            "Epoch 785/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2388 - acc: 0.9105\n",
            "Epoch 786/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2218 - acc: 0.9157\n",
            "Epoch 787/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2493 - acc: 0.9067\n",
            "Epoch 788/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2379 - acc: 0.9098\n",
            "Epoch 789/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2426 - acc: 0.9088\n",
            "Epoch 790/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2182 - acc: 0.9161\n",
            "Epoch 791/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2265 - acc: 0.9139\n",
            "Epoch 792/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2276 - acc: 0.9118\n",
            "Epoch 793/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2402 - acc: 0.9097\n",
            "Epoch 794/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2566 - acc: 0.9068\n",
            "Epoch 795/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2249 - acc: 0.9140\n",
            "Epoch 796/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2245 - acc: 0.9144\n",
            "Epoch 797/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2326 - acc: 0.9119\n",
            "Epoch 798/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2609 - acc: 0.9049\n",
            "Epoch 799/800\n",
            "896/896 [==============================] - 2s 3ms/step - loss: 0.2295 - acc: 0.9143\n",
            "Epoch 800/800\n",
            "896/896 [==============================] - 3s 3ms/step - loss: 0.2266 - acc: 0.9148\n",
            "\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         1\n",
            "           1       0.38      0.38      0.38       159\n",
            "           2       0.00      0.00      0.00         7\n",
            "           3       0.06      0.08      0.07        13\n",
            "           4       0.71      0.75      0.73      1643\n",
            "           5       0.20      0.13      0.16       111\n",
            "           6       0.21      0.15      0.18        84\n",
            "           7       0.16      0.13      0.15       104\n",
            "           8       0.66      0.67      0.67      2065\n",
            "           9       0.15      0.17      0.16        99\n",
            "          10       0.24      0.25      0.25       135\n",
            "          11       0.06      0.08      0.07        48\n",
            "          12       0.71      0.67      0.69      1917\n",
            "          13       0.21      0.16      0.18        45\n",
            "          14       0.13      0.08      0.10        26\n",
            "          15       0.60      0.63      0.61       670\n",
            "          17       0.22      0.17      0.19        12\n",
            "          18       0.13      0.10      0.12        29\n",
            "\n",
            "    accuracy                           0.63      7168\n",
            "   macro avg       0.27      0.26      0.26      7168\n",
            "weighted avg       0.62      0.63      0.63      7168\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "NMx2jxexb2Yu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 통합버전 전처리 데이터 불러오기"
      ],
      "metadata": {
        "id": "itYcogxcb2dy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir('/content/drive/MyDrive/Colab Notebooks/GitHub/AI-ExpertFW-Prj/dataset')\n",
        "\n",
        "mc_rr_df_read = pd.read_excel('modcolth_rentway_integra_data3_imputed.xlsx')"
      ],
      "metadata": {
        "id": "UvTGACnJb41z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mc_rr_df_read_cp = mc_rr_df_read.copy()"
      ],
      "metadata": {
        "id": "ElPxMaz4cdNs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mc_rr_df_read_cp.replace({'category':['dresses', 'dress', 'shirtdress']}, 'dresses', inplace = True)\n",
        "mc_rr_df_read_cp.replace({'category':['tops', 'top']}, 'tops', inplace = True)\n",
        "mc_rr_df_read_cp.replace({'category':['bottoms', 'sweatpants', 'jeans', 'down']}, 'bottoms', inplace = True)\n",
        "mc_rr_df_read_cp.replace({'category':['leggings', 'legging']}, 'leggings', inplace = True)\n",
        "mc_rr_df_read_cp.replace({'category':['shirt', 't-shirt','sweatershirt', 'sweatshirt']}, 'shirts', inplace = True)\n",
        "mc_rr_df_read_cp.replace({'category':['skirt', 'skirts']}, 'skirts', inplace = True)\n",
        "mc_rr_df_read_cp.replace({'category':['coat', 'peacoat', 'overcoat']}, 'coats', inplace = True)\n",
        "\n",
        "mc_rr_df_read_cp['rating'] = mc_rr_df_read_cp['rating']/2"
      ],
      "metadata": {
        "id": "d78ZrFS0b-8o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "O3blMXGtcfT4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mc_rr_df_read_cp['rating'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rq0JpH8bcfvB",
        "outputId": "5a71dfb6-1cc6-4c45-fd61-1a1c9bde0684"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5.0    150534\n",
              "4.0     77384\n",
              "3.0     28163\n",
              "2.0      7352\n",
              "1.0      2245\n",
              "Name: rating, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mc_rr_df_read_cp.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qjM36z1RcfX8",
        "outputId": "bdd4072b-5f57-46a9-daf5-483105eacae7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 265678 entries, 0 to 265677\n",
            "Data columns (total 20 columns):\n",
            " #   Column           Non-Null Count   Dtype  \n",
            "---  ------           --------------   -----  \n",
            " 0   item_id          265678 non-null  int64  \n",
            " 1   size             265678 non-null  int64  \n",
            " 2   rating           265678 non-null  float64\n",
            " 3   category         265678 non-null  object \n",
            " 4   user_name        74542 non-null   object \n",
            " 5   length           74518 non-null   object \n",
            " 6   fit              265678 non-null  object \n",
            " 7   user_id          265678 non-null  int64  \n",
            " 8   review_summary   265678 non-null  object \n",
            " 9   review_text      265678 non-null  object \n",
            " 10  waist            74542 non-null   float64\n",
            " 11  hips             74542 non-null   float64\n",
            " 12  bust_size        265678 non-null  float64\n",
            " 13  height           265678 non-null  float64\n",
            " 14  cup_size_in_cms  265678 non-null  float64\n",
            " 15  rented_for       191136 non-null  object \n",
            " 16  body_type        176687 non-null  object \n",
            " 17  age              190192 non-null  float64\n",
            " 18  review_date      191136 non-null  object \n",
            " 19  weight           191136 non-null  float64\n",
            "dtypes: float64(8), int64(3), object(9)\n",
            "memory usage: 40.5+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mc_rr_df_read_cp.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "id": "b8X7T2UdfO77",
        "outputId": "c1afc12b-38f9-47fb-f6de-7929d7ea129a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            item_id           size         rating        user_id  \\\n",
              "count  2.656780e+05  265678.000000  265678.000000  265678.000000   \n",
              "mean   8.918434e+05      12.333829       4.379903  499548.980751   \n",
              "std    7.334795e+05       8.423582       0.845591  288270.720136   \n",
              "min    1.233730e+05       0.000000       1.000000       6.000000   \n",
              "25%    2.691720e+05       8.000000       4.000000  251636.000000   \n",
              "50%    6.617750e+05      12.000000       5.000000  499004.000000   \n",
              "75%    1.382388e+06      16.000000       5.000000  749324.000000   \n",
              "max    2.966087e+06      58.000000       5.000000  999997.000000   \n",
              "\n",
              "              waist          hips      bust_size         height  \\\n",
              "count  74542.000000  74542.000000  265678.000000  265678.000000   \n",
              "mean      31.752537     40.395108      34.702768     165.768246   \n",
              "std        4.617340      5.381014       2.345771       6.809175   \n",
              "min       20.000000     30.000000      28.000000     142.240000   \n",
              "25%       28.231789     36.152672      34.000000     160.020000   \n",
              "50%       31.000000     39.729514      34.000000     165.100000   \n",
              "75%       34.000000     43.000000      36.000000     170.180000   \n",
              "max       50.000000     60.000000      48.000000     187.960000   \n",
              "\n",
              "       cup_size_in_cms            age         weight  \n",
              "count    265678.000000  190192.000000  191136.000000  \n",
              "mean         16.761331      33.875026      63.053087  \n",
              "std           2.550585       8.059234      10.057498  \n",
              "min          10.500000       0.000000      22.700000  \n",
              "25%          14.500000      29.000000      56.750000  \n",
              "50%          16.500000      32.000000      61.290000  \n",
              "75%          18.500000      37.000000      68.100000  \n",
              "max          32.500000     117.000000     136.200000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a01e6cb3-61cd-49d0-9b83-22fd2d289324\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>item_id</th>\n",
              "      <th>size</th>\n",
              "      <th>rating</th>\n",
              "      <th>user_id</th>\n",
              "      <th>waist</th>\n",
              "      <th>hips</th>\n",
              "      <th>bust_size</th>\n",
              "      <th>height</th>\n",
              "      <th>cup_size_in_cms</th>\n",
              "      <th>age</th>\n",
              "      <th>weight</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>2.656780e+05</td>\n",
              "      <td>265678.000000</td>\n",
              "      <td>265678.000000</td>\n",
              "      <td>265678.000000</td>\n",
              "      <td>74542.000000</td>\n",
              "      <td>74542.000000</td>\n",
              "      <td>265678.000000</td>\n",
              "      <td>265678.000000</td>\n",
              "      <td>265678.000000</td>\n",
              "      <td>190192.000000</td>\n",
              "      <td>191136.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>8.918434e+05</td>\n",
              "      <td>12.333829</td>\n",
              "      <td>4.379903</td>\n",
              "      <td>499548.980751</td>\n",
              "      <td>31.752537</td>\n",
              "      <td>40.395108</td>\n",
              "      <td>34.702768</td>\n",
              "      <td>165.768246</td>\n",
              "      <td>16.761331</td>\n",
              "      <td>33.875026</td>\n",
              "      <td>63.053087</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>7.334795e+05</td>\n",
              "      <td>8.423582</td>\n",
              "      <td>0.845591</td>\n",
              "      <td>288270.720136</td>\n",
              "      <td>4.617340</td>\n",
              "      <td>5.381014</td>\n",
              "      <td>2.345771</td>\n",
              "      <td>6.809175</td>\n",
              "      <td>2.550585</td>\n",
              "      <td>8.059234</td>\n",
              "      <td>10.057498</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.233730e+05</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>28.000000</td>\n",
              "      <td>142.240000</td>\n",
              "      <td>10.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>22.700000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>2.691720e+05</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>251636.000000</td>\n",
              "      <td>28.231789</td>\n",
              "      <td>36.152672</td>\n",
              "      <td>34.000000</td>\n",
              "      <td>160.020000</td>\n",
              "      <td>14.500000</td>\n",
              "      <td>29.000000</td>\n",
              "      <td>56.750000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>6.617750e+05</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>499004.000000</td>\n",
              "      <td>31.000000</td>\n",
              "      <td>39.729514</td>\n",
              "      <td>34.000000</td>\n",
              "      <td>165.100000</td>\n",
              "      <td>16.500000</td>\n",
              "      <td>32.000000</td>\n",
              "      <td>61.290000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1.382388e+06</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>749324.000000</td>\n",
              "      <td>34.000000</td>\n",
              "      <td>43.000000</td>\n",
              "      <td>36.000000</td>\n",
              "      <td>170.180000</td>\n",
              "      <td>18.500000</td>\n",
              "      <td>37.000000</td>\n",
              "      <td>68.100000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>2.966087e+06</td>\n",
              "      <td>58.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>999997.000000</td>\n",
              "      <td>50.000000</td>\n",
              "      <td>60.000000</td>\n",
              "      <td>48.000000</td>\n",
              "      <td>187.960000</td>\n",
              "      <td>32.500000</td>\n",
              "      <td>117.000000</td>\n",
              "      <td>136.200000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a01e6cb3-61cd-49d0-9b83-22fd2d289324')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a01e6cb3-61cd-49d0-9b83-22fd2d289324 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a01e6cb3-61cd-49d0-9b83-22fd2d289324');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mc_rr_df_read_cp2.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "SBYdRep1tM5v",
        "outputId": "f66ed9db-20d0-4e2f-c4cb-3e31fdc18577"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            item_id           size         rating        user_id  \\\n",
              "count  2.656780e+05  265678.000000  265678.000000  265678.000000   \n",
              "mean   8.918434e+05      12.333829       4.379903  499548.980751   \n",
              "std    7.334795e+05       8.423582       0.845591  288270.720136   \n",
              "min    1.233730e+05       0.000000       1.000000       6.000000   \n",
              "25%    2.691720e+05       8.000000       4.000000  251636.000000   \n",
              "50%    6.617750e+05      12.000000       5.000000  499004.000000   \n",
              "75%    1.382388e+06      16.000000       5.000000  749324.000000   \n",
              "max    2.966087e+06      58.000000       5.000000  999997.000000   \n",
              "\n",
              "              waist          hips      bust_size         height  \\\n",
              "count  74542.000000  74542.000000  265678.000000  265678.000000   \n",
              "mean      31.752537     40.395108      34.702768     165.768246   \n",
              "std        4.617340      5.381014       2.345771       6.809175   \n",
              "min       20.000000     30.000000      28.000000     142.240000   \n",
              "25%       28.231789     36.152672      34.000000     160.020000   \n",
              "50%       31.000000     39.729514      34.000000     165.100000   \n",
              "75%       34.000000     43.000000      36.000000     170.180000   \n",
              "max       50.000000     60.000000      48.000000     187.960000   \n",
              "\n",
              "       cup_size_in_cms         weight            age  \n",
              "count    265678.000000  265678.000000  265678.000000  \n",
              "mean         16.761331      65.526956      34.201773  \n",
              "std           2.550585      12.251326       7.104792  \n",
              "min          10.500000      22.700000       0.000000  \n",
              "25%          14.500000      56.750000      30.000000  \n",
              "50%          16.500000      62.882534      33.000000  \n",
              "75%          18.500000      70.733200      37.100000  \n",
              "max          32.500000     136.200000     117.000000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c309645b-5f97-42ea-8359-5058c3f51793\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>item_id</th>\n",
              "      <th>size</th>\n",
              "      <th>rating</th>\n",
              "      <th>user_id</th>\n",
              "      <th>waist</th>\n",
              "      <th>hips</th>\n",
              "      <th>bust_size</th>\n",
              "      <th>height</th>\n",
              "      <th>cup_size_in_cms</th>\n",
              "      <th>weight</th>\n",
              "      <th>age</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>2.656780e+05</td>\n",
              "      <td>265678.000000</td>\n",
              "      <td>265678.000000</td>\n",
              "      <td>265678.000000</td>\n",
              "      <td>74542.000000</td>\n",
              "      <td>74542.000000</td>\n",
              "      <td>265678.000000</td>\n",
              "      <td>265678.000000</td>\n",
              "      <td>265678.000000</td>\n",
              "      <td>265678.000000</td>\n",
              "      <td>265678.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>8.918434e+05</td>\n",
              "      <td>12.333829</td>\n",
              "      <td>4.379903</td>\n",
              "      <td>499548.980751</td>\n",
              "      <td>31.752537</td>\n",
              "      <td>40.395108</td>\n",
              "      <td>34.702768</td>\n",
              "      <td>165.768246</td>\n",
              "      <td>16.761331</td>\n",
              "      <td>65.526956</td>\n",
              "      <td>34.201773</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>7.334795e+05</td>\n",
              "      <td>8.423582</td>\n",
              "      <td>0.845591</td>\n",
              "      <td>288270.720136</td>\n",
              "      <td>4.617340</td>\n",
              "      <td>5.381014</td>\n",
              "      <td>2.345771</td>\n",
              "      <td>6.809175</td>\n",
              "      <td>2.550585</td>\n",
              "      <td>12.251326</td>\n",
              "      <td>7.104792</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.233730e+05</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>28.000000</td>\n",
              "      <td>142.240000</td>\n",
              "      <td>10.500000</td>\n",
              "      <td>22.700000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>2.691720e+05</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>251636.000000</td>\n",
              "      <td>28.231789</td>\n",
              "      <td>36.152672</td>\n",
              "      <td>34.000000</td>\n",
              "      <td>160.020000</td>\n",
              "      <td>14.500000</td>\n",
              "      <td>56.750000</td>\n",
              "      <td>30.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>6.617750e+05</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>499004.000000</td>\n",
              "      <td>31.000000</td>\n",
              "      <td>39.729514</td>\n",
              "      <td>34.000000</td>\n",
              "      <td>165.100000</td>\n",
              "      <td>16.500000</td>\n",
              "      <td>62.882534</td>\n",
              "      <td>33.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1.382388e+06</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>749324.000000</td>\n",
              "      <td>34.000000</td>\n",
              "      <td>43.000000</td>\n",
              "      <td>36.000000</td>\n",
              "      <td>170.180000</td>\n",
              "      <td>18.500000</td>\n",
              "      <td>70.733200</td>\n",
              "      <td>37.100000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>2.966087e+06</td>\n",
              "      <td>58.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>999997.000000</td>\n",
              "      <td>50.000000</td>\n",
              "      <td>60.000000</td>\n",
              "      <td>48.000000</td>\n",
              "      <td>187.960000</td>\n",
              "      <td>32.500000</td>\n",
              "      <td>136.200000</td>\n",
              "      <td>117.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c309645b-5f97-42ea-8359-5058c3f51793')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c309645b-5f97-42ea-8359-5058c3f51793 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c309645b-5f97-42ea-8359-5058c3f51793');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 통합버전 데이터 전처리"
      ],
      "metadata": {
        "id": "UZw6bQk4w_8j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.impute import KNNImputer\n",
        "imputer = KNNImputer(n_neighbors=10)\n",
        "mc_data_knn_ind_features = mc_rr_df_read_cp[['bust_size','height', 'cup_size_in_cms', 'weight', 'age']]\n",
        "\n",
        "df_filled = imputer.fit_transform(mc_data_knn_ind_features)\n",
        "\n",
        "knn_numeric_imputations = pd.DataFrame(data=df_filled, columns=['bust_size','height', 'cup_size_in_cms', 'weight', 'age'],index = mc_rr_df_read_cp.index)\n",
        "\n",
        "mc_rr_df_read_cp2 = mc_rr_df_read_cp.drop(['bust_size','height', 'cup_size_in_cms', 'weight', 'age'], axis=1)\n",
        "\n",
        "mc_rr_df_read_cp2 = pd.concat([mc_rr_df_read_cp2, knn_numeric_imputations], axis=1)\n",
        "\n",
        "#mc_rr_df_read_cp2.to_excel('modcolth_rentway_integra_data3_imputed2.xlsx', index = False)\n",
        "mc_rr_df_read_cp2 = pd.read_excel('modcolth_rentway_integra_data3_imputed2.xlsx')\n",
        "#27분 소요\n",
        "\n"
      ],
      "metadata": {
        "id": "Fc6DHpU8fMaI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mc_rr_df_read_cp2.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "0x6U1HBK17DZ",
        "outputId": "9de8a841-ac31-4e78-8762-d6901f7b7014"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   item_id  size  rating  fit  user_id             review_summary  \\\n",
              "0   152702     4       4    1   668176           Too much ruching   \n",
              "1   152702     4       5    2   320759        Suits my body type!   \n",
              "2   152702     4       3    2   144785  I love the design and fit   \n",
              "3   152702     4       3    2    52664           Beautiful Dress!   \n",
              "4   152702     4       5    2   155439  This is a very profession   \n",
              "\n",
              "                                         review_text rented_for body_type  \\\n",
              "0  I liked the color, the silhouette, and the fab...        NaN       NaN   \n",
              "1  From the other reviews it seems like this dres...        NaN       NaN   \n",
              "2  I love the design and fit of this dress!  I wo...        NaN       NaN   \n",
              "3  I bought this dress for work  it is flattering...        NaN       NaN   \n",
              "4  This is a very professional look. It is Great ...        NaN       NaN   \n",
              "\n",
              "   bust_size  ...  cate_tee  cate_tight  cate_tops  cate_trench  cate_trouser  \\\n",
              "0       32.0  ...         0           0          0            0             0   \n",
              "1       34.0  ...         0           0          0            0             0   \n",
              "2       34.0  ...         0           0          0            0             0   \n",
              "3       32.0  ...         0           0          0            0             0   \n",
              "4       32.0  ...         0           0          0            0             0   \n",
              "\n",
              "   cate_trousers  cate_tunic  cate_turtleneck  cate_vest  cate_wedding  \n",
              "0              0           0                0          0             0  \n",
              "1              0           0                0          0             0  \n",
              "2              0           0                0          0             0  \n",
              "3              0           0                0          0             0  \n",
              "4              0           0                0          0             0  \n",
              "\n",
              "[5 rows x 76 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8992dede-1a4d-4451-8c5e-6aa3be3eb2aa\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>item_id</th>\n",
              "      <th>size</th>\n",
              "      <th>rating</th>\n",
              "      <th>fit</th>\n",
              "      <th>user_id</th>\n",
              "      <th>review_summary</th>\n",
              "      <th>review_text</th>\n",
              "      <th>rented_for</th>\n",
              "      <th>body_type</th>\n",
              "      <th>bust_size</th>\n",
              "      <th>...</th>\n",
              "      <th>cate_tee</th>\n",
              "      <th>cate_tight</th>\n",
              "      <th>cate_tops</th>\n",
              "      <th>cate_trench</th>\n",
              "      <th>cate_trouser</th>\n",
              "      <th>cate_trousers</th>\n",
              "      <th>cate_tunic</th>\n",
              "      <th>cate_turtleneck</th>\n",
              "      <th>cate_vest</th>\n",
              "      <th>cate_wedding</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>152702</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>668176</td>\n",
              "      <td>Too much ruching</td>\n",
              "      <td>I liked the color, the silhouette, and the fab...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>32.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>152702</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>320759</td>\n",
              "      <td>Suits my body type!</td>\n",
              "      <td>From the other reviews it seems like this dres...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>34.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>152702</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>144785</td>\n",
              "      <td>I love the design and fit</td>\n",
              "      <td>I love the design and fit of this dress!  I wo...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>34.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>152702</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>52664</td>\n",
              "      <td>Beautiful Dress!</td>\n",
              "      <td>I bought this dress for work  it is flattering...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>32.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>152702</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>155439</td>\n",
              "      <td>This is a very profession</td>\n",
              "      <td>This is a very professional look. It is Great ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>32.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 76 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8992dede-1a4d-4451-8c5e-6aa3be3eb2aa')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8992dede-1a4d-4451-8c5e-6aa3be3eb2aa button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8992dede-1a4d-4451-8c5e-6aa3be3eb2aa');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mc_rr_df_read_cp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 956
        },
        "id": "dTPzaye4cyQq",
        "outputId": "ba9b087b-2931-4aae-89e0-b4f72a06516b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        item_id  size  rating  category        user_name          length  \\\n",
              "0        152702     4     4.0       new            avNYC      just right   \n",
              "1        152702     4     5.0       new         lanwei91  slightly short   \n",
              "2        152702     4     3.0       new  angeladevoe5678      just right   \n",
              "3        152702     4     3.0       new             Juli   slightly long   \n",
              "4        152702     4     5.0       new          lhalton      just right   \n",
              "...         ...   ...     ...       ...              ...             ...   \n",
              "265673  2252812     8     5.0  jumpsuit              NaN             NaN   \n",
              "265674   682043     4     5.0   dresses              NaN             NaN   \n",
              "265675   683251     8     3.0   dresses              NaN             NaN   \n",
              "265676   126335    16     5.0   dresses              NaN             NaN   \n",
              "265677   127865    16     5.0      gown              NaN             NaN   \n",
              "\n",
              "          fit  user_id                                     review_summary  \\\n",
              "0       small   668176                                   Too much ruching   \n",
              "1         fit   320759                                Suits my body type!   \n",
              "2         fit   144785                          I love the design and fit   \n",
              "3         fit    52664                                   Beautiful Dress!   \n",
              "4         fit   155439                          This is a very profession   \n",
              "...       ...      ...                                                ...   \n",
              "265673    fit    66386       LOVE IT!!! First Item Im thinking of buying!   \n",
              "265674    fit   118398                                           LOVE it!   \n",
              "265675    fit    47002                    Loud patterning, flattering fit   \n",
              "265676    fit   961120  loved this dress it was comfortable and photog...   \n",
              "265677    fit   123612  I wore this to a beautiful black tie optional ...   \n",
              "\n",
              "                                              review_text  waist       hips  \\\n",
              "0       I liked the color, the silhouette, and the fab...   27.0  37.000000   \n",
              "1       From the other reviews it seems like this dres...   26.0  36.000000   \n",
              "2       I love the design and fit of this dress!  I wo...   25.0  35.765625   \n",
              "3       I bought this dress for work  it is flattering...   25.0  35.000000   \n",
              "4       This is a very professional look. It is Great ...   25.0  32.000000   \n",
              "...                                                   ...    ...        ...   \n",
              "265673                                  Fit like a glove!    NaN        NaN   \n",
              "265674  The pattern contrast on this dress is really s...    NaN        NaN   \n",
              "265675  Like the other DVF wraps, the fit on this is f...    NaN        NaN   \n",
              "265676  This dress was PERFECTION.  it looked incredib...    NaN        NaN   \n",
              "265677  This dress was wonderful! I had originally pla...    NaN        NaN   \n",
              "\n",
              "        bust_size  height  cup_size_in_cms rented_for          body_type  \\\n",
              "0            32.0  167.64             14.5        NaN                NaN   \n",
              "1            34.0  167.64             16.5        NaN                NaN   \n",
              "2            34.0  160.02             12.5        NaN                NaN   \n",
              "3            32.0  154.94             16.5        NaN                NaN   \n",
              "4            32.0  167.64             16.5        NaN                NaN   \n",
              "...           ...     ...              ...        ...                ...   \n",
              "265673       34.0  175.26             20.5       work          hourglass   \n",
              "265674       32.0  154.94             16.5       work             petite   \n",
              "265675       36.0  172.72             12.5   everyday  straight & narrow   \n",
              "265676       36.0  167.64             16.5    wedding               pear   \n",
              "265677       36.0  167.64             14.5    wedding           athletic   \n",
              "\n",
              "         age         review_date  weight  \n",
              "0        NaN                 NaN     NaN  \n",
              "1        NaN                 NaN     NaN  \n",
              "2        NaN                 NaN     NaN  \n",
              "3        NaN                 NaN     NaN  \n",
              "4        NaN                 NaN     NaN  \n",
              "...      ...                 ...     ...  \n",
              "265673  42.0        May 18, 2016   63.56  \n",
              "265674  29.0  September 30, 2016   45.40  \n",
              "265675  31.0       March 4, 2016   61.29  \n",
              "265676  31.0   November 25, 2015   74.91  \n",
              "265677  30.0     August 29, 2017   70.37  \n",
              "\n",
              "[265678 rows x 20 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-aff6250e-d325-4a07-8d13-703f13b8a17f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>item_id</th>\n",
              "      <th>size</th>\n",
              "      <th>rating</th>\n",
              "      <th>category</th>\n",
              "      <th>user_name</th>\n",
              "      <th>length</th>\n",
              "      <th>fit</th>\n",
              "      <th>user_id</th>\n",
              "      <th>review_summary</th>\n",
              "      <th>review_text</th>\n",
              "      <th>waist</th>\n",
              "      <th>hips</th>\n",
              "      <th>bust_size</th>\n",
              "      <th>height</th>\n",
              "      <th>cup_size_in_cms</th>\n",
              "      <th>rented_for</th>\n",
              "      <th>body_type</th>\n",
              "      <th>age</th>\n",
              "      <th>review_date</th>\n",
              "      <th>weight</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>152702</td>\n",
              "      <td>4</td>\n",
              "      <td>4.0</td>\n",
              "      <td>new</td>\n",
              "      <td>avNYC</td>\n",
              "      <td>just right</td>\n",
              "      <td>small</td>\n",
              "      <td>668176</td>\n",
              "      <td>Too much ruching</td>\n",
              "      <td>I liked the color, the silhouette, and the fab...</td>\n",
              "      <td>27.0</td>\n",
              "      <td>37.000000</td>\n",
              "      <td>32.0</td>\n",
              "      <td>167.64</td>\n",
              "      <td>14.5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>152702</td>\n",
              "      <td>4</td>\n",
              "      <td>5.0</td>\n",
              "      <td>new</td>\n",
              "      <td>lanwei91</td>\n",
              "      <td>slightly short</td>\n",
              "      <td>fit</td>\n",
              "      <td>320759</td>\n",
              "      <td>Suits my body type!</td>\n",
              "      <td>From the other reviews it seems like this dres...</td>\n",
              "      <td>26.0</td>\n",
              "      <td>36.000000</td>\n",
              "      <td>34.0</td>\n",
              "      <td>167.64</td>\n",
              "      <td>16.5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>152702</td>\n",
              "      <td>4</td>\n",
              "      <td>3.0</td>\n",
              "      <td>new</td>\n",
              "      <td>angeladevoe5678</td>\n",
              "      <td>just right</td>\n",
              "      <td>fit</td>\n",
              "      <td>144785</td>\n",
              "      <td>I love the design and fit</td>\n",
              "      <td>I love the design and fit of this dress!  I wo...</td>\n",
              "      <td>25.0</td>\n",
              "      <td>35.765625</td>\n",
              "      <td>34.0</td>\n",
              "      <td>160.02</td>\n",
              "      <td>12.5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>152702</td>\n",
              "      <td>4</td>\n",
              "      <td>3.0</td>\n",
              "      <td>new</td>\n",
              "      <td>Juli</td>\n",
              "      <td>slightly long</td>\n",
              "      <td>fit</td>\n",
              "      <td>52664</td>\n",
              "      <td>Beautiful Dress!</td>\n",
              "      <td>I bought this dress for work  it is flattering...</td>\n",
              "      <td>25.0</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>32.0</td>\n",
              "      <td>154.94</td>\n",
              "      <td>16.5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>152702</td>\n",
              "      <td>4</td>\n",
              "      <td>5.0</td>\n",
              "      <td>new</td>\n",
              "      <td>lhalton</td>\n",
              "      <td>just right</td>\n",
              "      <td>fit</td>\n",
              "      <td>155439</td>\n",
              "      <td>This is a very profession</td>\n",
              "      <td>This is a very professional look. It is Great ...</td>\n",
              "      <td>25.0</td>\n",
              "      <td>32.000000</td>\n",
              "      <td>32.0</td>\n",
              "      <td>167.64</td>\n",
              "      <td>16.5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>265673</th>\n",
              "      <td>2252812</td>\n",
              "      <td>8</td>\n",
              "      <td>5.0</td>\n",
              "      <td>jumpsuit</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>fit</td>\n",
              "      <td>66386</td>\n",
              "      <td>LOVE IT!!! First Item Im thinking of buying!</td>\n",
              "      <td>Fit like a glove!</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>34.0</td>\n",
              "      <td>175.26</td>\n",
              "      <td>20.5</td>\n",
              "      <td>work</td>\n",
              "      <td>hourglass</td>\n",
              "      <td>42.0</td>\n",
              "      <td>May 18, 2016</td>\n",
              "      <td>63.56</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>265674</th>\n",
              "      <td>682043</td>\n",
              "      <td>4</td>\n",
              "      <td>5.0</td>\n",
              "      <td>dresses</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>fit</td>\n",
              "      <td>118398</td>\n",
              "      <td>LOVE it!</td>\n",
              "      <td>The pattern contrast on this dress is really s...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>32.0</td>\n",
              "      <td>154.94</td>\n",
              "      <td>16.5</td>\n",
              "      <td>work</td>\n",
              "      <td>petite</td>\n",
              "      <td>29.0</td>\n",
              "      <td>September 30, 2016</td>\n",
              "      <td>45.40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>265675</th>\n",
              "      <td>683251</td>\n",
              "      <td>8</td>\n",
              "      <td>3.0</td>\n",
              "      <td>dresses</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>fit</td>\n",
              "      <td>47002</td>\n",
              "      <td>Loud patterning, flattering fit</td>\n",
              "      <td>Like the other DVF wraps, the fit on this is f...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>36.0</td>\n",
              "      <td>172.72</td>\n",
              "      <td>12.5</td>\n",
              "      <td>everyday</td>\n",
              "      <td>straight &amp; narrow</td>\n",
              "      <td>31.0</td>\n",
              "      <td>March 4, 2016</td>\n",
              "      <td>61.29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>265676</th>\n",
              "      <td>126335</td>\n",
              "      <td>16</td>\n",
              "      <td>5.0</td>\n",
              "      <td>dresses</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>fit</td>\n",
              "      <td>961120</td>\n",
              "      <td>loved this dress it was comfortable and photog...</td>\n",
              "      <td>This dress was PERFECTION.  it looked incredib...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>36.0</td>\n",
              "      <td>167.64</td>\n",
              "      <td>16.5</td>\n",
              "      <td>wedding</td>\n",
              "      <td>pear</td>\n",
              "      <td>31.0</td>\n",
              "      <td>November 25, 2015</td>\n",
              "      <td>74.91</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>265677</th>\n",
              "      <td>127865</td>\n",
              "      <td>16</td>\n",
              "      <td>5.0</td>\n",
              "      <td>gown</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>fit</td>\n",
              "      <td>123612</td>\n",
              "      <td>I wore this to a beautiful black tie optional ...</td>\n",
              "      <td>This dress was wonderful! I had originally pla...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>36.0</td>\n",
              "      <td>167.64</td>\n",
              "      <td>14.5</td>\n",
              "      <td>wedding</td>\n",
              "      <td>athletic</td>\n",
              "      <td>30.0</td>\n",
              "      <td>August 29, 2017</td>\n",
              "      <td>70.37</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>265678 rows × 20 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-aff6250e-d325-4a07-8d13-703f13b8a17f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-aff6250e-d325-4a07-8d13-703f13b8a17f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-aff6250e-d325-4a07-8d13-703f13b8a17f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# apply one hot encoding using dummies\n",
        "\n",
        "#length_dummies  = pd.get_dummies(modcloth_preprocessing2['length'])\n",
        "\n",
        "category_dummies  = pd.get_dummies(mc_rr_df_read_cp2['category'], prefix='cate')\n",
        "\n",
        "#modcloth_preprocessing = pd.concat([modcloth_preprocessing, length_dummies], axis = 1)\n",
        "mc_rr_df_read_cp2 = pd.concat([mc_rr_df_read_cp2,category_dummies], axis = 1)\n",
        "\n",
        "#modcloth_preprocessing.drop(['length'], axis=1, inplace=True)\n",
        "mc_rr_df_read_cp2.drop(['category'], axis=1, inplace=True)\n",
        "\n",
        "# target variable \n",
        "fit = {'small':1, 'fit':2, 'large':3}\n",
        "mc_rr_df_read_cp2['fit'] = mc_rr_df_read_cp2['fit'].map(fit)\n",
        "\n",
        "#length = {'very short' : 1, 'slightly short' : 2, 'just right' : 3, 'slightly long' : 4, 'very long' : 5}\n",
        "#modcloth_preprocessing2['length'] = modcloth_preprocessing2['length'].map(length)\n"
      ],
      "metadata": {
        "id": "zLmZLuLutoZK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mc_rr_df_read_cp2.drop(['user_name', 'length', 'waist', 'hips', 'review_date'], axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "DRFF0-z3uKRl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mc_rr_df_read_cp2.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D_zsfsA9uyMF",
        "outputId": "36dffd29-9683-44c0-c014-715e596d3665"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 265678 entries, 0 to 265677\n",
            "Data columns (total 76 columns):\n",
            " #   Column           Non-Null Count   Dtype  \n",
            "---  ------           --------------   -----  \n",
            " 0   item_id          265678 non-null  int64  \n",
            " 1   size             265678 non-null  int64  \n",
            " 2   rating           265678 non-null  float64\n",
            " 3   fit              265678 non-null  int64  \n",
            " 4   user_id          265678 non-null  int64  \n",
            " 5   review_summary   265678 non-null  object \n",
            " 6   review_text      265678 non-null  object \n",
            " 7   rented_for       191136 non-null  object \n",
            " 8   body_type        176687 non-null  object \n",
            " 9   bust_size        265678 non-null  float64\n",
            " 10  height           265678 non-null  float64\n",
            " 11  cup_size_in_cms  265678 non-null  float64\n",
            " 12  weight           265678 non-null  float64\n",
            " 13  age              265678 non-null  float64\n",
            " 14  cate_ballgown    265678 non-null  uint8  \n",
            " 15  cate_blazer      265678 non-null  uint8  \n",
            " 16  cate_blouse      265678 non-null  uint8  \n",
            " 17  cate_blouson     265678 non-null  uint8  \n",
            " 18  cate_bomber      265678 non-null  uint8  \n",
            " 19  cate_bottoms     265678 non-null  uint8  \n",
            " 20  cate_buttondown  265678 non-null  uint8  \n",
            " 21  cate_caftan      265678 non-null  uint8  \n",
            " 22  cate_cami        265678 non-null  uint8  \n",
            " 23  cate_cape        265678 non-null  uint8  \n",
            " 24  cate_cardigan    265678 non-null  uint8  \n",
            " 25  cate_coats       265678 non-null  uint8  \n",
            " 26  cate_combo       265678 non-null  uint8  \n",
            " 27  cate_crewneck    265678 non-null  uint8  \n",
            " 28  cate_culotte     265678 non-null  uint8  \n",
            " 29  cate_culottes    265678 non-null  uint8  \n",
            " 30  cate_dresses     265678 non-null  uint8  \n",
            " 31  cate_duster      265678 non-null  uint8  \n",
            " 32  cate_for         265678 non-null  uint8  \n",
            " 33  cate_frock       265678 non-null  uint8  \n",
            " 34  cate_gown        265678 non-null  uint8  \n",
            " 35  cate_henley      265678 non-null  uint8  \n",
            " 36  cate_hoodie      265678 non-null  uint8  \n",
            " 37  cate_jacket      265678 non-null  uint8  \n",
            " 38  cate_jogger      265678 non-null  uint8  \n",
            " 39  cate_jumpsuit    265678 non-null  uint8  \n",
            " 40  cate_kaftan      265678 non-null  uint8  \n",
            " 41  cate_kimono      265678 non-null  uint8  \n",
            " 42  cate_knit        265678 non-null  uint8  \n",
            " 43  cate_leggings    265678 non-null  uint8  \n",
            " 44  cate_maxi        265678 non-null  uint8  \n",
            " 45  cate_midi        265678 non-null  uint8  \n",
            " 46  cate_mini        265678 non-null  uint8  \n",
            " 47  cate_new         265678 non-null  uint8  \n",
            " 48  cate_outerwear   265678 non-null  uint8  \n",
            " 49  cate_overalls    265678 non-null  uint8  \n",
            " 50  cate_pant        265678 non-null  uint8  \n",
            " 51  cate_pants       265678 non-null  uint8  \n",
            " 52  cate_parka       265678 non-null  uint8  \n",
            " 53  cate_poncho      265678 non-null  uint8  \n",
            " 54  cate_print       265678 non-null  uint8  \n",
            " 55  cate_pullover    265678 non-null  uint8  \n",
            " 56  cate_romper      265678 non-null  uint8  \n",
            " 57  cate_sale        265678 non-null  uint8  \n",
            " 58  cate_sheath      265678 non-null  uint8  \n",
            " 59  cate_shift       265678 non-null  uint8  \n",
            " 60  cate_shirts      265678 non-null  uint8  \n",
            " 61  cate_skirts      265678 non-null  uint8  \n",
            " 62  cate_skort       265678 non-null  uint8  \n",
            " 63  cate_suit        265678 non-null  uint8  \n",
            " 64  cate_sweater     265678 non-null  uint8  \n",
            " 65  cate_tank        265678 non-null  uint8  \n",
            " 66  cate_tee         265678 non-null  uint8  \n",
            " 67  cate_tight       265678 non-null  uint8  \n",
            " 68  cate_tops        265678 non-null  uint8  \n",
            " 69  cate_trench      265678 non-null  uint8  \n",
            " 70  cate_trouser     265678 non-null  uint8  \n",
            " 71  cate_trousers    265678 non-null  uint8  \n",
            " 72  cate_tunic       265678 non-null  uint8  \n",
            " 73  cate_turtleneck  265678 non-null  uint8  \n",
            " 74  cate_vest        265678 non-null  uint8  \n",
            " 75  cate_wedding     265678 non-null  uint8  \n",
            "dtypes: float64(6), int64(4), object(4), uint8(62)\n",
            "memory usage: 44.1+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#X_data = mc_rr_df_read_cp2[(mc_rr_df_read_cp2['fit'] == 2) ][['bust_size',\t'height',\t'cup_size_in_cms',\t'weight',\t'age',\t'cate_ballgown',\t'cate_blazer',\t'cate_blouse',\t'cate_blouson',\t'cate_bomber',\t'cate_bottoms',\t'cate_buttondown',\t'cate_caftan',\t'cate_cami',\t'cate_cape',\t'cate_cardigan',\t'cate_coats',\t'cate_combo',\t'cate_crewneck',\t'cate_culotte',\t'cate_culottes',\t'cate_dresses',\t'cate_duster',\t'cate_for',\t'cate_frock',\t'cate_gown',\t'cate_henley',\t'cate_hoodie',\t'cate_jacket',\t'cate_jogger',\t'cate_jumpsuit',\t'cate_kaftan',\t'cate_kimono',\t'cate_knit',\t'cate_leggings',\t'cate_maxi',\t'cate_midi',\t'cate_mini',\t'cate_new',\t'cate_outerwear',\t'cate_overalls',\t'cate_pant',\t'cate_pants',\t'cate_parka',\t'cate_poncho',\t'cate_print',\t'cate_pullover',\t'cate_romper',\t'cate_sale',\t'cate_sheath',\t'cate_shift',\t'cate_shirts',\t'cate_skirts',\t'cate_skort',\t'cate_suit',\t'cate_sweater',\t'cate_tank',\t'cate_tee',\t'cate_tight',\t'cate_tops',\t'cate_trench',\t'cate_trouser',\t'cate_trousers',\t'cate_tunic',\t'cate_turtleneck',\t'cate_vest',\t'cate_wedding']]\n",
        "\n",
        "X_data = mc_rr_df_read_cp2[(mc_rr_df_read_cp2['fit'] == 2) ][['bust_size',\t'height',\t'cup_size_in_cms',\t'weight',\t'age']]\n",
        "Y_data = mc_rr_df_read_cp2[(mc_rr_df_read_cp2['fit'] == 2) ]['size']\n"
      ],
      "metadata": {
        "id": "anIWYWI8u9AY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "test_size = 0.2 # taking 70:30 training and test set\n",
        "seed = 1  # Random numbmer seeding for reapeatability of the code\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_data, Y_data, test_size=test_size, random_state=seed)\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler() \n",
        "\n",
        "# 교차검증시\n",
        "scaler.fit(X_train)\n",
        "X_train = scaler.transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n"
      ],
      "metadata": {
        "id": "dtFu0IE5wk0j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 로지스틱 회귀"
      ],
      "metadata": {
        "id": "a4A5HDMQxD0J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "log_reg = LogisticRegression(max_iter=300)#multi_class = 'multinomial')\n",
        "log_reg.fit(X_train, y_train)\n",
        "\n",
        "y_pred_logis = log_reg.predict(X_test)\n",
        "#7분소요"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gfTDulegx3Yp",
        "outputId": "42d0e922-caad-4bfd-e55f-b1ecc3428913"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_score(y_test, y_pred_logis)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d5URtzQQyBSX",
        "outputId": "c3faf1ea-a905-482b-e78c-bb153f9abd2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3759781619654231"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('\\n', classification_report(y_test, y_pred_logis))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XtlQNpblyGj_",
        "outputId": "3e0de76f-6872-4d2a-9f59-d0de6b423579"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        89\n",
            "           1       0.56      0.37      0.45      2357\n",
            "           2       0.44      0.05      0.09       134\n",
            "           3       0.00      0.00      0.00       127\n",
            "           4       0.48      0.53      0.50      6103\n",
            "           5       0.34      0.04      0.08       342\n",
            "           6       0.00      0.00      0.00       114\n",
            "           7       0.00      0.00      0.00       210\n",
            "           8       0.41      0.64      0.50      8558\n",
            "           9       0.28      0.16      0.21       525\n",
            "          10       0.00      0.00      0.00       177\n",
            "          11       0.00      0.00      0.00       138\n",
            "          12       0.29      0.36      0.32      5806\n",
            "          13       0.25      0.25      0.25       457\n",
            "          14       0.41      0.08      0.14      1735\n",
            "          15       0.26      0.10      0.14       846\n",
            "          16       0.29      0.03      0.05      2471\n",
            "          17       0.27      0.10      0.15       371\n",
            "          18       0.00      0.00      0.00        27\n",
            "          19       0.00      0.00      0.00        12\n",
            "          20       0.30      0.46      0.37      3360\n",
            "          21       0.24      0.19      0.21       278\n",
            "          22       0.00      0.00      0.00         3\n",
            "          23       0.00      0.00      0.00        18\n",
            "          24       0.19      0.08      0.11      1363\n",
            "          25       0.28      0.32      0.30       189\n",
            "          26       0.32      0.29      0.31       740\n",
            "          27       0.00      0.00      0.00        15\n",
            "          28       0.11      0.03      0.04       469\n",
            "          29       0.03      0.02      0.02        66\n",
            "          30       0.00      0.00      0.00         5\n",
            "          32       0.27      0.17      0.21       559\n",
            "          33       0.00      0.00      0.00         9\n",
            "          34       0.00      0.00      0.00         1\n",
            "          35       0.00      0.00      0.00       126\n",
            "          36       0.00      0.00      0.00        35\n",
            "          38       0.35      0.15      0.21       163\n",
            "          39       0.31      0.21      0.26       177\n",
            "          40       0.00      0.00      0.00        11\n",
            "          42       0.00      0.00      0.00         7\n",
            "          43       0.00      0.00      0.00         6\n",
            "          44       0.00      0.00      0.00         3\n",
            "          45       0.29      0.25      0.27       126\n",
            "          46       0.29      0.13      0.18        15\n",
            "          48       0.00      0.00      0.00         9\n",
            "          50       0.00      0.00      0.00         1\n",
            "          51       0.42      0.07      0.12        73\n",
            "          52       0.00      0.00      0.00         4\n",
            "          54       0.00      0.00      0.00         2\n",
            "          56       0.00      0.00      0.00         1\n",
            "          57       0.33      0.06      0.11        32\n",
            "\n",
            "    accuracy                           0.38     38465\n",
            "   macro avg       0.16      0.10      0.11     38465\n",
            "weighted avg       0.35      0.38      0.34     38465\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test.value_counts().sort_values(ascending = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CiHDG5ZCyHfA",
        "outputId": "fa65877d-209b-4337-dc99-72b375899c0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8     8558\n",
              "4     6103\n",
              "12    5806\n",
              "20    3360\n",
              "16    2471\n",
              "1     2357\n",
              "14    1735\n",
              "24    1363\n",
              "15     846\n",
              "26     740\n",
              "32     559\n",
              "9      525\n",
              "28     469\n",
              "13     457\n",
              "17     371\n",
              "5      342\n",
              "21     278\n",
              "7      210\n",
              "25     189\n",
              "39     177\n",
              "10     177\n",
              "38     163\n",
              "11     138\n",
              "2      134\n",
              "3      127\n",
              "45     126\n",
              "35     126\n",
              "6      114\n",
              "0       89\n",
              "51      73\n",
              "29      66\n",
              "36      35\n",
              "57      32\n",
              "18      27\n",
              "23      18\n",
              "46      15\n",
              "27      15\n",
              "19      12\n",
              "40      11\n",
              "33       9\n",
              "48       9\n",
              "42       7\n",
              "43       6\n",
              "30       5\n",
              "52       4\n",
              "22       3\n",
              "44       3\n",
              "54       2\n",
              "50       1\n",
              "34       1\n",
              "56       1\n",
              "Name: size, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 랜덤 포레스트"
      ],
      "metadata": {
        "id": "y5mCZ0styPvd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# model = RandomForestClassifier()\n",
        "\n",
        "model = RandomForestClassifier(n_estimators=300,\n",
        "                               min_samples_split=10, \n",
        "                               n_jobs=-1)\n",
        "\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qu4W6SjfyRf-",
        "outputId": "ab0cd703-0017-4354-8bf2-a1960b78219d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(min_samples_split=10, n_estimators=300, n_jobs=-1)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JTZHwa9wyVvW",
        "outputId": "83556206-a8b2-451b-a5c9-9c47888919d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(min_samples_split=10, n_estimators=300, n_jobs=-1)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_random = model.predict(X_test)"
      ],
      "metadata": {
        "id": "FukpKbEVyY3_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "score = accuracy_score(y_test, y_pred_random) * 100\n",
        "score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QwRIyXKgycSd",
        "outputId": "607668e4-345a-4460-f92c-9f60e4784ffa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "42.313791758741715"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print('\\n', classification_report(y_test, y_pred_random))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PICNxuIiyfWC",
        "outputId": "694c4c68-38a6-4fa1-bf6f-419d4f3a9ed9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.27      0.03      0.06        89\n",
            "           1       0.54      0.43      0.48      2357\n",
            "           2       0.48      0.16      0.24       134\n",
            "           3       0.20      0.01      0.02       127\n",
            "           4       0.49      0.55      0.52      6103\n",
            "           5       0.34      0.18      0.24       342\n",
            "           6       0.32      0.05      0.09       114\n",
            "           7       0.00      0.00      0.00       210\n",
            "           8       0.47      0.56      0.51      8558\n",
            "           9       0.26      0.18      0.21       525\n",
            "          10       0.00      0.00      0.00       177\n",
            "          11       0.00      0.00      0.00       138\n",
            "          12       0.39      0.43      0.41      5806\n",
            "          13       0.26      0.23      0.24       457\n",
            "          14       0.33      0.17      0.22      1735\n",
            "          15       0.29      0.21      0.25       846\n",
            "          16       0.35      0.33      0.34      2471\n",
            "          17       0.27      0.19      0.22       371\n",
            "          18       0.00      0.00      0.00        27\n",
            "          19       0.00      0.00      0.00        12\n",
            "          20       0.40      0.46      0.43      3360\n",
            "          21       0.28      0.20      0.23       278\n",
            "          22       0.00      0.00      0.00         3\n",
            "          23       0.00      0.00      0.00        18\n",
            "          24       0.39      0.37      0.38      1363\n",
            "          25       0.31      0.32      0.31       189\n",
            "          26       0.37      0.34      0.36       740\n",
            "          27       0.00      0.00      0.00        15\n",
            "          28       0.28      0.27      0.28       469\n",
            "          29       0.29      0.30      0.30        66\n",
            "          30       0.00      0.00      0.00         5\n",
            "          32       0.38      0.27      0.31       559\n",
            "          33       0.00      0.00      0.00         9\n",
            "          34       0.00      0.00      0.00         1\n",
            "          35       0.16      0.06      0.09       126\n",
            "          36       0.15      0.11      0.13        35\n",
            "          38       0.45      0.26      0.33       163\n",
            "          39       0.31      0.25      0.28       177\n",
            "          40       0.25      0.09      0.13        11\n",
            "          42       0.00      0.00      0.00         7\n",
            "          43       0.00      0.00      0.00         6\n",
            "          44       0.00      0.00      0.00         3\n",
            "          45       0.34      0.33      0.34       126\n",
            "          46       0.12      0.07      0.09        15\n",
            "          48       0.00      0.00      0.00         9\n",
            "          50       0.00      0.00      0.00         1\n",
            "          51       0.39      0.23      0.29        73\n",
            "          52       0.00      0.00      0.00         4\n",
            "          54       0.00      0.00      0.00         2\n",
            "          55       0.00      0.00      0.00         0\n",
            "          56       0.00      0.00      0.00         1\n",
            "          57       0.22      0.06      0.10        32\n",
            "\n",
            "    accuracy                           0.42     38465\n",
            "   macro avg       0.20      0.15      0.16     38465\n",
            "weighted avg       0.41      0.42      0.41     38465\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SVM"
      ],
      "metadata": {
        "id": "6y48fJu-ylKI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "svm = SVC(kernel='linear', C=1.0, random_state=1)\n",
        "svm.fit(X_train, y_train)\n",
        "\n",
        "#plot_decision_regions(X_combined_std, \n",
        "#                      y_combined,\n",
        "#                      classifier=svm, \n",
        "#                      test_idx=range(105, 150))"
      ],
      "metadata": {
        "id": "9rQ1DYdBymfe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_svc = svm.predict(X_test)\n",
        "\n",
        "\n",
        "score_svc = accuracy_score(y_test, y_pred_svc) * 100\n",
        "score_svc\n",
        "\n",
        "\n",
        "print('\\n', classification_report(y_test, y_pred_svc))"
      ],
      "metadata": {
        "id": "3mjHXBNOyuOg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 결정트리"
      ],
      "metadata": {
        "id": "dRVUO14KyzPb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "tree_model = DecisionTreeClassifier(criterion='gini', \n",
        "                                    max_depth=9, \n",
        "                                    random_state=1)\n",
        "tree_model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "LvFf8SO7y0j3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_tree = tree_model.predict(X_test)\n",
        "\n",
        "\n",
        "score_tree = accuracy_score(y_test, y_pred_tree) * 100\n",
        "score_tree\n",
        "\n",
        "\n",
        "print('\\n', classification_report(y_test, y_pred_tree))"
      ],
      "metadata": {
        "id": "yRTDQcX1y3k-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 퍼셉트론"
      ],
      "metadata": {
        "id": "9B9LQQtfy7PA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import Perceptron"
      ],
      "metadata": {
        "id": "t46nCGQhy9U_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ppn = Perceptron(max_iter=40, eta0=0.1, tol=1e-3, random_state=1) \n",
        "ppn = Perceptron()\n",
        "ppn.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "xRzDysVqzAmc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_ppn = ppn.predict(X_test)\n",
        "\n",
        "score_ppn = accuracy_score(y_test, y_pred_ppn) * 100\n",
        "score_ppn\n",
        "\n",
        "\n",
        "print('\\n', classification_report(y_test, y_pred_ppn))"
      ],
      "metadata": {
        "id": "W2NZxVJWzDn2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 딥러닝 관련 import"
      ],
      "metadata": {
        "id": "2faAmzCczHkz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense # 은닉층 하나씩 정의\n",
        "from tensorflow.keras.optimizers import SGD # 역전파시 사용하는 최적화 알고리즘\n",
        "from tensorflow.keras.losses import mse # y가 수치형인 경우, 성능지표\n",
        "\n",
        "tf.random.set_seed(1234) #random seed 설정"
      ],
      "metadata": {
        "id": "waFuVrdszJl8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ANN"
      ],
      "metadata": {
        "id": "RS6n8nzBz-7t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 인공신경망 모형 구성(퍼셉트론)\n",
        "model = Sequential()\n",
        "model.add(Dense(4, input_shape = (67, ), activation = 'linear')) #Dense 함수가 은닉층을 표현, input shape 는 은닉층의 입력, x 변수가 두개임을 선언, 첫번째 은닉층은 노드가 3개\n",
        "model.add(Dense(2, activation = 'linear')) #앞에서 이미 은닉층 입력을 지정했으므로 두번째 은닉층은 이전의 input shape x 변수는 2개 동일함\n",
        "model.add(Dense(1, activation = 'linear')) #앞에서 이미 은닉층 입력을 지정했으므로 두번째 은닉층은 이전의 input shape x 변수는 2개 동일함\n",
        "\n",
        "#모형 컴파일\n",
        "model.compile(optimizer = 'SGD', loss = mse, metrics = ['acc']) #평가지표 설정\n",
        "#모형 학습 및 가중치 확인\n",
        "model.fit(X_train,y_train,epochs = 10)\n",
        "model.get_weights() #인공신경망 구성하는 각각의 가중치(2*3 = 6개의 가중치, 그다음 배열은 bias, 첫번째 은닉층에서 두번째 은닉층으로의 가중치 3개, 그 다음 배열은 bias로 총 4개의 배열)\n"
      ],
      "metadata": {
        "id": "4J3CzWK-zSky"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DNN\n"
      ],
      "metadata": {
        "id": "MDVtCbll0AqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "y_train_cate = to_categorical(y_train)\n",
        "y_test_cate = to_categorical(y_test)"
      ],
      "metadata": {
        "id": "TDENuTPP0Dbd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 인공신경망 모형 구성(퍼셉트론)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(256, activation = 'relu', input_shape = (67, ) ) ) \n",
        "model.add(Dense(128, activation = 'relu') ) \n",
        "model.add(Dense(64, activation = 'relu' ) ) \n",
        "model.add(Dense(32, activation = 'relu' ) )\n",
        "model.add(Dense(19, activation = 'softmax')) \n",
        "\n",
        "\n",
        "#모형 컴파일\n",
        "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['acc'])\n",
        "#모형 학습 및 가중치 확인\n",
        "history = model.fit(X_train, y_train_cate, epochs = 3000)#,\n",
        "                    #batch_size = 128, validation_data = (x_val,y_val))\n",
        "\n",
        "#model.fit(X_train,y_train,epochs = 10)\n",
        "#model.get_weights() #인공신경망 구성하는 각각의 가중치(2*3 = 6개의 가중치, 그다음 배열은 bias, 첫번째 은닉층에서 두번째 은닉층으로의 가중치 3개, 그 다음 배열은 bias로 총 4개의 배열)"
      ],
      "metadata": {
        "id": "DRfM-C0X0HGv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}